
Généralisation de l’alignement sous-phrastique par échantillonnage 
Adrien Lardilleux1 François Yvon1,2 Yves Lepage3 (1) LIMSI-CNRS, BP 133, 91403 Orsay Cedex (2) Université Paris-Sud (3) IPS, université Waseda, Japon Adrien.Lardilleux@limsi.fr, Francois.Yvon@limsi.fr, Yves.Lepage@aoni.waseda.jp 
Résumé.          L’alignement sous-phrastique consiste à extraire des traductions d’unités textuelles de grain inférieur à la phrase à partir de textes multilingues parallèles alignés au niveau de la phrase. Un tel alignement est nécessaire, par exemple, pour entraîner des systèmes de traduction statistique. L’approche standard pour réaliser cette tâche implique l’estimation successive de plusieurs modèles probabilistes de complexité croissante et l’utilisation d’heuristiques qui permettent d’aligner des mots isolés, puis, par extension, des groupes de mots. Dans cet article, nous considérons une approche alternative, initialement proposée dans (Lardilleux & Lepage, 2008), qui repose sur un principe beaucoup plus simple, à savoir la comparaison des profils d’occurrences dans des souscorpus obtenus par échantillonnage. Après avoir analysé les forces et faiblesses de cette approche, nous montrons comment améliorer la détection d’unités de traduction longues, et évaluons ces améliorations sur des tâches de traduction automatique.
Abstract. Sub-sentential alignment is the process by which multi-word translation units are extracted from sentence-aligned multilingual parallel texts. Such alignment is necessary, for instance, to train statistical machine translation systems. Standard approaches typically rely on the estimation of several probabilistic models of increasing complexity and on the use of various heuristics that make it possible to align, first isolated words, then, by extension, groups of words. In this paper, we explore an alternative approach, originally proposed in (Lardilleux & Lepage, 2008), that relies on a much simpler principle, which is the comparison of occurrence profiles in subcorpora obtained by sampling. After analyzing the strengths and weaknesses of this approach, we show how to improve the detection of long translation units, and evaluate these improvements on machine translation tasks.
Mots-clés :         alignement sous-phrastique, traduction automatique par fragments.

Keywords:           sub-sentential alignment, phrase-based machine translation.
1    Introduction L’alignement sous-phrastique consiste à extraire des traductions d’unités textuelles de grain inférieur à la phrase à partir de corpus multilingues parallèles, c’est-à-dire dont les phrases ont préalablement été mises en correspondance. Cette tâche constitue la première étape de la plupart des systèmes de traduction automatique fondés sur les données (traduction statistique et traduction par l’exemple). Les systèmes qui concentrent aujourd’hui les efforts de recherche sont majoritairement des systèmes statistiques par fragments (phrases en anglais), qui utilisent comme principale ressource une table de traductions, dérivée d’alignements sous-phrastiques. Un telle table consiste en une liste pré-calculée de couples de traductions associant à chaque couple de fragments (source, cible) un certain nombre de scores reflétant la probabilité que source se traduise par cible.
On peut globalement inscrire les méthodes d’alignement sous-phrastique dans l’un des deux courants suivants : l’approche estimative, introduite par Brown et al. (1988), et l’approche associative, introduite par Gale & Church (1991). La première est la plus utilisée à ce jour, principalement parce qu’elle est parfaitement intégrée à la traduction automatique statistique, dont elle constitue un pilier depuis l’apparition des modèles IBM (Brown et al., 1993).
Cette approche consiste à définir un modèle probabiliste du corpus parallèle dont les paramètres sont estimés selon un processus de maximisation globale sur l’ensemble des couples de phrases disponibles. Pratiquement, le but est de déterminer les meilleurs appariements possibles entre les mots sources et cibles dans chacun des couples de phrases parallèles. Dans la seconde approche, on établit une liste de traductions candidates soumises à un test d’indépendance statistique, tels que l’information mutuelle (Fung & Church, 1994) ou le rapport de vraisemblance A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 
(Dunning, 1993) — voir (Melamed, 2000; Moore, 2005) pour des travaux récents dans cette lignée. Il s’agit ici d’un processus de maximisation locale : chaque segment est traité indépendamment des autres. Cette approche est plus souvent utilisée pour extraire directement des couples de traductions, tandis que la première cherche avant tout à établir des liens de traduction entre les mots sources et cibles de chacun des couples de phrases du corpus d’entrée. Ces liens permettent, dans un deuxième temps, d’extraire des couples de traductions.
Nous avons récemment proposé une méthode d’alignement sous-phrastique (Lardilleux & Lepage, 2008, 2009; Lardilleux, 2010), apparentée aux méthodes associatives, s’attaquant à un certain nombre de problèmes souvent négligés dans le domaine : traitement simultané de multiples langues, parallélisme massif, passage à l’échelle au cœur de la méthode, et simplicité de mise en œuvre. En moyenne, cette méthode s’est révélée meilleure que l’état de l’art sur des tâches de constitution de lexiques bilingues, mais en retrait sur des tâches de traduction automatique par fragments (Lardilleux et al., 2009). Nous n’avions émis jusqu’alors que des hypothèses pour expliquer ces résultats a priori contradictoires. Dans cet article, nous proposons une analyse fine du comportement de notre méthode afin de déterminer l’origine de ces différences, ainsi qu’une généralisation destinée à améliorer ses performances en traduction automatique par fragments.
Cet article est organisé de la façon suivante : la section 2 présente une vue d’ensemble de la méthode d’alignement d’origine ; la section 3 présente des expériences mettant en évidence l’origine de ses faiblesses ; nous décrivons dans la section 4 une généralisation, et évaluons ses performances ; et la section 5 conclut ces travaux.
2      Vue d’ensemble de la méthode d’alignement d’origine 
2.1     Principes de base 
Notre méthode d’alignement peut être vue comme une émulation des méthodes associatives, à la différence (majeure) près qu’elle ne se restreint pas à aligner des couples de mots1 (source, cible). Elle permet, en effet, de considérer des séquences de mots de taille variable, éventuellement discontinues, qui partagent strictement la même distribution (répartition) dans les phrases du corpus parallèle d’entrée, indépendamment de leur langue. Ces séquences constituent en fait un sous-ensemble des candidats de traduction qui obtiendraient un score maximal par des tests d’association statistiques. Le nombre de séquences de mots ayant exactement la même distribution étant réduit, nous ne recherchons pas ces séquences dans le corpus d’entrée même, mais dans des sous-corpus de celuici, l’idée étant que plus un sous-corpus est petit, plus les mots qu’il contient ont de chances de partager la même distribution, et que par conséquent plus le nombre de mots alignés dans ce sous-corpus est élevée.
Le cœur de la méthode consiste donc à extraire des alignements à partir de multiples sous-corpus indépendants construits par échantillonnage. En pratique, nous privilégions les sous-corpus de petite taille car ils sont plus rapides à traiter et semblent donner de meilleurs résultats (Lardilleux, 2010). Pour chaque séquence de mots de même distribution dans un sous-corpus, deux alignements sont extraits : la séquence elle-même, d’une part, et son complémentaire, d’autre part. Le nombre de sous-corpus à traiter n’étant pas défini à l’avance, le processus est anytime, c’est-à-dire qu’il peut être interrompu à tout moment par l’utilisateur, ou selon des critères tels que le temps écoulé ou le taux de couverture du corpus de départ. Plus le nombre de sous-corpus traités est élevé, plus la couverture du corpus de départ est grande et plus les mesures d’association sont précises. Les alignements extraits sont collectés à partir de l’ensemble des sous-corpus traités, et sont évalués par divers scores (probabilité de traduction et poids lexicaux (Koehn et al., 2003)) à proportion du nombre de fois qu’ils ont été extraits. Le résultat est une table de traductions directement utilisable, par exemple, pour des tâches de traduction automatique.
2.2     Algorithme complet 
L’algorithme d’extraction complet est schématisé dans le tableau 1.
La figure 1 illustre les principales étapes de l’algorithme sur un exemple d’alignement d’un texte trilingue. Dans la suite de cet article consacré aux applications de l’alignement en traduction automatique, nous nous limiterons à une application bilingue de la méthode, bien que son caractère multilingue en constitue un atout majeur.

1 Nous   employons le terme « mot » pour désigner toute forme graphique identifiée par un programme de tokenisation.
G ÉNÉRALISATION DE L’ ALIGNEMENT SOUS - PHRASTIQUE PAR ÉCHANTILLONNAGE Entrée : un corpus multilingue, ici arabe-français-anglais.
1                                    ↔ Un café , s’il vous plaît . ↔ One coffee , please .
2                                    ↔ Ce café est excellent .                       ↔ This coffee is excellent .
3                                    ↔ Un thé fort .                                 ↔ One strong tea .
4                                    ↔ Un café fort .                                ↔ One strong coffee .
Transformation en corpus alingue (= monolingue) en concaténant les traductions d’une même phrase et distinguant les mots en fonction de leur langue d’origine.
Sélection d’un sous-corpus aléatoire (ici, les trois premières lignes du corpus d’origine).
1    1 1            1       1 1            Un2 café2 ,2 s’il2 vous2 plaît2 .2 One3 coffee3 ,3 please3 .3 2    1 1            1        1           Ce2 café2 est2 excellent2 .2 This3 coffee3 is3 excellent3 .3 3    1 1        1             Un2 thé2 fort2 .2 One3 strong3 tea3 .3 Indexation des mots (calcul des vecteurs de présence). Les mots ayant même distribution sont regroupés.
1   .2 .3   1       café2 coffee3 One3 Un2           1 1           1    ,3 ,2 plaît2 please3 s’il2 vous2        1       1       Ce2 This3 est2 excellent2 . . .
1 1 11               1    1      1           1        1   1     1           1 11       1          1       1      1       0       0    0       0   0       0      ...
2 1 11               1    1      1           0        0   0     0           0 00       0          0       0      0       1       1    1       1   1       1      ...
3 1 11               0    0      0           1        1   0     0           0 00       0          0       0      0       0       0    0       0   0       0      ...
Chaque groupe de mots permet d’extraire deux alignements par phrase où il apparaît.
apparaissent dans Les mots :                                                                                      d’où sont extraits : les phrases : 
1         café2 coffee3 
1 1            1        1     Un2 _ ,2 s’il2 vous2 plaît2 .2 One3 _ ,3 please3 .3 1               café2 coffee3 1          café2 coffee3 
1 1            _1                 Ce2 _ est2 excellent2 .2 This3 _ is3 excellent3 .3 ..
Décompte des alignements et rétablissement des limites entre langues.
Arabe                                   Français                               Anglais               Décompte ↔ café                                         ↔ coffee                                  2 ↔ Un _ , s’il vous plaît . ↔ One _ , please .                                            1 _               ↔ Ce _ est excellent .                         ↔ This _ is excellent .                   1 ..
F IG . 1 – Vue d’ensemble de la méthode d’alignement. C’est la phase d’indexation et de constitution des groupes de mots (troisième étape sur la figure) que nous généraliserons dans la suite de l’article.
A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 
Transformer le corpus parallèle d’entrée, multilingue, en corpus alingue (= monolingue) Initialiser un tableau associatif CompteurAlignements Faire Sélectionner un sous-corpus par échantillonnage Indexer les mots par leur vecteur de présence dans les phrases du sous-corpus Les mots de même distribution sont rassemblés dans un même groupe Pour chaque groupe de mots : Pour chaque phrase où le groupe apparaît : Rétablir l’ordre des mots du groupe CompteurAlignements[groupe] ++ CompteurAlignements[phrase - groupe] ++ Jusqu’à interruption par l’utilisateur ou temps imparti écoulé ou plus aucun alignement obtenu ou tout autre critère Calculer les scores des alignements 
TAB . 1 – Les étapes de la méthode d’alignement.
2.3     Résultats 
Dans cette section, nous résumons les principaux résultats et conclusions de (Lardilleux, 2010). Nous avons évalué cette méthode d’alignement sur deux tâches : en traduction automatique statistique par fragments et en constitution de lexiques bilingues. L’implémentation de notre méthode, Anymalign2 , est comparée à MGIZA++3 (Gao & Vogel, 2008), l’implantation la plus récente des modèles IBM. Anymalign étant anytime, nous commençons en pratique par exécuter MGIZA++ avec ses paramètres par défaut (5 itérations de chacun des modèles IBM1, HMM, IBM3 et IBM4), mesurons son temps d’exécution, et exécutons Anymalign pendant la même durée. Les corpus parallèles utilisés dans les expériences sont principalement Europarl (Koehn, 2005) et des extraits du BTEC (Takezawa et al., 2002), distribués lors des campagnes d’évaluation de traduction automatique IWSLT (Fordyce, 2007).
Les extraits du BTEC sont constitués de 20 000 à 40 000 couples de phrases courtes alignées (10 mots anglais en moyenne) et ceux d’Europarl de 100 000 couples de phrases longues (30 mots anglais).
Dans la tâche de traduction automatique statistique par fragments, nous comparons les scores obtenus par Moses (Koehn et al., 2007) avec sa table de traductions par défaut, construite à partir des alignements de MGIZA++, et celle produite par Anymalign. En moyenne, Anymalign est en retrait de deux points BLEU (Papineni et al., 2002) sur l’ensemble des expériences que nous avons menées. Dans le meilleur des cas, nous avons obtenu un gain d’un point par rapport à MGIZA++ (BTEC, japonais-anglais) ; dans le pire, une perte de huit points (Europarl, finnois-anglais). Dans l’ensemble, les écarts sont plus prononcés sur Europarl que sur le BTEC.
Dans la tâche de constitution de lexiques bilingues, nous comparons les tables de traductions produites par les deux aligneurs avec un lexique bilingue de référence4 . Dans un premier temps, ce lexique est filtré de façon qu’il ne contienne que des couples de traductions qui peuvent effectivement être extraits par les aligneurs à partir du corpus parallèle d’entrée. En pratique, un couple de traductions du lexique de référence est conservé s’il s’agit d’une sousséquence d’un couple de phrases du corpus parallèle. Nous définissons alors le score d’une table de traductions relativement à ce lexique de référence filtré comme la somme des probabilités de traduction source → cible des alignements de la table de traductions présents dans la référence, divisée par le nombre d’entrées distinctes dans la référence. Le résultat s’interprète comme un score de rappel, entre 0 et 1. En moyenne, Anymalign est meilleur de 7 % relativement à MGIZA++ sur l’ensemble des expériences que nous avons menées. Dans le meilleur des cas, nous avons obtenu un gain relatif de 70 % (Europarl, finnois-français) ; dans le pire une perte de 18 % (Europarl, suédois-finnois). Le genre de textes constituant le corpus ne semble pas avoir d’influence majeure sur ces scores.
En résumé, notre méthode est en retrait sur les tâches de traduction automatique par fragments, mais produit de meilleurs alignements de mots, comme l’attestent les résultats de comparaison avec lexiques de référence, dont les entrées sont majoritairement des mots simples (le nombre moyen de mots par entrée est 1,2). Nous avons montré (Lardilleux et al., 2009) que cela est en fait principalement dû à la faible capacité de cette méthode à produire des alignements de n-grammes de mots avec n 2, comme l’illustre la figure 2. Le but de la section suivante est de mettre en évidence l’origine de ces différences.

2 http://users.info.unicaen.fr/~alardill/anymalign 3 http://geek.kyloo.net/software/doku.php/mgiza:overview 4 Nos   lexiques proviennent principalement du site XDXF : http://xdxf.sourceforge.net G ÉNÉRALISATION DE L’ ALIGNEMENT SOUS - PHRASTIQUE PAR ÉCHANTILLONNAGE 100 % Couverture des n−grammes MGIZA++ 80 %                    Anymalign 
60 % 
40 % 
20 % 
0% 1      2    3      4   5    6      7 
F IG . 2 – Couverture de la partie source d’un échantillon d’Europarl français-anglais par les tables de traductions de MGIZA++ et d’Anymalign. Anymalign aligne plus d’unigrammes, mais peu de n-grammes plus longs.
3     Une analyse du comportement de la méthode Dans cette section, nous présentons des expériences montrant que deux causes principales sont à l’origine des résultats apparemment contradictoires présentés ci-dessus : les différences de fréquences des mots qui composent les séquences à aligner (cause propre à la méthode), et les fréquences de mots utiles à ces tâches (cause propre à la tâche). Les expériences présentées ici sont réalisées sur un extrait d’environ 320 000 phrases d’Europarl, avec les couples de langues portugais-espagnol (cas extrêmes de langues proches dans nos expériences) et finnoisanglais (cas extrême de langues éloignées : le finnois est une langue ouralienne agglutinante, l’anglais une langue germanique d’influence romane isolante, ce qui s’exprime par une grande différence de taille des vocabulaires).
Le tableau 2 présente le nombre de mots de chaque partie de nos corpus.

Langue                          Nombre de mots (tokens)     Taille du vocabulaire portugais                                9 249 177                   87 341 espagnol                                 9 330 199                   85 366 finnois                                  6 472 649                274 958 anglais                                  8 955 995                 53 704 
TAB . 2 – Caractéristiques des corpus utilisés pour nos analyses.
3.1    Différences de fréquences 
Nous avons précédemment montré (Lardilleux et al., 2009) qu’en pratique, la contrainte d’identité des distributions qui est au cœur de la méthode empêche d’extraire des séquences composées de mots de fréquences différentes. Par exemple, un bigramme constitué d’un mot hapax suivi du point de fin de phrase (assimilé à un mot typographique) ne peut être produit, car en supposant que le point apparaisse dans toutes les phrases du corpus d’entrée, la seule configuration dans laquelle ces deux mots partageraient la même distribution serait un souscorpus constitué d’une seule phrase. Dans une telle configuration, presque tous les mots seraient hapax, et la séquence extraite consisterait donc en l’unique phrase de ce sous-corpus. Le bigramme attendu serait donc « masqué » et ne pourrait pas être extrait isolément.
Nous faisons un pas supplémentaire en étudiant la taille des sous-corpus d’où les mots sont extraits en fonction de la fréquence de ces mots. Étant donné un mot source ms à aligner isolément, trois cas peuvent se produire : 1. dans un sous-corpus « trop petit », d’autres mots sources ont la même distribution que ms . Il n’est donc pas possible d’aligner ms isolément.
2. dans un sous-corpus de taille « idéale », aucun autre mot source n’a la même distribution que ms , et au moins un mot cible a cette distribution. ms peut donc être aligné isolément.
A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 
3. dans un sous-corpus « trop grand », aucun autre mot source n’a la même distribution que ms , mais aucun mot cible non plus. ms ne peut donc pas être aligné du tout.
Il existe ainsi une plage de tailles de sous-corpus qui permet d’extraire un mot isolément. Cette plage dépend bien entendu du mot à extraire et plus particulièrement de sa fréquence. Ces plages sont déterminées empiriquement en mesurant, pour chaque mot source d’un corpus parallèle, la taille moyenne des sous-corpus à partir de laquelle il peut être aligné isolément, ainsi que celle à partir de laquelle il ne peut plus être aligné du tout. Pour cela, nous commençons par tirer aléatoirement un sous-corpus d’une seule phrase contenant ce mot, testons si le mot peut y être aligné, puis recommençons ce test en augmentant le sous-corpus d’une nouvelle phrase tirée aléatoirement.
Le processus s’arrête lorsque plus aucun mot cible n’a la même distribution que le mot source testé.
Chaque expérience produit deux nombres : la taille à partir de laquelle le mot peut être aligné isolément (passage du cas 1 au cas 2 ci-dessus), et celle à partir de laquelle le mot ne peut plus être aligné du tout (du cas 2 au cas 3).
Ce test est répété 1 000 fois pour chaque mot source, et nous effectuons la moyenne des mesures recueillies sur l’ensemble des 1 000 tirages. Les résultats sont présentés à la figure 3, par classes de mots de fréquences proches.
pt → es                                                                                   fi → en Taille moyenne des sous−corpus Taille moyenne des sous−corpus 
100 000                                         Non alignable 100 000                            Non alignable Ali gn 10 000                ab                                                                         10 000 le iso lém 1 000                                   en                                                       1 000 
100                                                                                              100 10         Alignable, mais pas isolément 10         Alignable, mais pas isolément 1                                                                                                1 1     10 100 1 000       100 000                                                                 1     10 100 1 000       100 000 Nombre d’occurrences du mot                                                                      Nombre d’occurrences du mot 
F IG . 3 – Tailles moyennes des sous-corpus à partir desquelles un mot source peut être extrait en fonction de la fréquence de ce mot. Dans la zone inférieure, le mot ne peut pas être aligné isolément (cas 1). Dans la zone du milieu, le mot peut être aligné isolément (cas 2). Dans la zone supérieure, le mot ne peut pas être aligné du tout (cas 3). Le petit sursaut de la limite supérieure à l’extrémité droite des deux graphiques est dû au point de fin de phrase, qui s’aligne plus facilement que les autres mots fréquents : il peut être aligné isolément dans des sous-corpus de 5 à 80 phrases environ.
Ces graphiques nous permettent de faire deux remarques. D’abord, la plage des tailles « idéales » des sous-corpus, autrement dit la largeur de la zone du milieu, varie grandement d’un couple de langues à l’autre. Notons que l’échelle logarithmique fait paraître cette plage plus étroite qu’elle ne l’est en réalité : le rapport moyen entre sa limite supérieure et sa limite inférieure est de 2,2 pour le couple espagnol-portugais et 1,2 pour le couple finnoisanglais. Cette différence de rapport s’explique aisément par les différences de morphologie des langues dans chacun de ces couples. Nous pouvons donc nous attendre à ce que l’alignement d’un mot donné par Anymalign nécessite le traitement de davantage de sous-corpus avec le couple finnois-anglais qu’avec le couple portugaisespagnol, puisqu’il est alors plus difficile de tirer aléatoirement un sous-corpus de la « bonne » taille.
La seconde remarque nous intéresse tout particulièrement dans le cadre de cet article : plus un mot est fréquent, plus les sous-corpus à partir desquels il est extrait sont petits, et réciproquement. Les mots rares (partie gauche des graphiques) sont donc alignés à partir de grands sous-corpus, tandis que les mots fréquents (partie droite des graphiques) sont alignés à partir de petits sous-corpus, constitués par exemple de 5 à 9 phrases pour la virgule. Ces résultats valident nos premières hypothèses : s’il est difficile de tirer un sous-corpus dans lequel deux mots source de fréquences différentes partagent la même distribution, c’est avant tout parce que ces mots ne peuvent pas être alignés à partir du même sous-corpus. Pour aligner des mots de fréquences différentes, il est nécessaire de les extraire à partir de sous-corpus de tailles différentes. Nous proposerons une alternative dans la section suivante.
G ÉNÉRALISATION DE L’ ALIGNEMENT SOUS - PHRASTIQUE PAR ÉCHANTILLONNAGE 
3.2         Fréquences utiles 
La seconde explication des différences de résultats d’Anymalign sur les deux tâches sur lesquelles il a été évalué provient en fait de la tâche elle-même, ou pour être plus précis du couple (aligneur, tâche).
Notre méthode et les modèles IBM reposent sur des intuitions opposées : la première tire parti de la rareté des mots pour les aligner (on réduit artificiellement et temporairement la fréquence de tous les mots en se plaçant dans un sous-corpus), tandis que les seconds sont estimés à partir des observations mesurées sur l’ensemble du corpus.
En conséquence, Anymalign aligne mieux les mots rares, tandis que MGIZA++ aligne mieux les mots fréquents, comme l’illustre la figure 4.

pt-es                                                  fi-en 100 %                                                  100 % Anymalign (60 %)                                       Anymalign (36 %) 80 %          MGIZA++ (53 %)                          80 %           MGIZA++ (26 %) 
60 %                                                  60 % Score Score 40 %                                                  40 % 20 %                                                  20 % 0%                                                    0% 1     10 100 1 000       100 000                       1     10 100 1 000       100 000 Nombre d’occurrences des mots                          Nombre d’occurrences des mots 
F IG . 4 – Scores obtenus par les tables de traductions produites par Anymalign et MGIZA++ sur la tâche de constitution de lexiques bilingues. Les scores entre parenthèses sont les scores globaux, calculés comme décrits au 3e paragraphe de la section 2.3. Les courbes présentent le détail de ces scores, en fonction du nombre d’occurrences du mot source de chacun des alignements : un score a été calculé localement pour chaque effectif de mot. Les courbes ont été lissées pour améliorer leur lisibilité.

Ce qui nous intéresse ici n’est pas tant l’allure générale des courbes que leur position relative : la courbe correspondant à Anymalign est au-dessus de celle de MGIZA++ pour les mots d’effectif 1 à 5 000 environ, et en-dessous pour les effectifs supérieurs. Cela montre qu’Anymalign aligne mieux non seulement les mots rares, mais également les mots de fréquence intermédiaire. Cette observation a été corroborée sur d’autres couples de langues (de-en, es-en, fr-en).
Or, les mots rares étant beaucoup plus nombreux dans tout texte — cf. loi d’Estoup-Zipf (Zipf, 1965; Mandelbrot, 1954; Montemurro, 2004) —, a fortiori dans notre corpus parallèle ainsi que dans les tables de traductions produites, et notre protocole d’évaluation par comparaison avec lexiques de référence traitant les mots indépendemment de leur fréquence, il est attendu que notre méthode obtienne de meilleurs scores en constitution de lexiques bilingues, puisque les mots qu’elle aligne le mieux sont au total les plus nombreux. À l’opposé, les mots fréquents sont beaucoup moins nombreux, mais autrement plus importants en traduction automatique car ils y sont beaucoup plus sollicités : un mot fréquent a plus de chances d’apparaître dans un jeu de test qu’un mot rare. Cela peut expliquer, au moins pour partie, les scores plus faibles d’Anymalign en traduction automatique. Idéalement, nous aimerions pouvoir utiliser les alignements de tel ou tel aligneur en fonction de la fréquence des mots, par exemple en combinant les tables de traductions produites par les aligneurs. Des expériences préliminaires utilisant les probabilités de traduction d’Anymalign comme fonction de trait supplémentaire dans la table de traduction par défaut de Moses ont donné des résultats prometteurs. Cela sort cependant du cadre de cet article, et nous nous consacrons par la suite à l’alignement de mots de fréquences différentes. Nous garderons néanmoins à l’esprit que, pour bien faire en traduction automatique, notre méthode devra également aligner plus efficacement les mots fréquents, ce que nous gardons pour des recherches futures.
4       Généralisation de la méthode à toutes les chaînes de mots Dans cette section, nous présentons une généralisation de la méthode destinée à améliorer ses performances en traduction automatique statistique par fragments. En conformité avec la méthode d’origine, nous travaillerons A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 
toujours sur les formes surfaciques des mots et sans ressource autre que le corpus d’entrée (traitement endogène).
Notre but est d’extraire davantage d’alignements de n-grammes (chaînes de mots) avec n 2 (cf. figure 2), tout en contournant le problème de l’extraction des mots de fréquences différentes (section 3.1).
4.1   Phase d’indexation 
Nous introduisons le traitement à un grain variable en indexant des n-grammes plutôt que des mots. Nous ne chercherons pas à effectuer une segmentation particulière des phrases, par exemple en chunks, dont Vergne (2009) a montré qu’ils pouvaient être déterminés de façon endogène, mais traiterons plus simplement tous les n-grammes de mots se chevauchant. Considérons le (sous-)corpus d’entrée alingue5 suivant, constitué de trois phrases : 1    abc 2    abde 3    ac 
L’indexation sur l’ensemble des n-grammes de ce corpus, avant recensement des groupes de même distribution servant de base à l’extraction des alignements, produit le résultat suivant : n=1                        n=2                       n=3             n=4 a     b    c    d   e    ab     ac    bc bd       de     abc   abd     bde     abde 1    1     1    1    0   0     1     0     1   0       0       1     0       0       0 2    1     1    0    1   1     1     0     0   1       1       0     1       1       1 3    1     0    1    0   0     0     1     0   0       0       0     0       0       0 
Dans l’étape suivante, le recensement des groupes de même distribution, nous introduisons un changement majeur : si des n-grammes de même distribution se chevauchent, le groupe de mots résultant est constitué de l’union de ces n-grammes. Par exemple, les bigrammes de même distribution bd et de formeront le groupe de mots bde.
Autrement dit, les groupes ne sont plus constitués de mots de même distribution, mais de mots issus de n-grammes de même distribution. Un même mot peut désormais apparaître dans plusieurs groupes, ce qui n’était pas le cas dans la méthode d’origine.
Ce changement soulève un problème qui ne pouvait pas se produire avec la méthode d’origine : des n-grammes peuvent masquer des (n−1)-grammes, et ce récursivement. L’unigramme b est par exemple masqué par le bigramme de même distribution ab, car l’union de b et ab donne ab, et b ne peut plus être aligné isolément. Il est donc nécessaire de traiter l’introduction de chaque longueur de n-gramme de façon spécifique.
4.2   Stratégie de constitution des groupes de mots 
Nous avons testé trois stratégies : 1. traiter séparément les n-grammes en fonction de leur longueur. Ainsi, les groupes de mots ne sont construits qu’à partir de n-grammes de même longueur en source et en cible. Cela est bien entendu d’efficacité limitée sur des couples de langues tels que finnois-anglais : il serait préférable d’autoriser l’extraction d’un seul mot d’une langue agglutinante avec plusieurs mots d’une langue isolante.
2. permettre le mélange de toutes les longueurs de n-grammes, mais en ajoutant progressivement chaque longueur. L’ensemble initial ne contient que des unigrammes (méthode d’origine). Dans un deuxième temps, nous ajoutons les bigrammes et recréons tous les groupes de mots : certains sont identiques (les décomptes des alignements correspondants sont renforcés), d’autres sont nouveaux, d’autres enfin sont masqués mais cela n’a pas d’importance car ils ont déjà été extraits à partir des unigrammes. On ajoute ensuite les trigrammes, etc. Les alignements sont extraits à chaque fois que des n-grammes sont ajoutés.
3. forcer l’alignement de n-grammes de longueurs différentes, à contrepied de la première stratégie, en traitant séquentiellement tous les couples de longueurs (source, cible) possibles (produit cartésien). Cela permet l’alignement de n-grammes de longueurs très différentes en source et en cible, voire trop : puisque nous n’avons recours à aucune connaissance extérieure, Anymalign ne sait pas a priori quelle langue est traitée, et rien ne l’empêche par exemple de vouloir aligner des unigrammes en anglais avec de longs n-grammes en finnois, quand bien même il est peu probable que le moindre alignement puisse être produit à partir d’une telle configuration. En outre, la complexité de cette approche est bien plus importante que celle des deux précédentes, et ne passe pas à l’échelle lorsque nous traitons plus de deux langues simultanément.
5 Comme   décrit à la section 2, notre principal algorithme ne fait pas de différence entre corpus multilingues et corpus monolingues.
G ÉNÉRALISATION DE L’ ALIGNEMENT SOUS - PHRASTIQUE PAR ÉCHANTILLONNAGE 
Pour comparer ces trois stratégies, nous préparons un ensemble de 100 000 sous-corpus aléatoires issus d’Europarl (français-anglais) et en extrayons les alignements selon chacune de ces stratégies. Nous réalisons l’expérience pour des longueurs maximales de n-grammes allant de 1 à 5. Les tables de traductions (3 × 5 = 15 tables au total), obtenues à partir de ce même ensemble de sous-corpus, sont évaluées sur les mêmes tâches que précédemment : en traduction automatique statistique par fragments (les critères d’évaluation sont BLEU et TER (Snover et al., 2006)) et en constitution de lexiques bilingues. Les résultats sont présentés dans le tableau 3.

Stratégie    n max.   Score en lexique (%)   BLEU (%)     TER (%)     Nombre d’entrées    Long. moy. des entrées 1             36,19             21,12        63,57          83 967                  1,92 2             36,71             22,62        61,93         277 858                  2,79 1.         3             36,66             23,08        62,06         366 971                  3,13 4             36,60             23,23        61,43         393 453                  3,24 5             36,58             22,92        62,14         399 810                  3,27 1             36,19             21,12        63,57          83 967                  1,92 2             37,08             23,63        60,68         290 631                  2,78 2.         3             37,35             24,72        59,86         398 880                  3,12 4             37,45             24,47        60,69         436 760                  3,25 5             37,56             24,25        59,94         448 212                  3,31 1             36,19             21,12        63,57          83 967                  1,92 2             31,71             23,85        60,41         312 273                  2,86 3.         3             30,90             24,50        60,68         453 429                  3,24 4             30,48             24,47        59,96         507 359                  3,39 5             30,25             24,26        60,03         524 091                  3,45 
TAB . 3 – Qualité et caractéristiques des tables de traductions produites selon chacune des trois stratégies de constitution de groupes de mots, pour différente longueurs maximales de n-grammes indexés. Les lignes où n max. = 1 sont identiques pour les trois stratégies et correspondent à la méthode d’origine.

Comme il était attendu, plus la longueur maximale des n-grammes indexés est grande, plus le nombre d’entrées dans la table de traductions et la longueur de ces entrées sont également élevés, car les alignements produits avec un n max. donné contiennent ceux produits avec un n max. inférieur (inclusion des tables). Les scores en constitution de lexiques augmentent de façon négligeable lorsque n max. augmente avec les deux premières approches, mais se dégradent de façon significative avec la troisième. Le gain en traduction automatique est significatif avec les trois approches. La seconde semble néanmoins fournir des résultats très légèrement meilleurs selon les trois critères d’évaluation. Son temps d’exécution est légèrement supérieur à celui de la première (au pire deux fois plus lent avec les 5-grammes), mais bien en-deçà de celui de la troisième (de l’ordre de l’heure à celui de la journée avec les 5-grammes).
La stratégie que nous utiliserons par la suite sera donc la deuxième. Elle constitue sur le fond un bon compromis entre les deux autres. La figure 5 présente le détail de la colonne « Nombre d’entrées » du tableau 3 pour cette deuxième stratégie, et est à confronter avec la figure 2.
Dans l’ensemble, l’ajout d’une longueur de n-grammes indexés, autrement dit le passage d’une courbe à celle immédiatement au-dessus, augmente considérablement la quantité de l’ensemble des n-grammes produits (y compris, de façon marginale, les n-grammes de taille inférieure, mais cela n’est dû qu’à l’extraction des complémentaires des groupes de mots). Le cas le plus significatif est celui de l’indexation des bigrammes (n max. = 2), qui fait exploser la quantité de bigrammes en sortie, et dans une moindre mesure de toutes les tailles de n-grammes supérieures. Le phénomène se produit également en indexant des n-grammes encore plus longs, mais cela est de moins en moins significatif à mesure que n max. augmente. Le graphique semble montrer qu’il n’est pas utile d’indexer des n-grammes de plus de 3 ou 4 mots, car cela se révèle peu productif. Les n-grammes qui nous intéressent le plus sont de toute façon ceux de longueur 1 à 3, parce que ce sont généralement les plus utiles en traduction automatique par fragments.
4.3    Expériences et nouveaux résultats 
Nous comparons à présent notre méthode généralisée (indexation des n-grammes + constitution des groupes de mots selon la deuxième stratégie testée) à MGIZA++ sur des tâches de traduction automatique statistique par A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 140 000 n max. = 5 Nombre d’entrées source 120 000                                                            n max. = 4 n max. = 3 100 000                                                            n max. = 2 80 000                                                            n max. = 1 
60 000 40 000 20 000 
1   2     3     4     5     6    7 Longueur des entrées source (en mots) 
F IG . 5 – Distribution des n-grammes dans les cinq tables de traductions obtenues par la deuxième stratégie de constitution de groupes de mots. Chaque courbe correspond à une ligne du tableau 3, et la somme des ordonnées de ses points reportés est égale à la valeur indiquée dans la colonne « Nombre d’entrées » du tableau. La courbe la plus basse (n max. = 1) correspond à la méthode d’origine (cf. figure 2).

Tâche                    Entraînement      Développement        Test      Références par phrase de test BTEC : ar-en                                                 19 972          1 512             489                      7 BTEC : zh-en                                                 19 972          1 512             989                      7 Europarl : fi-en, fr-en, pt-es                              318 804            500           1 000                      1 
TAB . 4 – Caractéristiques des corpus utilisés pour notre évaluation.

Aligneur      n max.   BLEU (%)    TER (%)         Nombre d’entrées MGIZA++                  33,68      46,17              217 512 Anymalign       1        26,33      51,17              170 521 ar-en          -            2        30,88      49,70              269 454 -            3        31,81      51,48              273 197 -            4        33,75      48,80              258 141 MGIZA++                  15,46      70,49              141 773 Anymalign       1        14,77      68,97              158 904 zh-en          -            2        16,35      71,70              263 315 -            3        16,54      70,62              250 292 -            4        16,84      69,45              269 353 
TAB . 5 – Résultats des tâches de traduction sur le BTEC.

Même temps de traitement que MGIZA++           Temps théorique = 20 × MGIZA++ Aligneur                        n max.          BLEU (%)    TER (%)     Nombre d’entrées       BLEU (%)    TER (%)     Nombre d’entrées MGIZA++                                            21,68        65,50        5 241 325 Anymalign                            1             13,73        77,57        1 871 639               13,54        74,34      5 178 683 fi-en       -                                 2             14,39        76,59          890 644               16,21        71,18      5 948 094 -                                 3             14,64        77,15          696 420               17,44        72,63      4 001 816 -                                 4             12,79        78,46          279 437               16,80        71,34      2 266 448 MGIZA++                                            29,39        54,37       10 783 083 Anymalign                            1             22,74        61,85        1 755 334               23,58        61,09      7 882 822 fr-en       -                                 2             24,68        60,22        1 805 297               24,55        58,42      8 317 221 -                                 3             24,40        59,77        1 074 258               25,29        57,66      6 943 421 -                                 4             23,01        61,86          492 530               24,78        58,11      5 121 617 MGIZA++                                            38,22        47,47       17 828 592 Anymalign                            1             34,63        50,25        1 532 520               34,84        50,35      6 730 554 pt-es       -                                 2             36,03        49,63          987 884               36,72        49,10      7 295 581 -                                 3             35,72        49,95          744 947               35,98        49,02      6 126 896 -                                 4             35,18        50,34          342 168               37,01        48,71      3 926 578 
TAB . 6 – Résultats des tâches de traduction sur Europarl.
G ÉNÉRALISATION DE L’ ALIGNEMENT SOUS - PHRASTIQUE PAR ÉCHANTILLONNAGE 
fragments. Le tableau 4 présente les caractéristiques des données utilisées pour chacune de ces expériences, et les tableaux 5 et 6 présentent les résultats.
Les lignes où n max. = 1 correspondent à la version d’origine d’Anymalign. Comme décrit précédemment (section 2.3), Anymalign étant anytime, la condition d’arrêt que nous lui imposons dépend du temps d’exécution de MGIZA++. Ce temps est constant quelle que soit la valeur de n max. Le temps de traitement augmentant avec ce paramètre, plus ce paramètre est élevé et plus le nombre de sous-corpus traités est faible, contrairement aux expériences présentées dans la section 4.2 où l’ensemble des sous-corpus à traiter était fixé à l’avance, impliquant un temps de traitement dépendant de n max. Théoriquement, les tables produites pour un n max. donné sont plus grandes que pour un n max. inférieur, à condition que l’aligneur soit exécuté suffisamment longtemps. Cela explique pourquoi les tables de traductions des tableaux 5 et 6 peuvent contenir moins d’entrées pour de plus grandes valeurs de n max. En pratique, ces tables contiennent tout de même davantage de longs n-grammes, ce qui permet une amélioration très significative des scores, malgré une table de traductions plus petite.
Sur les tâches impliquant le BTEC, les lignes où n max. = 1 montrent que la version d’origine d’Anymalign obtient des scores BLEU comparables à MGIZA++ en chinois-anglais, et est loin derrière en arabe-anglais. La généralisation aux n-grammes lui permet de devancer MGIZA++ de plus d’un point BLEU en chinois-anglais, et de l’égaliser en arabe-anglais, soit un gain spectaculaire de 7 points BLEU.
Sur les tâches impliquant Europarl, les scores de la version d’origine d’Anymalign sont en retrait de façon significative par rapport à MGIZA++, ce qui est conforme aux expériences que nous avions menées précédemment. Cela dit, la différence n’était pas aussi prononcée dans nos anciennes expériences : nous observions une différence de 2 à 3 points BLEU en moyenne, alors qu’elle est ici de 6 points. Nous pensons que ce changement est dû à la taille de notre corpus qui est désormais beaucoup plus élevé : 320 000 couples de phrases contre 100 000 précédemment.
La taille des tables de traductions d’Anymalign, très petites par rapport à celles de MGIZA++, semble indiquer que le temps d’exécution de notre méthode n’est pas suffisant. Pour cette raison, le tableau 6 contient dans sa partie droite une deuxième série de résultats, qui correspondent à l’exécution d’Anymalign pendant une durée totale égale à 20 fois le temps d’exécution de MGIZA++. En pratique, Anymalign étant massivement parallélisable, nous avons découpé les traitements en 140 processus et les avons exécutés sur un cluster, pour finalement profiter d’un temps de traitement 7 fois plus rapide qu’avec les résultats présentés dans la partie gauche du tableau. Les tailles des tables de traductions dans la partie droite du tableau sont plus proches de celles de MGIZA++, ce qui confirme que le temps d’exécution n’était pas suffisant6 , mais le gain en BLEU de la version d’origine d’Anymalign n’est pas significatif pour autant. Il l’est par contre lorsque nous augmentons n max. : nous gagnons jusqu’à 3 points BLEU en finnois-anglais (n max. = 3) simplement en exécutant Anymalign plus longtemps. Dans tous les cas de la partie droite du tableau, l’indexation des n-grammes permet un gain en BLEU allant d’1,7 point en françaisanglais à près de 4 points en finnois-anglais. En moyenne, les meilleurs scores d’Anymalign sont désormais en retrait de 3,5 points BLEU par rapport à MGIZA++, divisant pratiquement par deux son retard initial.
5     Conclusion 
Cet article a présenté une généralisation de notre méthode d’alignement sous-phrastique afin d’améliorer ses résultats en traduction automatique. La méthode d’origine obtient de meilleurs résultats que l’état de l’art sur des tâches de constitution de lexiques bilingues, mais des résultats inférieurs en traduction automatique statistique par fragments. Nous avons montré que ces différences ont principalement deux causes : les différences de fréquences des mots qui composent les séquences à aligner (cause propre à la méthode), et les fréquences de mots utiles à ces tâches (cause propre à la tâche). Pour pallier le premier problème, nous avons proposé une généralisation de la phase d’indexation de notre méthode, en ne considérant non plus le mot comme unité, mais le n-gramme. Le résultat de cette généralisation est un fort accroissement du nombre de n-grammes en sortie, qui mène à des gains très significatifs en traduction automatique par fragments (jusqu’à +7 points BLEU sur le couple arabe-anglais).
Notre méthode fait désormais jeu égal avec l’état de l’art sur des tâches « simples » de traduction automatique (BTEC), et nous avons pratiquement divisé son retard par deux sur des tâches plus difficiles (Europarl). Pour aller plus loin, nous envisageons d’étudier le cas de l’alignement des mots fréquents, dont nous avons montré qu’ils étaient moins bien alignés que les mots rares par notre méthode, ainsi que la question de sa condition d’arrêt.

6 Cela soulève une autre question, qui est celle de la condition d’arrêt d’Anymalign. Les présentes expériences montrent que nos critères 
actuels sont insuffisants, ne serait-ce que pour effectuer une juste comparaison avec d’autres outils.
A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 
Remerciements Les travaux présentés dans cet article ont été partiellement financés par le projet Cap Digital SAMAR.


Estimation d’un modèle de traduction à partir d’alignements mot-à-mot non-déterministes 
Nadi Tomeh Alexandre Allauzen François Yvon Université Paris Sud et LIMSI/CNRS BP 133 91 403 Orsay {nadi,allauzen,yvon}@limsi.fr 
Résumé.           Dans les systèmes de traduction statistique à base de segments, le modèle de traduction est estimé à partir d’alignements mot-à-mot grâce à des heuristiques d’extraction et de valuation. Bien que ces alignements mot-à-mot soient construits par des modèles probabilistes, les processus d’extraction et de valuation utilisent ces modèles en faisant l’hypothèse que ces alignements sont déterministes. Dans cet article, nous proposons de lever cette hypothèse en considérant l’ensemble de la matrice d’alignement, d’une paire de phrases, chaque association étant valuée par sa probabilité. En comparaison avec les travaux antérieurs, nous montrons qu’en utilisant un modèle exponentiel pour estimer de manière discriminante ces probabilités, il est possible d’obtenir des améliorations significatives des performances de traduction. Ces améliorations sont mesurées à l’aide de la métrique BLEU sur la tâche de traduction de l’arabe vers l’anglais de l’évaluation NIST MT’09, en considérant deux types de conditions selon la taille du corpus de données parallèles utilisées.
Abstract.         In extant phrase-based statistical translation systems, the translation model relies on word-to-word alignments, which serve as constraints for further heuristic extraction and scoring processes. These word alignments are infered in a probabilistic framework ; yet, only one single best word alignment is used as if alignments were deterministically produced. In this paper, we propose to take the full probabilistic alignment matrix into account, where each alignment link is scored by its probability score. By comparison with previous attempts, we show that using an exponential model to compute these probabilities is an effective way to achieve significant improvements in translation accuracy on the NIST MT’09 Arabic to English translation task, where the accuracy is measured in terms of BLEU scores.
Mots-clés :         traduction statistique, modèles de traduction à base de segments, modèles d’alignement mot-à-mot.

Keywords:           statistical machine translation, phrase based translation models, word alignment models.
1    Introduction Dans les systèmes de traduction statistique à base de segments (phrase-based systems), le modèle de traduction sert de pont entre les langues source et cible. Sur la base d’hypothèses de segmentation de la phrase source à traduire, il permet de proposer, pour chacun des segments, des traductions candidates en langue cible. Ces hypothèses de traduction sont sélectionnées dans un inventaire qui enregistre des appariements valués entre segments de longueur variable. Ces associations et les scores qui les accompagnent constituent la table de traductions (phrase-table).
Ce modèle est estimé en deux temps à partir d’un corpus parallèle : (i) extraction d’un ensemble de couples de segments candidats, (ii) valuation des couples retenus dans la phase (i). Faute de disposer de méthodes d’estimation théoriquement bien fondées, chacune de ces deux étapes repose sur un ensemble d’heuristiques. Il s’avère en effet impossible d’estimer directement les valuations calculées en (ii), ni même de recencer tous les appariements possibles en (i). En effet, estimer de façon non-supervisée un modèle probabiliste des alignements de segments demanderait de pouvoir calculer des sommes sur tous les alignements de segments possibles, à défaut, de savoir calculer un alignement optimal utilisant des segments de taille variable. Ces deux procédures posent des problèmes combinatoires NP-difficiles (DeNero & Klein, 2008) et ne peuvent être effectuées de manière exacte. De manière plus subtile, construire des modèles d’alignements de segments demande de mettre en compétition des segmentations conjointes de taille variable des phrases source et cible, au risque de toujours préférer les alignements impliquant des segments longs. Enfin, ne considérer qu’une seule segmentation lors de l’apprentissage semble avoir un effet négatif sur la capacité de généralisation du modèle (DeNero et al., 2006).
La solution pratique qui s’est progressivement imposée contourne le problème en considérant en premier lieu une segmentation NADI T OMEH , A LEXANDRE A LLAUZEN ET F RANÇOIS Y VON 
maximale et en effectuant un alignement préalable au niveau des mots ; des procédures efficaces fondées sur l’algorithme EM (Expectation-Maximisation) pour effectuer cet alignement de manière efficace existent depuis le début des années 90 (Brown et al., 1993; Och & Ney, 2003). Ces alignements de mots sont ensuite ré-analysés pour en déduire des alignements de segments, la méthode la plus répandue consistant à extraire les alignements de segments compatibles avec les contraintes posées par les alignements de mots.
Dans un troisième temps, les statistiques d’occurrence de ces alignements de segments sont collectées et utilisées pour attribuer des scores de confiance à ces groupes bilingues. Ces trois étapes successives de la construction du modèle de traduction sont usuellement abordées et optimisées séparément les unes des autres. Le risque est naturellement que les erreurs s’accumulent le long de cette séquence de traitements. Ainsi, des erreurs précoces dans les calculs des alignements mot-à-mot viennent bruiter le processus d’extraction des couples de segments appariés et biaiser les calculs de scores afférents.
Pour pallier ce problème, les auteurs de (Liu et al., 2009) proposent d’extraire davantage d’informations de la phase d’alignement des mots, sous la forme d’une matrice d’alignements pondérés, qui représente de manière compacte un ensemble d’alignements de mots potentiels. Cette matrice est utilisée dans les étapes ultérieures de l’apprentissage. Dans une matrice pondérée, chaque lien d’alignement potentiel est nanti d’une probabilité qui mesure la confiance dans l’alignement de ces deux mots. Dans (Liu et al., 2009), ces probabilités sont estimées à partir du calcul des n-meilleurs alignements de mots tels que produits par les modèles d’alignement standards. À l’aide de cette technique, ces auteurs parviennent à améliorer de façon modeste leurs systèmes de traduction automatique. Une des limites de cette approche est toutefois l’utilisation d’une liste de n-meilleurs, qui ne représente que très imparfaitement la diversité et la variabilité des alignements de mots potentiels, et conduit à des mauvais estimateurs des probabilités a posteriori des liens d’alignement.
Dans ce travail, nous soutenons qu’une meilleure estimation des probabilités des liens d’alignement est susceptible de donner lieu à de meilleurs modèles. Nous étudions donc une méthode alternative pour réaliser cette estimation, fondée sur des modèles discriminants pour l’alignement de mots (Ayan & Dorr, 2006; Tomeh et al., 2010, 2011) et analysons les performances qu’elles permettent d’obtenir. La principale contribution de ce travail est donc de nature empirique : en comparant différentes manières de calculer et d’exploiter ces matrices d’alignement pondérées, nous montrons qu’il peut être bénéfique, en particulier quand les données d’apprentissage du modèle de traduction sont réduites, de prendre en compte l’information contenue dans ces matrices, au-delà du meilleur alignement mot-à-mot.
Cet article est organisé comme suit. Après avoir brièvement posé le cadre de la construction du modèle de traduction dans l’approche standard, nous présentons à la section 2 les principes de construction et d’exploitation de matrices d’alignements pondérées. Nous introduisons, à la section 3 une approche alternative permettant d’estimer directement la matrice d’alignement pondérée. Les résultats expérimentaux sont ensuite décrits à la section 4. Enfin, nous explicitons le positionnement de notre approche par rapport aux travaux existants, avant de conclure et d’évoquer diverses pistes vers lesquelles nous comptons nous orienter dans le futur.
2     Matrices pondérées pour la construction de modèles de traduction 
Pour un système de traduction à base de segments (Zens et al., 2002), le modèle de traduction est la source de connaissance principale qui établit une correspondance entre les deux langues (source et cible). Son rôle est de guider la construction, pour chaque phrase source, d’un ensemble d’hypothèses de traduction en langue cible. L’unité de traduction est le segment, qui correspond à un groupe de mots contigus. L’association entre un segment source et une traduction possible en cible forme un bi-segment. Notons qu’il est possible qu’un segment admette plusieurs traductions alternatives, donnant lieu à plusieurs bi-segments partageant le même segment source. Afin de faire un bon usage de ces bi-segments, il est nécessaire de leur associer des mesures, par exemple statistiques, qui quantifient la confiance en l’association ainsi réalisée.
Dans la suite de cet article, nous utilisons les notations suivantes : un couple de phrases est désigné par (e, f ), où la phrase source f = f1 , ..., fi , ..., fI est une séquence de I mots et la phrase cible e = e1 , ..., ej , ..., eJ est une séquence de J mots. De plus, une sous-séquence de mots extraite d’une phrase sera notée fii12 = fi1 . . . fi2 et donc f = f1I .
2.1    Cadre général 
Les méthodes décrites dans la littérature pour construire le modèle de traduction peuvent se résumer par l’algorithme présenté dans la partie gauche de la figure 1. Le point de départ est un couple de phrases accompagné d’un alignement mot-à-mot représenté par une matrice d’alignement. Chaque cellule de cette matrice booléenne A = {ai,j : 1 ≤ i ≤ I, 1 ≤ j ≤ J} représente un lien 4   2e soumission à TAL E STIMATION D ’ UN MODÈLE DE TRADUCTION que les méthodes d’évaluation (sous-section 2.4) et la manière dont nous évaluerons les différents modèles.

1: POUR toutes les paires de phrases        (f1J , eI1 ) FAIRE j2 2:   POUR tous les segments fj1 FAIRE                                                      2.1. Définition Corpus parallèle : j2 i2                                  Un alignement mot-à-mot             entre pas  phrase une la glaceetau sa chocolat traduction. associe à chaque mot 3:       Construire l’ensemble des bi-segments EA = {fj1  , ei1 }                          de cette phrase un mot e : je n' aime de f : I do not likeUn la traduction.     alignement chocolate     iceregroupe cream . donc un ensemble de satisfaisant le jeu de contraintes CA                                             liens décrivant une relation de traduction entre mots. Il est possible qu’un mot n’ait pas de traduction directe, il est alors aligné sur un symbole spécial noté null.
4:       Trier EA selon la fonction fR                                                                                                                  Modèle d'alignements mot-à-mot Dans la suite de cet article, nous utilisons les notations suivantes : un couple de 5:       Appliquer le critère de sélection CS définissant l’en-                            phrases est désigné par e, f , où la phrase e = e1 , ..., ei , ..., eI est une séquence de I mots f : je et    = f1pas n' faime   , ...,la  , ..., fJau fj glace                   . e :de une séquence estchocolat             J mots.
I do  not like   alignementice Unchocolate       mot-à-mot cream .
semble EAS des bi-segments à extraire                                             d’un couple de phrases est représenté par une matrice d’alignement. L’élément (i, j) de la matrice est 1 si le ième mot de e est aligné avec le j ème mot de f et 0 sinon. La 6:       Assigner une fonction de compte fC à chaque bi-                                   e : I do1 not Figure         likeunchocolate donne       exemple de    icematrice   .
creamd’alignement       et des pas lienslaqui f : je n' aime            glace       associés. .
au chocolat lui sont j2 i2 segments (fj1   , ei1 ) de EAS Heuristique de symétrisation 7:     end POUR 8:   end POUR chocolat glace aime 9:   POUR chaque bi-segments extraite {(e, f )} FAIRE pas au Je n’ la 10:     Calcul des scores :                                                                                         cream ice fC (e, f )                                                                 chocolate φ(e|f ) =                      ,                                                           like not fi fC (e, fi )                                                             do length(e) 1                                           Figure 1. Exemple de matrice d’alignementExtraction lex(e|f, A) =                                                  w(ei |fj ),                                                                     entre une phrase          anglaise et et évaluation 
i=1 |{j : (i, j) ∈ A}|                                    une phrase française. Les termes non nuls des                de lasegments matrices sont tés par des carrés pleins. L’ensemble des liens associés à cette matrice est représenbilingues ∀(i,j)∈a {(1, 1), (2, 2), (2, 3), (3, 4), (4, 2), (4, 3), (6, 6), (6, 7), (7, 5), (8, 5), (9, 8)} où A désigne la matrice d’alignement, et w une probabi-                        glace au chocolat ||| chocolate ice cream |||0.82 0.21 0.81 0.49 2.72 Nous pouvons d’ores et déjà remarquer qu’une matrice d’alignement comporte lité de traduction lexicale (IBM1 ou fréquence relative).                           majoritairement des termes nuls : en première approximation, chaque mot de la phrase e est aligné avec un mot de la phrase f ; la matrice d’alignement comporte donc envi11: end POUR                                                                              ron min(I, J) éléments non nuls où I et J sont les tailles des deux phrases à aligner.
F IGURE 1 – Algorithme générique pour la construction du modèle de traduction et un exemple de son application fréquement utilisé d’alignement potentiel ; la variable binaire ai,j vaut 1 si le lien entre le ième mot de f et le j ème mot de e est actif, et 0 sinon.
Un jeu de contraintes CA permet de définir, parmi tous les bi-segments potentiellement contenus dans une paire de phrases, ceux qui sont « acceptables » ou cohérents avec la matrice d’alignement. Les contraintes apportées par les alignements de mots permettent l’énumération conjointe de toutes les segmentations de la paire de phrases avec tous les alignements de segments autorisés. Une fois cet ensemble de bi-segments identifié, il est possible de le trier (fR ) et de lui appliquer un critère de séléction CS afin d’éliminer les bi-segments qui semblent a priori les moins plausibles. La dernière étape concerne la valuation des bi-segments ainsi extraits. Les fonctions de valuation les plus communément utilisées sont : – la fréquence d’observation du segment e connaissant le segment f notée φ(e|f ) ainsi que le terme symétrique φ(f |e) ; – les poids lexicaux ou lexical weights dans les deux directions (lex(e|f, A) et lex(f |e, A)), qui utilisent, le plus souvent, les probabilités de traduction lexicale du modèle IBM1.
Ces fonctions sont définies dans l’algorithme détaillé sur la figure 1 (ligne 10).
L’instanciation standard de cet algorithme correspond aux travaux de (Zens et al., 2002; Koehn et al., 2003) (voir partie droite de la figure 1), qui se déduit du cadre général en utilisant les définitions suivantes : – CA représente des contraintes de cohérence qui s’appliquent à un alignement mots-à-mots symétrisé d’une paire de phrases. Ces alignements se déduisent des deux meilleures hypothèses données par le modèle IBM4 (une pour chaque direction de traduction), symétrisées par l’heuristique grow-diag-final-and (Koehn et al., 2003).
– La fonction de compte et celle de tri sont les mêmes : fR = fC = 1 – la contrainte CS est définie par un seuil portant sur la longueur relative des segments source et cible et permet de filtrer les bi-segments trop longs.
Les hypothèses simplificatrices utilisées dans l’approche standard permettent d’obtenir une procédure efficace et robuste ; elles soulèvent néanmoins quelques critiques. Tout d’abord, le choix du modèle IBM4 pose problème puisque sa complexité interdit d’utiliser des procédures exactes lors de l’inférence et du calcul des probabilités a posteriori de chacun des liens d’alignement.
Ainsi, les contraintes de cohérence des bi-segments portent sur des alignements qui ne sont pas forcément les meilleurs et pour lesquels les approximations des probabilités a posteriori ne reflètent qu’imparfaitement la confiance du modèle. Ce dernier point implique naturellement le choix des fonctions de compte et de tri fC = fR = 1, puisqu’en l’absence de mesure de confiance, une décision binaire s’impose. Enfin, ces simplifications entraînent que l’exploration de la matrice d’alignement est restreinte à la sous-partie sélectionnée par les alignements IBM4 et ne prend pas en considération la plus grande partie de la matrice d’alignement.
NADI T OMEH , A LEXANDRE A LLAUZEN ET F RANÇOIS Y VON 
j1            j2 0,9 0,5 0,8 0,8 0,6 0,7 0,2 0,4 0,8 0,7 0,1                       0,3 0,1 0,4 0,8 0,2 0,3 0,1 0,1 0,6 0,3 0,8 0,2                                i1 0,1            0,4 0,8 0,7 0,2 0,1 0,9 0,1 0,3                 i2 
0,4 0,5 0,6 0,5 ,                                                             0,9 0,4 0,8 0,8 
,                                                                     0,8 1,0 
F IGURE 2 – Illustration du calcul des comptes fractionnaire pour un bi-segment donné. Dans cet exemple, le calcul des comptes fractionnaires se fait de la manière suivante : fC (fjj12 , eii21 ) = α(j1 , j2 , i1 , i2 ) × β(j1 , j2 , i1 , i2 ).
2.2    La matrice d’alignement pondérée 
Dans (Liu et al., 2009), les auteurs proposent d’augmenter le nombre des alignements mot-à-mot qui sont impliqués dans l’estimation des modèles de traduction et introduisent, à cet effet, la notion de matrice d’alignement pondérée : Ap = {p(ai,j |e, f ) : 1 ≤ i ≤ I, 1 ≤ j ≤ J}. Dans cette matrice, chaque lien d’alignement est pondéré par sa probabilité a posteriori p(ai,j |e, f ). Ces probabilités sont calculées à partir des n-meilleurs alignements symétrisés proposés par le modèle IBM4. Partant de cette matrice, l’algorithme représente à la figure 1 est modifié de la manière suivante : – Les contraintes de cohérence CA stipulent qu’un bi-segment est acceptable si au moins un lien d’alignement ai,j à l’intérieur du bi-segment est tel que p(ai,j |e, f ) est supérieur à un certain seuil.
– Les fonctions de compte fC = fR prennent en compte le caractère non-déterministe des liens d’alignement de la manière suivante.
Pour un bi-segment fC (fjj12 , eii21 ) : 
fC (fjj12 , eii21 ) = α(j1 , j2 , i1 , i2 ) × β(j1 , j2 , i1 , i2 ) avec                                     (1) α(j1 , j2 , i1 , i2 ) = 1 −                                 p¯(ai,j |e, f ),                                    (2) (j,i)∈in(j1 ,j2 ,i1 ,i2 ) 
β(j1 , j2 , i1 , i2 ) =                                p¯(ai,j |e, f )                                          (3) (j,i)∈out(j1 ,j2 ,i1 ,i2 ) où p¯(ai,j |e, f ) = (1 − p(ai,j |e, f )), le coefficient α correspond à la confiance accordée au lien à l’intérieur (in) du bi-segment et β quantifie la masse totale de probabilité des liens situés à l’extérieur (out) de ce bi-segment. L’estimation de cette fonction est illustrée à la figure 2.
Avec ces nouvelles définitions, l’évaluation des bi-segments doit être modifiée pour également prendre en compte les probabilités des alignements. La fonction φ ne nécessite pas de modification, puisqu’elle utilise la fonction fC , qui a été redéfinie. En revanche, les poids lexicaux sont maintenant définis comme suit : |e|                                                                                              |f | 
lex(e|f, Ap ) =                                                            w(ei |fj )p(ai,j |e, f ) + w(ei |f0 )           p¯(ai,j |e, f ) .   (4) i=1 {j|p(ai,j |e, f ) > 0}                                                                    j=1 ∀j:p(ai,j |e,f )>0 L’une des hypothèses explorée dans notre travail est que les gains modestes obtenus par (Liu et al., 2009) sont dus à la méthode utilisée pour estimer cette matrice pondérée, qui s’appuie sur un petit ensemble d’alignements calculés par le modèle IBM4. En E STIMATION D ’ UN MODÈLE DE TRADUCTION 
effet l’échantillonnage des alignements en ne considérant que les n-meilleures hypothèses des modèles IBM4 (n = 10 en pratique) revient à considérer qu’un sous-ensemble qui ne contient que peu de variation et beaucoup de redondance. Ainsi, l’exploration de la matrice d’alignement est par construction très limitée et l’estimation approximative. Par ailleurs, le calcul de la matrice d’alignement s’appuie sur une procédure ad hoc de recombinaisons des probabilités a posteriori des alignements initialement calculés séparément pour chaque direction de traduction.
L’alternative que nous proposons d’explorer consiste à estimer cette matrice en utilisant une modélisation directe de la probabilité d’un lien d’alignement en utilisant des modèles conditionnels exponentiels qui seront décrits à la section 3.
3    Modélisation de la matrice d’alignement Un alignement mot à mot entre une phrase source, et sa traduction (la phrase cible) regroupe un ensemble de liens décrivant une relation de traduction entre mots. Ainsi, prédire la matrice d’alignement peut être envisagé comme un problème de classification superviséé pour des données structurées. Lorsque des données étiquettées sont disponibles, la solution proposée dans (Ayan & Dorr, 2006; Tomeh et al., 2010, 2011) consiste à estimer de manière indépendante la probabilité de chaque lien dans la matrice à l’aide d’un modèle de régression logistique défini par : 
p (y|x) =        exp          λk fk (y, x) ,                                          (5) Z(x) k=1 où y désigne la variable aléatoire binaire qui indique si un lien est actif, x l’observation, Z(x) le facteur de normalisation, (fk )K k=1 définit un ensemble de fonctions caractéristiques, et (λk )K k=1 les poids associés. Dans l’équation (5), l’observation x désigne la paire de phrases augmentée de son étiquetage morphosyntaxique et des liens d’alignement produits par les modèles génératifs.
Cette formulation du problème permet de modéliser directement chaque cellule de la matrice d’alignement. Mais elle peut être également perçue comme une manière de fusionner différents alignements d’une paire de phrases. Cette approche permet donc également de remplacer l’étape heuristique de symétrisation, nommée grow-diag-final-and (Koehn et al., 2003) dans l’approche standard, par un modèle d’apprentissage statistique pouvant prendre en compte un nombre arbitraire d’alignements en entrée.
Estimer ce modèle à partir d’exemples demande néanmoins de prendre en considération le caractère très creux de la matrice d’alignement, conséquence du fait qu’une forte majorité de liens sont inactifs. La tâche de classification considérée est donc très déséquilibrée. Afin d’éviter d’apprendre un classifieur trop biaisé en faveur de la prédiction de liens inactifs, l’ensemble des liens à étiqueter peut être au préalable réduit à un sous-ensemble de la matrice. Pour définir ce sous-ensemble, les modèles génératifs classiques sont utilisés (modèles de Markov cachés et/ou IBM4 dans les deux directions) : tout lien qui n’apparait pas dans un des alignements génératifs est considéré comme inactif ; les autres liens sont évalués par le modèle de classification. Dans ce cadre, les alignements génératifs sont utilisés pour réduire l’espace de recherche et permettent de limiter l’effet potentiellement néfaste de données déséquilibrées (Ayan & Dorr, 2006; Elming & Habash, 2007).
Ce modèle est utilisé pour estimer la matrice pondérée d’alignement Ap décrite à la section 2.2. Le classifieur supervisé estime donc la probabilité p(ai,j |e, f ) pour chaque cellule de la matrice.
Apprentissage L’estimation des paramètres du modèle (les λk dans l’équation (5)) est faite de manière à maximiser la vraisemblance conditionnelle régularisée à partir d’un corpus d’entraînement. La régularisation utilisée est connue sous le nom d’ elasticnet (Zou & Hastie, 2005) et combine un terme de régularisation 1 , qui aide à sélectionner les fonctions caractéristiques les plus utiles et ainsi réduire la taille du modèle, et un terme de régularisation 2 , qui garantit que le Hessien de la fonction objectif n’est jamais trop proche de zéro, et permet ainsi d’éviter les problèmes d’instabilité numérique. Ce choix de régularisation nous permet d’envisager de nombreuses fonctions caractéristiques, sachant que certaines d’entre elles seront éliminées lors de l’entraînement car jugées inutiles.
Les caractéristiques Les fonctions caractéristiques utilisées pour le classifieur sont décrites en détail dans (Tomeh et al., 2010) et reprennent en partie celles proposées par (Ayan & Dorr, 2006). Elles prennent en compte les multiples sources d’informations : la paire de phrases augmentée de son étiquetage morphosyntaxique et les liens d’alignement produits par les différents modèles génératifs considérés. Ainsi, pour un lien d’alignement donné, ces fonctions binaires indiquent par exemple : l’association entre les mots source/cible et de même pour les étiquettes morphosyntaxiques associées ; quel modèle génératif propose ce lien comme actif NADI T OMEH , A LEXANDRE A LLAUZEN ET F RANÇOIS Y VON 
ainsi que le nombre total de modèles génératifs proposant ce lien comme actif ; combien de liens sont proposés par les modèles génératifs dans le voisinage ; la fertilité du mot source (et resp. du mot cible) considérant l’ensemble des alignements d’entrée ; l’écart du lien à la diagonale afin de favoriser ou non les alignements monotones ; la distance du lien avec le mot aligné le plus proche (en source et en cible) afin de caractériser si ce lien est isolé des autres.
À ces caractéristiques s’ajoutent celles que nous allons décrire. Une première famille de fonctions caractéristiques décrit les mots source et cible relatifs à un lien d’alignement (i.e une case de la matrice) : – Probabilité de traduction lexicale pour le couple de mots utilisé : p(fi |ej ) et p(ei |fj ) estimées par le modèle IBM1.
– La fréquence des mots source et cible ainsi que leur ratio.
– Un test sur tous les préfixes et suffixes de longueur 3.
– La similarité entre les mots source et cible calculée par la distance d’édition. Cette caractéristique tente de capturer la propension qu’ont les noms propres à être traduits de manière similaire, comme par exemple : SdAm Hsyn et Saddam Hussein.
– Un test portant sur l’égalité entre les mots source et cible.
– Un test indiquant si l’un des mots est une ponctuation associé avec un mot qui n’est pas une ponctuation.
Nous avons également définit un ensemble de fonctions caractéristiques permettant de décrire la structure de la matrice et les liens qui la composent. En plus des fonctions décrites dans (Tomeh et al., 2010), nous ajoutons la fonction qui indique si un lien d’alignement implique un mot dupliqué dans l’une des phrases. Cette caractéristique permet de pallier une faible modélisation de la distorsion.
Par exemple le mot arabe fy peut apparaître plusieurs fois dans une même phrase et être ainsi toujours aligné avec le même mot in en cible. Cette fonction retourne la distance du lien considéré à la diagonale.
4        Expériences 
Pour évaluer les différentes approches, nous utilisons la tâche de traduction de l’arabe vers l’anglais de l’évaluation NIST MT’09.
Nous comparons quatre méthodes d’estimation de la matrice pondérée : l’approche standard qui utilise les modèles d’alignement IBM4 et les heuristiques d’extraction et de valuation usuelles ; la méthode décrite dans le premier article sur les matrices pondérées (Liu et al., 2009) ; le système PostCAT (Graça et al., 2010) (décrit brièvement à la section 4.1) ; et l’estimation directe de la matrice via un modèle de régression logistique. Le système de traduction utilisé est M OSES(Koehn et al., 2007), un outil sous licence libre.
4.1       Corpus et outils 
Pour entraîner le modèle logistique, nous avons utilisé Wapiti (Lavergne et al., 2010) 1 , avec comme corpus d’apprentissage et de développement les données alignées manuellement du corpus IBMAC (Ittycheriah et al., 2006), contenant respectivement 10 000 et 663 paires de phrases. Nous avons construit 2 sous-ensembles, de taille différente, de données parallèles pour entraîner le système de traduction, afin d’évaluer l’impact du volume de données disponibles sur les résultats obtenus. Ces deux corpus ont été constitués à partir des données autorisées dans la tâche contrainte de l’évaluation NIST MT’09. Elles sont toutes disponibles via le Linguistic Data Consortium 2 .
Nous avons ainsi défini 2 tâches, l’une avec un corpus parallèle de 30 000 phrases (30k) et l’autre avec 130 000 phrases (130k). Les systèmes de traduction sont construits avec M OSES 3 en utilisant la configuration par défaut. Les paramètres de ces systèmes sont optimisés de manière usuelle avec l’outil MERT (Minimum Error Rate Training) avec comme données de développement le corpus NIST MT’06 contenant 1 800 phrases arabes et 4 traductions anglaises. Les traductions produites sont évaluées avec la métrique BLEU (Papineni et al., 2002) sur les données d’évaluation NIST MT’08, qui contiennent 1 400 phrases et 53k mots.
Pour le système PostCAT 4 et l’extraction des unités de traduction 5 , nous avons utilisé les outils libres disponibles sur la toile. Enfin les modèles de langue cible ont été appris avec la boîte à outils SRILM 6 en utilisant toutes les données monolingues autorisées dans le cadre de l’évaluation NIST MT’09 (pour plus de détails, on se reportera à (Allauzen et al., 2009)).
La partie anglaise des données est pré-traitée de manière classique (les méthodes utilisées sont décrites dans (Allauzen et al., 2009)).

1.   http ://wapiti.limsi.fr/ 2.   La description complète est disponible à l’adresse http ://www.itl.nist.gov/iad/mig/tests/mt/2009/ 3.   http ://www.statmt.org/moses/ 4.   http://www.seas.upenn.edu/~strctlrn/CAT/CAT.html 5.   http://www.nlp.org.cn/~liuyang/wam/wam.html.
6.   http://www-speech.sri.com/projects/srilm/.
E STIMATION D ’ UN MODÈLE DE TRADUCTION 
Pour la partie arabe, toutes les phrases sont analysées et segmentées avec l’outil MADA+TOKAN 7 . Nous avons utilisé le schéma de segmentation D2 afin de tenir compte de la morphologie riche de l’arabe et ainsi segmenter les mots arabes en des unités qui correspondent approximativement aux mots anglais.
4.2   Construction des modèles de traduction 
Dans la section 2, nous avons décrit un algorithme générique pour la construction d’un modèle de traduction. Cet algorithme fonctionne en trois étapes séparées : construction des matrices d’alignement pondérées, extraction puis évaluation des bi-segments. Nous allons maintenant évaluer l’impact de ces trois étapes sur les résultats en traduction automatique.
Pour la première étape, nous expérimentons deux manières de construire les matrices pondérées : (i) la méthode standard qui ne considère que les meilleurs alignements (ii) la matrice pondérée par les probabilités qui est utilisée dans le processus d’extraction et de valuation.
Notons qu’il est possible de passer de la configuration (ii) à (i) par un simple seuillage sur les probabilités. Dans toutes nos expériences, nous utilisons un seuil de 0, 5. Ainsi, pour chaque modèle d’alignement, deux types de systèmes sont construits : standard (configuration (i)) et WAM pour la matrice pondérée (configuration (ii) ). Le corpus de référence IBMAC contient également un jeu de test qui est utilisé pour calculer le taux d’erreur d’alignement (ou AER, pour Alignment Error Rate).
Les deux autres étapes (extraction et valuation des bi-segments) dépendent du mode de construction de la matrice d’alignement.
Dans le cas standard, les bi-segments sont extraits et évalués selon les heuristiques décrites à la section 2.1. Lorsque l’on utilise des matrices pondérées, nous utilisons les méthodes d’extraction et de valuation décrites à la section 2.2, qui prennent en compte la probabilité des liens d’alignement. Pour cette dernière approche, seuls les bi-segments dont la probabilité est supérieure à un seuil sont conservés. Ceci permet, comme le préconisent les auteurs de (Liu et al., 2009), de restreindre le nombre de bi-segments qui sont extraits. De plus, comme cela est fait dans l’approche standard, les bi-segments comprenant un segment de longueur supérieur à 7 sont également rejetés. Comme il est d’usage, les performances en traduction automatique sont évaluées par la métrique BLEU (Papineni et al., 2002).
4.3   Modèles d’alignement mot-à-mot 
En plus des deux méthodes de construction du modèle de traduction, nous avons également considéré plusieurs modèles d’alignement mot-à-mot, que nous allons décrire brièvement.
MGIZA++ 8 propose une implémentation efficace et parallèle (Gao & Vogel, 2008) des modèles génératifs les plus utilisés : les modèles IBM1 à IBM4 (Brown et al., 1993) et HMM (Vogel et al., 1996). Ces modèles sont utilisés par la suite pour construire des modèles de traduction selon la configuration standard et pour entraîner notre système d’alignement discriminant (voir section 3).
N-best WAM construit la matrice pondérée en effectuant une moyenne des occurences des liens d’alignement à partir des nmeilleures séquences d’alignement produites par le modèle IBM4. Cette méthode correspond à l’article original sur les matrices pondérées (Liu et al., 2009). Comme ces auteurs, nous avons utilisé la valeur n = 10.
PostCAT (Posterior Constrained Alignment Toolkit) propose une implémentation des modèles HMM permettant d’injecter des contraintes lors de l’apprentissage via l’algorithme EM. Ces contraintes portent sur les probabilités a posteriori des variables latentes (Graça et al., 2010) et permettent de corréler les deux directions d’alignement. Deux types de contraintes simples (symmétrie et bijectivité) permettent au modèle HMM d’atteindre des performances comparables au modèle IBM4. Le fait d’utiliser des modèles HMM permet de pouvoir calculer de manière exacte et efficace les probabilités a posteriori et ainsi construire la matrice pondérée en considérant l’ensemble des liens d’alignement. Dans cet article, nous avons utilisé la boite à outils Geppetto 9 (Ling et al., 2010), une implémentation de PostCAT et des matrices d’alignement pondérées.

7. http ://www1.ccls.columbia.edu/ cadim/MADA.html 8. http ://geek.kyloo.net/ 9. http ://code.google.com/p/geppetto/ NADI T OMEH , A LEXANDRE A LLAUZEN ET F RANÇOIS Y VON 
MaxEntWA est le système décrit à la section 3. Il s’agit d’un classifieur MaxEnt qui prédit pour chaque lien de la matrice sa probabilité a posteriori.
Exception faite du modèle noté MGIZA++, il est possible pour tous les modèles d’extraire et de valuer les bi-segments selon les deux méthodes. Pour appliquer la méthode (i), nous avons appliqué pour toutes les expériences un seuil de 0, 1 comme les auteurs de (Liu et al., 2009).
4.4    Résultats 
Les résultats expérimentaux pour les différentes configurations et les différents modèles d’alignement sont rassemblés dans le tableau 1. Examinons pour commencer, la partie 30k du tableau qui correspond aux expériences où M OSES a été entraîné sur un corpus de 30 000 phrases parallèles. La partie MGIZA++ présente les résultats obtenus en utilisant l’approche standard : utilisation des meilleures hypothèses d’alignement IBM4 symmetrisés pour extraire et valuer les bi-segments via les heuristiques usuelles (Koehn et al., 2003). Ainsi sur la tâche 30k, le système standard obtient un score BLEU de 35,9. La partie 10-best WAM correspond au matrice pondérée où les probabibilités a posteriori sont estimées à partir des 10 meilleurs alignements de IBM4. Cette approche permet d’obtenir un faible gain de 0,3 points BLEU par rapport à l’approche standard, soit (36,2). Ce résultat est cohérent avec ceux publiés dans (Liu et al., 2009).
La partie PostCAT introduit par rapport aux travaux de (Liu et al., 2009) l’utilisation des modèles HMM pour les alignements de mot et donc la possibilité d’estimer les probabilités a posteriori de manière exacte pour l’ensemble de la matrice. Cet apport permet d’augmenter le BLEU de manière significative : de 35,9 à 36,9 ou 37,0 selon la variante du modèle HMM utilisée. Enfin la partie MaxEntWA présente les résultats obtenus en utilisant un modèle exponentiel pour prédire la matrice d’alignement. Les résultats montrent un gain en BLEU supplémentaire et conséquent : 1,5 points par rapport à l’approche standard et 0,5 points par rapport à l’approche PostCAT. Notons également, que même si les méthodes standard d’extraction et de valuation sont utilisées, les matrices d’alignements engendrées par PostCAT et MaxEntWA permettent d’obtenir de meilleurs résultats et que MaxEntWA est à nouveau la méthode donnant le meilleur résultat.
Sur la tâche 130k (M OSES est entrainé sur 130 000 phrases parallèles), nous observons les mêmes tendances, avec cependant des gains en BLEU moindres. Notons que le gain modeste obtenu avec la méthode 10-best pour estimer la matrice pondérée est similaire à celui obtenu sur la tâche 30k. Pour les autres méthodes de calcul de la matrice pondérée, les gains restent significatifs, bien que moins importants. De nouveau, nous pouvons observer que le calcul de la matrice d’alignement avec le modèle de régression logisitique (MaxEntWA) permet d’obtenir de meilleurs résultats en termes de score BLEU.
La colonne PT du tableau 1 indique la taille du modèle de traduction en nombre de bi-segments extraits. Nous observons, tout naturellement, que quand on considère l’intégralité de la matrice pondérée (PostCAT et MaxEntWA), la taille du modèle de traduction augmente considérablement, puisqu’elle se trouve multipliée par plus de 4, alors même que le seuil de filtrage est resté constant à 0,1.
Le risque était, en multipliant les entrées du modèle de traduction, d’ajouter un bruit pouvant affecter le comportement global du système. Toutefois, il apparaît que la valuation des bi-segments par les probabilités (voir la section 2.2) est un moyen effectif pour filtrer les bi-segments les moins utiles lors de l’étape de traduction.
Ainsi, l’amélioration de la valuation des bi-segments a un impact significatif sur les résultats en BLEU. Si cette amélioration peut être imputée en partie à l’utilisation des matrice pondérée, la colonne AER (Alignment Error Rate) montre que cette amélioration peut provenir également d’alignements mot-à-mot de meilleure qualité. Partant d’un l’AER obtenu avec les modèles IBM4 symétrisés d’une valeur de 25,0%, on note tout d’abord que l’usage des 10-meilleurs alignements ne permet pas d’améliorer la qualité intrinsèque des alignements. En revanche, l’utilisation d’un modèle plus approprié tel que PostCAT entraîne une amélioration sensible des alignements, avec un AER de 22,5%. Cette tendance est encore plus affirmée avec la méthode MaxEntWA, qui introduit dans le processus des alignements de qualité nettement accrue, puisque la réduction absolue de l’AER est de plus de 10 points.
Globalement, les résultats expérimentaux montrent que l’utilisation de la matrice pondérée pour extraire et valuer les bi-segments permet d’améliorer les performances des systèmes de traduction, quand cette méthode est associée à un mode de calcul pertinent pour les valuations de la matrice pondérée. Ce dernier point recouvre d’une part la manière dont sont calculées les probabilités d’alignement, et d’autre part la fraction de cette matrice qui est effectivement explorée. La différence de résultats entre les deux tâches (30k et 130k) suggère que l’utilisation d’un modèle de régression logistique pour estimer la matrice pondérée conduit à des gains bien plus importants sur la petite tâche (30k). Une explication de cette différence est que cette approche permet, lorsque l’on dispose de peu de données parallèles, d’extraire plus de bi-segments : lorsque les données manquent pour estimer le modèle de traduction, il est en effet important de pouvoir malgré tout engendrer un grand nombre de bi-segments potentiels. De surcroît, on note que la valuation par des probabilités permet effectivement de limiter, au moment du décodage, les effets de l’introduction d’entrées bruitées dans la table de traduction.
E STIMATION D ’ UN MODÈLE DE TRADUCTION Tâche de traduction :                         30K                                             130K Construction du MT :                 Standard(i)         WAM(ii)                      Standard(i)         WAM(ii) Alignement                   AER      BLEU       PT    BLEU       PT         AER      BLEU       PT     BLEU       PT HMM                 28,4     35,0      3,6      -         -        26,8      39,2      9,7       -        MGIZA++ IBM4                25,0     35,9      2,4      -         -        23,3      40,2      6,5       -        10-best             IBM4                24,9     35,8      2,4     36,2     3,0        23,3      40,0      6,6     40,4      8,5 Bijective             22,5     36,6      3,3     36,9     10,2       20,5      40,1      9,1     40,6      29,5 PostCAT Symmetric              22,5     36,7      2,9     37,0     10,7       20,8      40,2      8,5     40,4      30,2 HMM                    17,6     36,9      6,7     37,5     11,7       16,4      40,5     17,7     40,8      30,0 MaxEntWA          IBM4                   15,6     37,2      5,5     37,5      9,6       14,3      41,0     14,5     41,1      25,0 HMM+IBM 1,3,4             14,7     37,1      5,2     37,9      8,6       13,9      40,8     13,4     41,1      22,2 
TABLE 1 – Comparaison de 4 modèles d’alignement (MGIZA++, 10-best, PostCAT and MaxEntWA) et de leurs interactions avec la méthode d’extraction et de valuation de la table de traduction en termes de taux d’erreur d’alignement (AER), de score BLEU et de la taille de la table de traduction exprimée en millions de bi-segments (PT). Les deux méthodes de construction du modèle de traduction (MT) sont l’approche standard (standard) et celle utilisant les matrices pondérées (WAM). Deux tailles de données parallèles d’apprentissage sont considérées (30K et 130K).
5    Discussion 
De nombreux travaux récents se sont intéressés aux méthodes d’extraction d’unités de traduction à partir de corpus parallèles. Que ce soit dans le cadre des systèmes hiérarchiques ou à base de segments, le processus d’extraction (Koehn et al., 2003; Chiang, 2007) repose sur les matrices d’alignement mot-à-mot construites à partir des modèles d’alignement IBM4 (Brown et al., 1993) symétrisés.
Comme nous l’avons évoqué à la section 2.1, ce choix de la première étape se justifie par un souci d’efficacité puisqu’il restreint considérablement l’espace des unités qui sont explorées, puis sélectionnées. Néanmoins, ce choix favorise la propagation d’erreurs dues à des décisions (d’accepter ou de rejeter des liens d’alignement) qui sont prises trop tôt dans le processus, sans qu’il soit de surcroit possible d’affecter de réels scores de confiance à ces décisions.
Lorsqu’il s’agit d’étendre l’espace des unités qui sont explorées, la première difficulté est la complexité qui résulte de l’énumération puis de la valuation de toutes les unités de traduction possible. Ainsi, une partie des travaux récents s’intéresse à l’élaboration d’une représentation efficace. Dans (Mi & Huang, 2008), le processus d’extraction des règles pour un système hiérarchique est étendu en considérant l’ensemble composé des n-meilleurs arbres d’analyse syntaxique au lieu de tenir compte uniquement du meilleur. Afin de représenter puis de manipuler efficacement ces n-meilleurs arbres, les auteurs utilisent une représentation efficace (packed forest) (Billot & Lang, 1989) ayant également démontré son utilité (Galley et al., 2006; Wang et al., 2007) en traduction automatique.
De manière similaire, les n-meilleurs alignements peuvent être utilisés afin d’enrichir la matrice d’alignement, que ce soit pour extraire les bi-segments (Xue et al., 2006), ou les règles d’un système hiérarchique (Venugopal et al., 2008). Dans ce dernier article comme dans (Mi & Huang, 2008), les auteurs définissent une distribution de probabilité sur les alignements à partir des n-meilleurs alignements et des n-meilleurs arbres d’analyse syntaxique. Cette approche par échantillonage permet aux auteurs d’introduire des comptes fractionnaires pour les règles extraites et ainsi de pouvoir estimer le modèle de traduction.
Ce recours à l’échantillonnage pour l’inférence des probabilités a posteriori des d’alignement se justifie par la complexité d’inférence du modèle IBM4. Il existe en revanche, pour les modèles plus simples, tels que ceux qui s’inspirent des modèles de Markov cachés (souvent désignés de manière générique sous le nom de « modèle HMM ») (Vogel et al., 1996) ou pour le modèle IBM1 (Brown et al., 1993), des algorithmes d’inférence exacts et efficaces (Venugopal et al., 2003; Deng & Byrne, 2005). Une des limitations du modèle HMM est son absence de modélisation de la fertilité. Pour pallier cette limitation, les auteurs de (Deng & Byrne, 2005) définissent un HMM permettant d’aligner des mots avec des segments qui rivalise en termes de performances avec le modèleIBM4, tout en préservant la possibilité d’un calcul exact des probabilités a posteriori des alignements de mots et qui s’étend au calcul de distributions a posteriori des segments ou des règles. Les expériences montrent que cette approche améliore significativement le processus d’extraction d’unités de traductions pour les systèmes à base de segments (Deng & Byrne, 2005) et hiérarchiques (de Gispert et al., 2010).
L’introduction des matrices pondérées (Liu et al., 2009) que nous décrivons à la section 2 peut être considérée comme l’adaptation NADI T OMEH , A LEXANDRE A LLAUZEN ET F RANÇOIS Y VON 
des packed forests des systèmes hiérarchiques au systèmes à base de segments : une exploration plus exhaustive de la matrice d’alignement, l’usage des probabilités des alignements de mots pour dériver des scores de confiance sur les bi-segments extraits.
Pour ce dernier point, les auteurs s’inspirent d’ailleurs des travaux de (Mi & Huang, 2008).
Comme mentionné à la section 2, un des problème des matrices pondérées est l’estimation des probabilités a posteriori des alignements. Dans (Liu et al., 2009), cette estimation est faite en échantillonnant les n-meilleurs alignements des modèles IBM4, alors que dans (Deng & Byrne, 2005; de Gispert et al., 2010; Ling et al., 2010) le modèle HMM ou une de ses variante est utilisé pour les estimer de manière exacte. Cependant, dans ce dernier type d’approche, il est encore nécessaire de fusionner les alignements correspondant aux deux directions (un modèle d’alignement de source vers cible et réciproquement). Les solutions envisagées semblent peu satisfaisantes : soit la fusion est heuristique et consiste simplement à prendre la moyenne arithmétique des distributions a posteriori (Graça et al., 2010; Ling et al., 2010) ; soit de manière beaucoup plus coûteuse, deux systèmes de traduction indépendants sont utilisés utilisant chaque modèle HMM, la fusion se fait alors sur les treillis engendrés par chaque système (de Gispert et al., 2010).
Dans cet article, nous introduisons donc une extension du travail de (Liu et al., 2009) en proposant une nouvelle méthode de construction de la matrice d’alignement. Pour cela, nous proposons d’utiliser un classifieur au maximum d’entropie décrit dans (Ayan & Dorr, 2006; Tomeh et al., 2010, 2011). Cette approche permet en effet de calculer directement la matrice pondérée sans avoir recours ni à une fusion heuristique des distributions a posteriori, ni à une coûteuse étape de fusion de système. Faute de données étiquettées permettant de mettre en œuvre cette démarche, l’approche de (Graça et al., 2010) semble fournir des performances proches de nos meilleurs résultats.
6    Conclusion 
Dans cet article, nous avons abordé le problème de l’estimation des modèles de traduction à partir d’alignements mot-à-mot nondéterministes. En effet, dans l’approche considérée comme standard, les modèles de traduction sont estimés à partir d’alignements mot-à-mot grâce à des heuristiques d’extraction et de valuation. Bien que ces alignements mot-à-mot soient construits par des modèles probabilistes, les processus d’extraction et de valuation utilisent ces modèles comme produisant des alignements déterministes.
À la suite (Liu et al., 2009), la solution que nous avons envisagée lève cette limitation en considérant une matrice d’alignement pondérée, dans laquelle chaque lien d’alignement est valué par sa probabilité. Les premiers travaux dans cette direction étaient, selon nos hypothèses, limités par la méthode d’estimation de la matrice pondérée, et nous avons proposé une méthode permettant d’estimer directement cette matrice à l’aide d’une méthode de classification supervisée.
Afin de valider cette approche, nous avons effectué des expériences sur la tâche de traduction automatique de l’Arabe vers l’Anglais de l’évaluation NIST MT’09. Dans ce cadre expérimental, nous avons comparé 4 méthodes de construction du modèle de traduction, contrastant ainsi l’approche standard avec l’usage des matrices pondérées, et évaluant différents estimateurs de cette matrice.
Les résultats ont montré que l’usage des matrices pondérées impliquait une extraction plus importante de bi-segments et que leur valuation adaptée permettait au système de traduction d’obtenir de meilleurs résultats mesurés en terme de BLEU. En particulier, des gains significatifs (entre 2 et 0,9 point BLEU, selon la tâche considérée) ont été obtenus par notre méthode, qui semble la mieux à même de produire des alignements de bonne qualité (au sens de l’AER). Ces résultats nous ont permis de conclure que le choix de l’estimateur des matrices pondérés a un impact net sur les performances en traduction et que notre méthode est nettement plus pertinente que celles proposées dans les travaux antérieurs.
Contrairement aux heuristiques standard, notre méthode permet de contrôler et d’adapter le nombre de bi-segments extraits à la taille des données parallèles d’entraînement. Nous souhaitons donc à l’avenir explorer cet aspect. L’approche envisagée consiste à extraire le plus de bi-segments possibles et à travailler sur leur filtrage. L’intérêt de cette approche est que nous pensons ainsi limiter l’impact des erreurs commises par les modèles d’alignement. De plus, l’étape de filtrage peut se faire en prenant en compte l’utilité des bisegments lors de l’étape de traduction et ainsi ne pas se limiter à des tests statistiques qui ne prennent pas en compte la finalité des modèles de traduction. Des articles récents comme (Wuebker et al., 2010) montrent l’importance d’une valuation des bi-segments qui améliorerait les simples calculs de fréquences, et qui serait plus directement en rapport avec la finalité des modèles de traduction.
Remerciements 
Ces travaux ont été en partie financé par l’agence OSEO dans le cadre du programme Quaero. Les auteurs tiennent à remercier Thomas Lavergne pour son aide précieuse concernant la mise en œuvre de Wapiti.
E STIMATION D ’ UN MODÈLE DE TRADUCTION 


Combinaison d’informations pour l’alignement monolingue 
Houda Bouamor Aurélien Max Anne Vilnat LIMSI-CNRS, Univ. Paris-Sud Orsay, F-91403, France {prénom.nom}@limsi.fr 
Résumé. Dans cet article, nous décrivons une nouvelle méthode d’alignement automatique de paraphrases d’énoncés. Nous utilisons des méthodes développées précédemment afin de produire différentes approches hybrides (hybridations). Ces différentes méthodes permettent d’acquérir des équivalences textuelles à partir d’un corpus monolingue parallèle. L’hybridation combine des informations obtenues par diverses techniques : alignements statistiques, approche symbolique, fusion d’arbres syntaxiques et alignement basé sur des distances d’édition. Nous avons évalué l’ensemble de ces résultats et nous constatons une amélioration sur l’acquisition de paraphrases sous-phrastiques.
Abstract.         In this paper, we detail a new method to automatic alignment of paraphrase of statements. We also use previously developed methods to produce different hybrid approaches. These methods allow the acquisition of textual equivalence from a parallel monolingual corpus. Hybridization combines information obtained by using advanced statistical alignments, symbolic approach, syntax tree based alignment and edit distances technique. We evaluated all these results and we see an improvement on the acquisition of sub-sentential paraphrases.
Mots-clés :         Paraphrase sous-phrastique, corpus parallèle monolingue, hybridation.

Keywords:           Phrasal paraphrase, monolingual parallel corpora, hybridization.
1    Introduction 
Le traitement de corpus monolingues et multilingues constitue un champ d’investigation très animé dans le domaine du traitement automatique des langues. Ils sont souvent constitués d’unités de texte ayant des liens sémantiques forts, une information qui peut être exploitée pour acquérir des équivalences entre des mots ou des groupes de mots et construire des ressources linguistiques importantes pour diverses applications. Ces resssources peuvent être utilisées par la suite pour extraire des réponses à des questions (Duclaye et al., 2003), par exemple, ou autoriser des formulations différentes en évaluation de la traduction automatique (Russo-Lassner .G & .P, 2005; Kauchak & Barzilay, 2006), ainsi qu’en génération, pour aider des auteurs à trouver des formulations plus adaptées (Max, 2008).
De nombreuses techniques ont été proposées pour l’acquisition de segments en relation de paraphrase. Ces techniques ont en commun d’être directement liées aux types de ressources sur lesquelles elles s’appliquent. Les plus nombreuses exploitent des corpus monolingues comparables disponibles en grandes quantités, et se fondent sur l’hypothèse que des unités linguistiques apparaissant de nombreuses fois dans des contextes similaires peuvent avoir la même signification. Restreindre les corpus utilisés à des textes comparables, sélectionnés sur la base d’un genre ou de thèmes communs, permet d’augmenter la probabilité que les correspondances obtenues seront effectivement valides grâce aux contextes plus restreints.
Peu de travaux ont, en comparaison, porté sur l’exploitation de corpus monolingues parallèles, constitués de phrases alignées en relation de paraphrase. Cela peut certainement s’expliquer par la faible disponibilité de telles ressources engendrée par le coût de leur construction. Mais elles présentent des caractéristiques qui en font les candidates les plus naturelles pour l’étude de la paraphrase sous-phrastique : les phrases parallèles étant issues de la volonté d’exprimer la même idée, les équivalences apprises apparaissent comme beaucoup plus fiables que celles extraites indirectement via des textes comparables ou des équivalences de traduction. En outre, le contexte de ces équivalences peut être extrait de façon directe, ce qui est particulièrement important pour caractériser les H OUDA B OUAMOR , AURÉLIEN M AX ET A NNE V ILNAT 
conditions de leur validité.
Ce travail porte sur l’acquisition de paraphrases sous-phrastiques depuis des corpus monolingues parallèles, et vise en particulier à extraire des paraphrases de qualité. Dans cet article, nous présentons D IST une nouvelle méthode symbolique optimisée pour l’alignement de bi-segments exploitant un corpus monolingue parallèle. Puis nous décrivons une approche hybride d’extraction de paraphrases sous-phrastiques par la combinaison d’informations issues de différentes techniques. Cet article est organisé comme suit : dans la section 2, nous passons en revue les travaux portant sur l’acquisition automatique de paraphrases puis nous détaillons, dans la section 3, le cadre expérimental de notre travail, l’approche suivie pour combiner des informations issues de différentes techniques et extraire des bi-segments à partir de corpus monolingues parallèles ainsi que les résultats obtenus. Nous terminerons par une description de nos prochains travaux (section 4).
2    Travaux précédents en acquisition de paraphrases 
L’acquisition de paraphrases peut être réalisées à l’aide de diverses méthodologies. Langkilde & Knight (1998) se sont basés sur les connaissances sémantiques de WordNet (Miller, 1995) pour exploiter les relations de synonymie entre termes et les utiliser ensuite lors de la génération de paraphrases. Cependant, ces ressources ne sont pas nécessairement disponibles dans toutes les langues et ne comportent que des équivalences textuelles au niveau des mots. C’est la raison pour laquelle de nombreux autres travaux se sont basés sur des corpus monolingues et multilingues parallèles ou comparables.
La majorité des travaux menés sur des corpus monolingues parallèles se basent essentiellement sur l’hypothèse de distributionnalité (Harris, 1954), selon laquelle les mots apparaissant dans le même contexte tendent à avoir des sens similaires. Cette hypothèse a été appliquée, par exemple, à des chemins dans des arbres de dépendance pour la découverte de règles d’inférence à partir de textes (Lin & Pantel, 2001). Barzilay & McKeown (2001) utilisent des informations contextuelles basées sur des similarités lexicales pour extraire des paraphrases à partir d’un ensemble de corpus alignés. De manière similaire, Pang et al. (2003) exploitent la structure syntaxique d’un ensemble de phrases issues de corpus parallèles monolingues pour construire de nouvelles paraphrases d’énoncés par fusion syntaxique et regénération. Ibrahim et al. (2003) présentent eux une méthode non supervisée d’acquisition de paraphrases qui consiste à extraire des paraphrases structurelles, ou des fragments d’arbres syntaxiques sémantiquement équivalents, à partir de corpus monolingues parallèles.
Puisque les corpus monolingues parallèles sont des ressources rares et difficiles à obtenir, d’autres techniques ont été implémentées en se basant sur des corpus monolingues comparables, corpus composés de textes dans la même langue partageant une partie du vocabulaire employé, ce qui implique généralement que les textes parlent d’un même sujet, durant la même période, afin d’obtenir des paraphrases. Notamment, certains travaux exploitent des corpus monolingues comparables, comme ceux de Deléger & Zweigenbaum (2009) dans le domaine médical visant la construction d’un corpus de paraphrases de segments opposant les langues de spécialité et de vulgarisation. Barzilay & Lee (2003) introduisent une technique d’alignement multi-séquence factorisant des phrases ayant la même structure syntaxique, extraites à partir d’un corpus comparable, sous forme de treillis contenant des équivalences locales. Quirk et al. (2004) proposent une approche consistant à apprendre un système de traduction statistique sur un corpus monolingue de phrases alignées automatiquement à partir d’un corpus comparable qui opère par reformulations locales.
Outre les corpus monolingues, des corpus multilingues parallèles ont été exploités pour l’extraction des paraphrases en se basant sur l’hypothèse que des segments partageant des traductions dans une autre langue peuvent être des paraphrases dans certains contextes. Bannard & Callison-Burch (2005) ont décrit une approche par pivot exploitant plusieurs corpus parallèles. De la même manière, Max (2009) utilise des traductions de segments en pivot pour produire des reformulations et sélectionner parmi celles-ci celles qui sont préférées par différents types de modèles. La majorité de ces approches s’attaque au problème d’acquisition de paraphrases d’énoncés complets.
Or, il est également intéressant de pouvoir extraire des reformulations pour des unités de texte plus petites à partir de plusieurs corpus quel que soit leur degré de parallélisme.
C OMBINAISON D ’ INFORMATIONS POUR L’ ALIGNEMENT MONOLINGUE 
3     Combiner des informations pour l’alignement 
Différentes approches peuvent être utilisées pour faire l’acquisition de paraphrases sous-phrastiques depuis des corpus monolingues parallèles (Bouamor et al., 2010). Outre l’amélioration individuelle de ces techniques, il est possible de parvenir à une amélioration des performances obtenues en exploitant utilement les résultats de chacune. Dans cette section, nous commençons par décrire le cadre expérimental dans lequel s’ancre notre étude sur l’alignement monolingue dans des paires de paraphrases, puis nous présentons brièvement quatre techniques que nous utilisons pour cette tâche. Nous décrivons ensuite un cadre de combinaison des résultats qu’elles produisent et détaillons les résultats de nos expériences.
3.1     Cadre expérimental 
Les paraphrases d’énoncés sont relativement rares à l’état naturel, car peu d’activités humaines en gardent la trace lorsqu’elles existent. En outre, certains types de réécritures, comme le résumé, altèrent de façon significative le contenu des textes. Des solutions pour l’acquisition de paraphrases ont cependant été proposées, par exemple à partir de corpus comparables (Dolan & Brockett, 2005) ou de traces d’éditions (Dutrey et al., 2010), mais l’identification de ce qui constitue des paraphrases acceptables reste une difficulté majeure. Une solution plus directe consiste à faire produire de telles paraphrases par des humains dans le cadre naturel d’une traduction où une même phrase est traduite plusieurs fois indépendamment. Le corpus MultiTrad (Bouamor, 2010) a été construit selon ce principe en obtenant des traductions vers le français d’extraits du corpus des débats parlementaire européen.
Pour l’étude présentée ici, nous avons sélectionné un corpus de développement issu de MultiTrad constitué de 50 énoncés traduits 4 fois de l’anglais vers le français. Pour chaque groupe de quatre paraphrases, la paraphrase la plus similaire en moyenne aux autres paraphrases a été identifiée et associée aux trois autres. Cette similarité est calculée par une valeur moyenne d’édition mesurée par TER (Translation Error Rate) (Snover et al., 2009). Les 150 paires de paraphrases obtenues ont alors été annotée au niveau des mots par 3 annotateurs à l’aide de YAWAT (Germann, 2008), un outil qui permet d’utiliser, au choix, une vue parallèle entre énoncés présentés sous forme de paragraphes ou de matrices d’alignement. Chaque paire a été annotée par un seul annotateur : Callison-Burch (2008) mentionne un accord inter-annotateur acceptable sur une telle tâche 1 , mais l’ensemble des annotations a par la suite été vérifié par le même annotateur. À partir des matrices d’alignement produites, l’ensemble des bi-segments de référence est extrait en respectant la contrainte suivante : tous les mots du segment contenu dans la première paraphrase sont alignés avec au moins un mot du segment de la seconde paraphrase et ne sont alignés qu’avec des mots de ce segment, et réciproquement.
Pour évaluer la performance de nos techniques d’alignement monolingue, nous utilisons l’approche PARAMETRIC (Callison-Burch et al., 2008), dans laquelle un ensemble de bi-segments (correspondant à des paires de paraphrases sous-phrastiques) de référence est comparé aux bi-segments produits par la méthode évaluée. La mesure PARAMETRIC se décompose en des valeurs usuelles de précision et de rappel, définies respectivement comme la proportion des candidats proposés appartenant à la référence et la proportion des éléments de la référence proposés, ainsi qu’en une F-Mesure combinant les deux à égalité. Notre évaluation portera sur un extrait du corpus de traductions multiples issus de la campagne CESTA 2 contenant 375 paires de paraphrases (comportant entre 15 et 25 mots) et obtenues par traduction de l’anglais vers le français. L’alignement de référence a été réalisé en suivant la même procédure que pour le corpus de développement avec 2 annotateurs. Notre étude a révélé un taux d’accord inter-annotateur global de 88,96% qu n’est plus, cependant, que de 67,35% lorsque les paraphrases "identité" ne sont pas prises en compte.
3.2     Techniques individuelles 
Nous avons implémenté dans ce travail quatre techniques, développées pour des besoins différents. Nous les avons choisies parce qu’elles opèrent à différents niveaux ce qui devrait permettre de tirer parti de leur complémentarité potentielle. La première est fondée sur l’apprentissage statistique d’alignements entre mots (M OT), et requiert 
1. Il faut cependant noter que les travaux de Callison-Burch (2008) portait sur des textes journalistiques en anglais et qu’un guide d’annotation avait été fourni aux annotateurs.
2. Corpus de la Campagne d’Evaluation de Systèmes de Traduction Automatique : http://www.elda.org/article125.html H OUDA B OUAMOR , AURÉLIEN M AX ET A NNE V ILNAT 
donc des quantités de données d’apprentissage en nombre relativement important. La seconde exploite des règles de description de variantes de termes et des connaissances a priori sur la variation lexicale (T ERME). La troisième utilise la structure syntaxique des énoncés pour mettre en correspondance des segments (S YNT), et requiert par conséquent un analyseur syntaxique. La quatrième, calcule une transformation au niveau des mots pour transformer une séquence de mots en une autre en mettant en jeu des opérations de transformation dont le coût est appris automatiquement (D IST). Une étude comparative des trois premières techniques a été faite dans (Bouamor et al., 2010). Elle a, en particulier, mis en évidence des différences de performance notables sur deux types de corpus parallèles monolingues obtenus par traductions multiples à partir d’une même langue d’une part, et de plusieurs langues d’autre part. Dans cet article, une nouvelle technique est introduite et utilisée de façon originale, et une combinaison efficace sous forme d’adaptation de cette dernière technique est proposée.
3.2.1   Approche fondée sur l’apprentissage d’alignements entre mots (M OT) 
La technique M OT consiste à apprendre des alignements entre mots en utilisant des modèles d’alignement statistique appliqués sur deux phrases parallèles, initialement conçus pour la tâche d’alignement bilingue entre mots en traduction automatique statistique. Une telle technique requiert typiquement des quantités de données importantes pour apprendre des alignements fiables 3 . Dans nos expériences, nous mettrons à disposition de M OT toutes les paires de paraphrases possibles (pour des groupes constitués de 4 paraphrases) afin d’améliorer ses capacités d’alignement, ce qui constitue pour elle un avantage car les autres techniques ne considèrent les paires de paraphrases qu’isolément (en d’autres termes, pour les autres techniques l’information acquise sur une paire de paraphrases n’est pas directement exploitée pour les alignements ultérieurs). Par ailleurs, ce type de technique fonctionne d’autant mieux que les phrases des corpus d’apprentissage utilisées sont parallèles, signifiant ici qu’un alignement mot à mot est facile à réaliser. Dans le cas bilingue, ce n’est évidemment pas le cas de langues très différentes, et dans le cas monolingue, nos expériences précédentes ont montré que M OT obtenait des résultats sensiblement meilleurs lorsque les paraphrases utilisées sont obtenues par traduction depuis une même langue.
Nous avons utilisé le programme G IZA ++ (Och & Ney, 2003) pour réaliser l’alignement entre mots et les heuristiques du système de traduction statistique M OSES (Koehn et al., 2007) pour extraire des bi-segments à partir des matrices d’alignement obtenues. Un exemple d’une matrice d’alignement produite par M OT est donné dans la figure 1. À partir de cette matrice, 12 bi-segments différents sont extraits en appliquant les critères décrits ci-dessus.
3.2.2   Approche fondée sur l’expression symbolique de la variation (T ERME) 
Pour chaque paire d’énoncés en relation de paraphrase, il est possible d’exprimer des règles régissant les variations syntagmatiques et paradigmatiques acceptables au niveau des segments. Les nombreux travaux qui ont porté sur les notions de termes et de variantes de termes offrent ainsi une solution assez directe à ce problème de mise en correspondance. L’approche symbolique T ERME que nous utilisons exploite l’opération d’indexation contrôlée du système FASTR (Jacquemin, 1999) pour trouver les alignements sous-phrastiques possibles entre deux paraphrases d’une paire donnée. Cette opération définit les variations acceptables pour un terme par un système de métarègles décrivant ses réécritures morphosyntaxiques possibles. Les métarègles peuvent également mettre en jeu des relations lexicales définissant des variations morphologiques (mots d’une même famille morphologique) et sémantiques (synonymie). Ces ressources constituent donc des connaissances a priori utilisées par T ERME qui ne sont pas accessibles aux autres techniques.
L’outil FASTR utilisé a été conçu pour rechercher efficacement des termes et leurs variantes dans de grands corpus de textes. Pour nos besoins, considérant une paire de paraphrases d’énoncés, nous recherchons dans la première phrase (notre « corpus ») des variantes pour chacun des segments possibles de l’autre phrase (à concurrence d’une certaine taille), puis nous inversons la recherche et retenons l’intersection des résultats. L’usage que nous faisons du moteur de détection de variantes de termes semble favorable à l’obtention d’une bonne précision. À l’inverse, les métarègles définies pour le repérage de variantes de termes ne sont pas nécessairement les mieux adaptées pour assurer une bonne couverture des phénomènes paraphrastiques entre segments de nature quelconque (Dutrey et al., 2010).
3. La technique développée par Lardilleux (2010) constitue une exception notable adaptée aux événements de basse fréquence, et sera naturellement considérée dans la suite de nos travaux.
C OMBINAISON D ’ INFORMATIONS POUR L’ ALIGNEMENT MONOLINGUE Commission Commission application application témoigner réglement témoigner règlement membres membres intention intention a-t-elle a-t-elle précité précité intérêt intérêt pour états pour états son son par par les La les du La de du de l’ l’ l’ l’ ,                                                                     La Commission envisage-t-elle de contrôler la mise en oeuvre de cette réglementation par les Etats membres F IGURE 1 – Matrice d’alignement d’une paire de phrases dans M OT (à gauche), et sa matrice correspondante dans la base de référence.

3.2.3          Approche fondée sur l’alignement de structures syntaxiques (S YNT) 
Lorsque deux énoncés en relation de paraphrase partagent une même structure syntaxique, il est possible de réaliser un alignement fin guidé par la syntaxe permettant de faire apparaître des correspondances sous-phrastiques fines. L’algorithme de Pang et al. (2003) décrit une fusion syntaxique consistant essentiellement à fusionner des arbres de constituants de deux énoncés là où les listes de catégories filles sont compatibles et qu’aucune évidence de non parallélisme syntaxique (via un mécanisme de blocage lexical) n’est détectée. La forêt d’arbres syntaxiques ainsi obtenue permet de construire un treillis de mots représentant des formulations alternatives qu’il est possible d’extraire par simple parcours du treillis.
Pour la méthode S YNT nous avons réimplémenté l’algorithme originel et avons amélioré sa robustesse et sa correction en ajoutant un mode de fusion flexible dans lequel les parties de la phrase non concernées par un blocage lexical sont tout de même fusionnées. Par ailleurs, étant donné que l’algorithme est très dépendant de la qualité des analyses syntaxiques produites, nous avons également ajouté un mode exploitant les k meilleures analyses produites par un analyseur probabiliste. La combinaison retenue entre une analyse du premier énoncé et une analyse du second parmi les k 2 combinaisons possibles est celle minimisant le nombre de nœuds dans le treillis obtenu avant réduction. Un exemple de treillis obtenu par application de S YNT est donné dans la figure 2.

cette                    proximité dans     14                      15 
...       sous       la       barre       des        2                                  ou                         alentours                                   valeur   19 0         4          5        6           7         8                           cent   12         13   aux                              de          cette deux                                                                       16        17               18 pour                                      autour 10          11 F IGURE 2 – Exemple d’un treillis obtenu par application de S YNT 
Tout comme T ERME, cette technique semble a priori plus adaptée à l’extraction précise de bi-segments monolingues, mais contrairement à T ERME il est attendu qu’elle ne parvienne pas à extraire de correspondance lorsque les structures syntaxiques de haut niveau des paraphrases d’énoncés ne sont pas compatibles.
3.2.4          Approche fondée sur la distance d’éditions sur des séquences de mots (D IST) 
Une relation entre deux paraphrases peut également s’exprimer sous forme de la séquence d’éditions la plus directe permettant de transformer l’une en l’autre. Une telle séquence d’éditions sur les mots est, par exemple, H OUDA B OUAMOR , AURÉLIEN M AX ET A NNE V ILNAT 
implémentée dans la technique TERp (Translation Edit Rate plus) (Snover et al., 2009), originellement développée pour le calcul d’une distance d’édition servant de mesure en traduction automatique pour évaluer une hypothèse de traduction relativement à une traduction de référence. Ce calcul met en jeu des opérations de transformation de chaîne incluant l’insertion, la suppression et la substitution de mots, ainsi que le déplacement et la substitution de segments. Chaque type d’opération est associé à une pondération optimisée sur un corpus de développement pour une mesure particulière, et l’algorithme effectue une recherche de la séquence d’opération la moins coûteuse. Les substitutions de mots ou segments sont optionnelles, mais peuvent exploiter des listes fournies à l’algorithme 4 , et les substitutions de segments ont une probabilité associée.
Pour son calcul, TERp produit donc un alignement au niveau des mots entre deux énoncés. Pour nos besoins, nous avons implémenté une méthode D IST qui extrait l’ensemble des bi-segments (à concurrence d’une taille maximale) dérivables des alignements produits par TERp. Nous avons exploité la possibilité d’optimiser TERp pour nos besoins, en optimisant ses paramètres par la méthode du hill climbing 5 . Par la suite, nous dénoterons D ISTA l’optimisation originelle réalisée par Snover et al. (2009) pour l’évaluation de la traduction automatique (le « A » est pour « adequacy »). Les variantes D ISTP , D ISTR et D ISTF1 correspondent à des optimisations réalisées sur un corpus de développement maximisant respectivement la précision, le rappel et la F-mesure de PARAMETRIC exploitant des annotations de référence. L’ensemble de ces configurations n’utilisent pas de substitutions de segments, mais nous ferons appel à cette possibilité dans un cadre d’hybridation décrit plus loin. Un exemple de résultat d’alignement fourni par TERp est donné dans la figure 3.
F IGURE 3 – Exemple d’un alignement résultat de D IST 3.2.5    Résultats expérimentaux et analyse 
Nous avons évalué chacune des méthodes présentées ci-dessus sur le corpus de test décrit dans la section 3.1.
Les techniques M OT, T ERME et S YNT ont été utilisées telles que décrites. Pour D IST, nous avons exploité la possibilité d’optimiser la mesure selon nos propres objectifs. La variante D ISTA , évaluée pour référence, correspond à la version de TERp optimisée pour les besoins de l’évaluation de la traduction automatique. Les autres variantes D ISTP , D ISTR et D ISTF1 correspondent à TERp optimisée pour maximiser respectivement la précision, le rappel et la f-mesure de PARAMETRIC. La première partie de la table 1 donne les résultats obtenus sur les trois sous-mesures de PARAMETRIC. On constate tout d’abord que les résultats pour les 3 premières techniques sont cohérents avec ceux obtenus dans (Bouamor et al., 2010). La seule différence notable est l’amélioration de la précision des deux techniques symboliques T ERME et S YNT. La technique statistique d’alignement entre mots M OT obtient un rappel beaucoup plus important que les deux autres techniques qui se distinguent par une précision relativement forte (60,87 pour T ERME et 66,96 pour S YNT). La précision de M OT reste toutefois dans une zone raisonnable à 47,02. Comme expliqué précedemment, M OT tire avantage des 3 paires de paraphrases sur lesquelles il peut réaliser son apprentissage, alors que les deux autres techniques, telles qu’implémentées, ne peuvent améliorer l’alignement à l’intérieur d’une phrase en exploitant des informations dérivées d’autres phrases.
L’ajout original pour notre tâche de D IST, technique fondée sur une distance d’édition sur des séquences de mots, révèle de nouveaux résultats intéressants. Tout d’abord, on constate qu’au niveau de la f-mesure, il n’existe qu’une faible différence entre D ISTA et la variante optimisée sur la f-mesure, D ISTF1 . Ceci signifie que nos objectifs sont très similaires à ceux de l’évaluation en traduction automatique tels que décrits par (Snover et al., 2009). On constate cependant que des optimisations spécifiques en faveur de la précision ou du rappel mènent ici à des gains très importants de +8,69 en précision et de +7,42 en rappel. Ces résultats montrent que la technique D IST peine à améliorer simultanément la précision et le rappel, même si celle-ci obtient globalement des performances très proches de la meilleure technique envisagée jusque-là, M OT, avec une précision légèrement meilleure et un rappel 4. La version standard de TERp fournit des techniques de racinisation ainsi que des ressources de synonymie ainsi que de paraphrases locales pour l’anglais. TERp utilise jusqu’à 11 paramètres.
5. La première itération d’optimisation se fait avec des poids uniformes, puis nous réalisons 10 itérations avec des valeurs initiales tirées aléatoirement afin de diminuer le risque d’utiliser un minimum local.
C OMBINAISON D ’ INFORMATIONS POUR L’ ALIGNEMENT MONOLINGUE 
légèrement inférieur. Il est possible que les modèles mis en jeu pour le calcul de la distance d’édition ne soient pas suffisamment expressifs pour nos besoins, et qu’en particulier, la non prise en compte de critères linguistiques pour opérer des transformations de séquences de mots soit à mettre en cause.

Précision   Rappel/13532     F1 Mot                  47,02        61,42       53,26 Terme                 60,87         4,19        7,85 Synt                 66,96        13,11       21,92 DistA                 49,85        54,14       51,91 DistP                 58,54         2,68        5,13 DistR                 39,48        61,56       48,11 DistF1                49,03        56,21       52,37 union(Mot,Terme,Synt,DistF1 )      38,99        73,55       50,97 intersection(Mot,DistF1 )       70,38        32,31       44,29 TABLE 1 – Résultats obtenus pour chaque technique 
La dernière partie de la table 1 donne les résultats obtenus en opérant une combinaison élémentaire des résultats visant à maximiser d’une part la précision, et d’autre part le rappel. L’union sur le résultat de l’ensemble des techniques obtient un maximum de valeur de rappel de 73,55 (+12,13 relativement à M OT), avec une précision légèrement affectée (-2,29 relativement à M OT). Par ailleurs, réaliser l’intersection entre les différentes techniques peut raisonnablement mener à une précision améliorée. Cependant, le peu de résultats produits par T ERME et S YNT nous ont fait préférer une mesure sur l’intersection de M OT et D ISTF1 : nous obtenons alors une valeur maximale de précision de 70,38 (+23,36 relativement à M OT et +21,35 relativement à D ISTF1 ). Ces résultats montrent bien la complémentarité qui existe entre ces différentes techniques, et servent donc ici de motivation pour la recherche d’un mode de combinaison plus efficace des informations issues de chaque technique.
3.3     Approche hybride d’extraction de paraphrases locales 
3.3.1   Observations et motivations 
Les expériences présentées dans la section 3.2.5 ont révélé que les différentes techniques ont des performances variées, ce qui permet aussi de faire l’hypothèse qu’il est possible d’opérer une combinaison efficace de leurs résultats. Nous faisons ici une synthèse des points forts et des limitations de chacune de ces techniques orientée par la recherche d’un mode de combinaison plus efficace : – M OT : très sensible à la fréquence de ses observations de mots et de cooccurrences entre mots, cette technique peut être informée par des connaissances d’association a priori, qui peuvent par exemple être transmises sous forme de données d’apprentissage additionnelles. En outre, il est possible, avec des données d’entraînement annotées, d’améliorer les performances des alignements statistiques par apprentissage discriminant (Tomeh et al., 2010).
– T ERME : cette technique est spécialisée dans l’extraction d’un type de bi-segments contraints par des règles de réécriture et de variation lexicale. Les métarègles, qui ont été développées manuellement, sont assez précises et ne peuvent couvrir tous les phénomènes de paraphrase. Leur apprentissage automatique peut améliorer la couverture, mais au détriment de la précision. L’enrichissement automatique des familles morphologiques et sémantiques devrait également permettre d’augmenter le rappel.
– S YNT : cette technique est très sensible au degré de parallélisme des énoncés qui décide de la fusion de constituants syntaxiques. Nous avons déjà pris en compte la qualité des analyses syntaxiques en autorisant la fusion à opérer sur les k-meilleures analyses syntaxiques. Le blocage lexical empêche une fusion lorsqu’un mot présent dans le constituant d’une phrase est attesté dans un constituant non aligné de l’autre phrase. Il pourrait être amélioré par la connaissance a priori de paraphrases locales, ce qui, néanmoins, ne pourrait bénéficier qu’à la précision.
– D IST : cette technique transforme une séquence de mots en une autre en un coût minimal, en utilisant des pondérations optimisées pour les différentes opérations utilisées. L’algorithme manipule des segments qui n’ont pas nécessairement de motivation linguistique, ce qui peut mener à des transformations aberrantes. En outre, des H OUDA B OUAMOR , AURÉLIEN M AX ET A NNE V ILNAT 
opérations d’insertion et de suppression peuvent être utilisées à tort lorsque des correspondance au niveau des mots ou des segments ne sont pas connues. Ainsi, si de telles correspondances peuvent être fournies à TERp, il est possible d’espérer diminuer le nombre d’opérations de transformation aberrantes et ainsi d’augmenter la performance.
3.3.2   Présentation de l’hybridation des méthodes 
Dans la section précédente nous avons montré qu’il existait plusieurs voies pour améliorer la performance de l’alignement monolingue auquel nous nous intéressons à partir des techniques décrites. Sans considérer davantage, à ce stade, l’amélioration individuelle de chacune des techniques, nous pouvons décrire les deux grandes familles d’approches possibles pour l’hybridation de la manière suivante : 1) les résultats produits indépendamment par chaque technique sont combinés a posteriori, et 2) une technique est adaptée par la connaissance des résultats produits par les autres techniques.
Nous avons déjà montré le résultat de l’évaluation d’une approche élémentaire par combinaison a posteriori dans la section 3.2.5, illustrée sur la partie gauche de la figure 4, qui révèle que la précision et le rappel peuvent ainsi être facilement améliorés. Nous considérons désormais la seconde approche. D’après nos observations, D IST est un candidat assez naturel pour l’adaptation. En effet, la connaissance d’alignements au niveau des mots ou des segments peut diminuer le nombre d’opérations effectuées à tort. Il s’agit précisément de la motivation majeure pour l’évolution de TER à TERp (Snover et al., 2009), liée à la possibilité d’utiliser une base de paraphrases locales connues a priori et ainsi d’être plus robustes quant aux hypothèses de traduction acceptées par le système lorsqu’elle ne correspondent pas exactement à une traduction de référence.
Au contraire de ce qui est fait dans TERp, nous n’utiliserons pas une base de connaissances externe, même si nous ne rejetons pas cette hypothèse pour de futures expériences, mais nous adaptons dynamiquement la base de paraphrases utilisées en fonction des hypothèses extraites par les autres techniques, à savoir des hypothèses nombreuses et relativement précises pour M OT, et peu nombreuses mais précises pour T ERME et S YNT. De plus, comme nous l’avons déjà montré, ces techniques peuvent être complémentaires quant aux types de paraphrases locales qu’elles permettent d’identifier, ce qui rejoint nos intuitions initiales liées à la nature de chacune d’elles.
Cette approche est illustrée sur la partie droite de la figure 4. Les bi-segments obtenus par M OT, T ERME et S YNT sont combinés pour construire une table de paraphrases utilisée ensuite par D IST, que nous pouvons optimiser en fonction d’un besoin particulier (précision, rappel ou f-mesure). On remarque ici une analogie assez directe avec d’autres scénarios de combinaisons d’informations en TAL : en traduction automatique, l’approche de la partie gauche de la figure 4 correspond à la définition classique de la combinaison de systèmes (Matusov et al., 2009), alors que l’approche de la partie droite correspond à l’adaptation d’un système par des sources externes telles que d’autres systèmes de traduction (Crego et al., 2010).
Mot                                                   Mot Terme                                                Terme 
Dist combinaison                                          combinaison (union) Synt                                     Bitexte     Synt Bitexte monolingue                                           monolingue Dist F IGURE 4 – Principales approches de combinaisons d’informations pour l’alignement multilingue. À gauche, plusieurs techniques produisent des résultats combinés pour produire une nouvelle sortie. À droite, un sousensemble des techniques fournissent leurs résultats à une dernière technique adaptée à l’exploitation de ces connaissances.

Un problème important à considérer concerne la manière dont la table de paraphrases utilisée par TERp est construite à partir des hypothèses produites par les différentes techniques. À ce stade de nos travaux, nous ne disposons pas de mesures de confiance données par chaque technique pour chacune de ses hypothèses, et nous sommes donc contraints de les considérer initialement comme équiprobables. De plus, pour assurer une comparaison plus directe avec la combinaison correspondant à la partie gauche de la figure 4, nous réalisons une combinaison simple C OMBINAISON D ’ INFORMATIONS POUR L’ ALIGNEMENT MONOLINGUE 
à base d’union : chaque hypothèse apparaissant au moins une fois parmi les hypothèses des différents systèmes est retenue et est associée à un poids constant uniforme. 6 Un autre aspect important concerne là encore la pondération associée à chacune des paires de paraphrases a priori fournies à TERp. Considérons le cas où deux paraphrases sont fournies à TERp et où l’une est un sous-segment de l’autre : par exemple, (ce degrévement ↔ cet allègement) inclut (dégrèvement ↔ allègement). Si ces deux paraphrases sont fournies avec le même score à TERp, celui-ci préfèrera, dans de nombreux cas, utiliser la plus couvrante des deux, car cela minimisera souvent la quantité d’opérations de transformation restant à faire, et donc le coût global de transformation (voir partie gauche de la figure 5). Cela peut ne pas être un défaut en soi, car l’identification des plus longues sous-unités paraphrastiques peut être utile. Cependant, PARAMETRIC base ces mesures sur l’ensemble des bi-segments pouvant être extraits à partir d’alignement sur les mots. Ainsi, si dans l’exemple précédent l’alignement de référence inclut deux points d’alignement pour (ce ↔ cet) et (dégrèvement ↔ allègement), l’ensemble des bi-segments de référence sera constitué des deux bi-segments précédents et de leur combinaison ou « extension » (ce degrévement ↔ cet allègement). Si ce dernier est utilisé par TERp, il n’existe pas de moyen immédiat pour retrouver l’alignement sous-phrastique, et donc le rappel de la technique adaptée sera pénalisé.
Plusieurs solutions sont envisageables pour pallier ce problème. La pondération des paraphrases pourraient prendre en compte le nombre de mots/tokens couverts en favorisant les courts segments. Ne disposant néanmoins pas de solutions génériques applicables à toutes les techniques ni de moyen d’intégrer des scores de confiance motivés, nous préférons nous en remettre à une solution initiale plus simple, qui consiste à ne conserver que les sous-segments minimaux parmi l’union de ceux proposés par chacune des techniques. Ainsi, ne seront gardés pour construire la table de paraphrases utilisée par TERp que les bi-segments n’étant inclus dans aucun autre bi-segment, que nous appellons bi-segments minimaux.
F IGURE 5 – Exemple de deux alignements résultats de D ISTF1 , avec à gauche l’ensemble des bi-segments non filtrés, et à droite un ensemble de bi-segments minimaux 3.3.3    Résultats expérimentaux et analyse 
Les résultats que nous obtenons en optimisant TERp sur les trois mesures de PARAMETRIC et en utilisant différentes sources de bi-segments sont présentés dans la table 2. Le résultat principal de ces expériences est la nouvelle f-mesure de 55,27 obtenue en optimisant sur cette mesure et en exploitant les bi-segments provenant des trois autres techniques. C’est la valeur la plus élevée sur l’ensemble de nos expériences, et elle correspond notamment à un gain de +4,3 par rapport à la combinaison par union des résultats de toutes les techniques, ou encore à un gain de +2,01 par rapport à M OT, la meilleure technique individuelle pour la f-mesure, et à un gain de +2,9 par rapport à D ISTF1 , la technique utilisée sans adaptation et optimisée selon le même critère. Ces résultats viennent confirmer notre hypothèse que TERp a pu ici tirer utilement profit des connaissances a priori qui lui ont été fournies.
Nous constatons de plus que des valeurs de précision et de rappel encourageantes peuvent être atteintes : une précision de 69,66 est obtenue en exploitant les prédictions de T ERME et en optimisant sur la précision (+2,7 par rapport à la meilleure technique individuelle S YNT), et un rappel de 62,38 est obtenu en exploitant les prédictions de M OT en optimisant sur le rappel (+0.82 par rapport à la meilleure technique individuelle D ISTR ).
Les cas de combinaisons où une seule technique est utilisée pour alimenter la base de paraphrases de TERp peuvent également être étudiés en comparant les valeurs des tables 1 et 2. Hormis les valeurs de rappel obtenues pour 6. Il serait bien sûr possible de pondérer a priori chaque hypothèse par le nombre de techniques l’ayant proposée, et/ou par la performance mesurée des techniques en question, dérivée par exemple de leur performance individuelle dans les différentes valeurs de PARAMETRIC. En outre, la contribution de chacune des techniques pourrait faire l’objet d’un paramètre optimisé simultanément aux paramètres de TERp. Toutes ces possibilités seront considérées dans notre travail futur.
H OUDA B OUAMOR , AURÉLIEN M AX ET A NNE V ILNAT 
Critère d’optimisation Source de bi-segments               D ISTP                      D ISTR                      D ISTF1 P     R/13532     F1       P     R/13532      F1       P      R/13532     F1 M OT                  67,83    13,21     22,11   41,49     62,38    49,83    55,11     54,51     54,81 T ERME                 69,66     6,82     12,42   40,51     55,6     46,87    53,16     49,84     51,45 S YNT                 68,08     8,11     14,48   29,99     56,84    39,26    51,25     50,14     50,69 comb(M OT, S YNT, T ERME)      66,02    13,15     21,93   38,46     61,09     47,2    55,01     55,54     55,27 TABLE 2 – Résultats obtenus pour différentes optimisations et différentes sources de bi-segments. La fonction comb correspond à l’union avec pondération uniforme des bi-segments ne retenant que les bi-segments minimaux.
D ISTR avec les paraphrases de T ERME et S YNT, toutes les autres combinaisons de D IST avec les données d’une autre technique et optimisées selon un critère particulier améliorent la meilleure des deux valeurs précédentes.
Par exemple, D ISTP adapté avec les paraphrases de T ERME obtient une précision de 69,66, qui est meilleure que celle de D ISTP (58,54) et celle de T ERME (60,87). Il est à noter qu’en combinaison de systèmes, comme c’est par exemple le cas en traduction automatique, des gains sont plus généralement obtenus lorsque un certain nombre de systèmes sont combinés. La complémentarité de nos sources d’information et l’impact assez immédiat d’une amélioration des informations a priori utilisées par TERp semblent donc ici avoir un rôle très bénéfique pour notre tâche.
Il est finalement instructif de considérer la performance des différentes configurations testées en fonction d’une certaine difficulté a priori. Celle-ci pourrait se mesurer par le degré d’accord inter-annotateurs pour chaque phrase, mais nous avons choisi d’utiliser un résultat en lien avec TERp : (1 − T ER(paraphrase1 , paraphrase2 )), qui est donc d’autant plus grand que les phrases sont proches. Le résultat pour nos quatre techniques individuelles est présenté dans la figure 6. Pour la précision, on constate tout d’abord que M OT est très sensible à la difficulté telle que nous la définissons, et que les alignements que cette technique produit sont d’autant moins bons que les phrases sont différentes. De façon un peu plus surprenante, S YNT et D ISTP ne semblent pas trop affectés par cette difficulté. Cependant, ceci est peut-être dû au fait que les valeurs des barres, pour chaque intervalle discrétisé, sont une moyenne qui ne rend pas compte du nombre d’éléments. Il est possible que S YNT extraie peu de bi-segments sur des paires de phrases difficiles, mais que lorsqu’elle parvient à trouver des structures syntaxiques compatibles, celles-ci permettent un alignement précis. Enfin, T ERME est lui insensible à cette difficulté, ce qui était attendu puisqu’elle fonctionne sur de courts patrons morphosyntaxiques pouvant impliquer des mots différents. Nous déduisons donc de ces remarques que ces différentes techniques peuvent être utilisées à bon escient pour différents niveaux de parallélisme des corpus d’acquisition. Le rappel fait apparaître une tendance beaucoup plus marquée : M OT, D ISTR et S YNT extraient d’autant moins de bi-segments de la référence que les phrases sont difficiles. À nouveau, T ERME y semble insensible. On retiendra de cette analyse qu’il est préférable d’avoir des paraphrases d’énoncés les plus « parallèles » possibles pour obtenir une bonne performance en acquisition, mais que les techniques symboliques sont utiles pour extraire des paraphrases sous-phrastiques précises dans des paraphrases d’énoncés de formes très différentes.
4    Conclusion et travaux futurs 
Dans cet article nous avons poursuivi deux objectifs. D’une part, nous avons présenté quatre méthodes d’acquisition de paraphrases sous-phrastiques à partir de corpus monolingues parallèles. Trois d’entre elles avaient déjà été évaluées, la dernière est nouvelle. Ces méthodes reposent sur des caractéristiques linguistiques différentes : M OT sur l’apprentissage statistique, T ERME sur un approche symbolique de la variation de termes, S YNT sur des proximités syntaxiques et enfin DIST sur des distances d’édition. En évaluant ces méthodes, nous avons constaté qu’effectivement leurs résultats semblent complémentaires, ce qui nous a mené à notre second objectif, à savoir l’hybridation de ces méthodes. Plutôt que de combiner les résultats a posteriori, nous avons choisi d’utiliser les résultats de certaines méthodes comme données d’entrée d’une autre. Les résultats de cette approche ont confirmé notre hypothèse en montrant que la complémentarité de ces techniques donne un gain significatif.
De nombreuses pistes s’ouvrent à nous à la suite de ce travail. Nous souhaitons explorer toutes celles évoquées au cours de cet article. À court terme, nous comptons attribuer des scores de confiance à chacune des techniques afin C OMBINAISON D ’ INFORMATIONS POUR L’ ALIGNEMENT MONOLINGUE F IGURE 6 – Performance selon les différents critères de PARAMETRIC de différentes techniques. La valeur de chaque barre dans les intervalles discrétisés est une moyenne des éléments de cet intervalle, et ne rend pas compte du nombre de ces éléments. Pour la précision, une valeur de 0 peut indiquer soit l’absence de proposition pour les phrases de cet intervalle, soit de propositions toutes incorrectes.
de mieux tirer parti de leur complémentarité. Nous allons également utiliser des connaissances complémentaires.
Il est important de noter que cette méthode peut s’adapter à la tâche requérant des paraphrases. Ainsi, on peut souhaiter en obtenir de nombreuses, au détriment de leur qualité pour de la recherche d’information, alors que la correction sera privilégiée pour le résumé automatique.

