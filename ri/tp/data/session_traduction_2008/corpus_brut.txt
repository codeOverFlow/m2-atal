
Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues 
Caroline Lavecchia1, 2 Kamel Smäıli1, 2 David Langlois1, 3 (1) LORIA/Speech Group, Campus scientifique, BP 239, 54506 Vandoeuvre lès Nancy Cedex, France (2) Université Nancy2 (3) IUFM de Lorraine 
Résumé.        Dans cet article, nous présentons une nouvelle approche pour la traduction automatique fondée sur les triggers inter-langues. Dans un premier temps, nous expliquons le concept de triggers inter-langues ainsi que la façon dont ils sont déterminés. Nous présentons ensuite les différentes expérimentations qui ont été menées à partir de ces triggers afin de les intégrer au mieux dans un processus complet de traduction automatique. Pour cela, nous construisons à partir des triggers inter-langues des tables de traduction suivant différentes méthodes. Nous comparons par la suite notre système de traduction fondé sur les triggers interlangues à un système état de l’art reposant sur le modèle 3 d’IBM (Brown & al., 1993). Les tests menés ont montré que les traductions automatiques générées par notre système améliorent le score BLEU (Papineni & al., 2001) de 2, 4% comparé à celles produites par le système état de l’art.
Abstract. In this paper, we present an original approach for machine translation based on inter-lingual triggers. First, we describe the idea of inter-lingual triggers and how to determine them. Then, we present the way to make good use of them in order to integrate them in an entire translation process. We used inter-lingual triggers to estimate different translation tables. Then we compared our translation system based on triggers to a state-of-the-art system based on IBM model 3 (Brown & al., 1993). The experiments showed that automatic translations generated by our system outperform model 3 of IBM by 2.4% in terms of BLEU (Papineni & al., 2001).
Mots-clés :       Traduction Automatique Statistique, Triggers Inter-Langues, Information Mutuelle, Corpus parallèle, Décodage.

Keywords:          Statistical Machine Translation, Inter-Lingual Triggers, Mutual Information, Parallel corpus, Decoding process.
Caroline Lavecchia, Kamel Smäıli, David Langlois 1 Introduction L’objectif de la traduction automatique est de transformer une phrase donnée dans une langue source en une phrase dans une langue cible. Pour résoudre ce problème très complexe, il est possible d’intégrer le savoir faire de traducteurs humains, mais cela demande une modélisation de ce savoir qui est en soi un sujet de recherche. Il faut utiliser des modèles formels des langues source et cible issus du Traitement Automatique des Langues, et un modèle de traduction à base de règles, comme par exemple ce qui est fait dans le système de Systran (Jean Senellart, 2001).
Cet effort de conception doit ê tre répété pour chaque couple de langues (même si le savoir faire peut ê tre en partie transféré). L’approche statistique, quant à elle, utilise une voie différente. En effet, elle n’utilise pas de connaissances a priori, mais s’appuie sur des corpus bilingues. Ces corpus sont alignés, c’est-à-dire que le lien entre chaque partie du texte de la langue source est fait avec la partie correspondante dans la langue cible. Le lien est généralement fait au niveau de la phrase. Partant de ces corpus, une analyse statistique utilise les redondances existantes afin d’estimer les paramètres du processus de traduction. La traduction statistique est possible car les modèles adhoc sont couplés avec des algorithmes de programmation dynamique qui maximisent une fonction de traduction d’une phrase source vers une phrase cible. IBM a utilisé avec succès cette approche (Brown & al., 1993). La plupart des systèmes statistiques actuels sont fondés sur les modèles d’IBM.
L’approche statistique nécessite de définir un modèle de traduction qui va permettre de calculer les probabilités de traduction entre les mots, les suites de mots et les autres constituants de la phrase. Ainsi, on définit pour toute phrase s de la langue source et toute phrase t de la langue cible une valeur P (s|t) calculée à l’aide de modèles composés de nombreux paramètres. IBM propose pour estimer ces paramètres une méthode itérative engendrant 5 modèles de traduction différents, du plus simple au plus complexe. Cela aboutit à des modèles performants, mais longs et complexes à estimer. Cette complexité croit trè s vite au fur et à mesure des paramètres supplémentaires pris en compte lors du processus de traduction. En plus du modèle de traduction, cette approche utilise un modèle de langage de la langue cible qui permet d’évaluer la qualité de la phrase t. Un décodeur tel que Pharaoh (Koehn, 2004) utilise ces deux modèles afin de rechercher pour une phrase s donnée une phrase t qui peut ê tre acceptée comme traduction de s.
Dans cet article, nous proposons une nouvelle approche permettant de construire un modèle de traduction fondé sur les triggers inter-langues (extension des triggers classiques) pour construire notre système de traduction statistique. Le concept de triggers est bien connu de la communauté de la modélisation statistique du langage. Facile à mettre en oeuvre, il possède une certaine souplesse qui permet de l’appliquer à différents niveaux de lecture de la phrase (mots, genre, nombre, constituants syntaxiques). Nous montrerons que les triggers inter-langues permettent de construire un modèle de traduction efficace. Nous comparerons ses résultats à ceux fondés sur les modèles d’IBM.
Nous présentons dans la partie 2 la notion générale des triggers. La partie 3 définit le concept de triggers inter-langues qui associe à chaque mot de la langue source une liste de traductions possibles. Dans la partie 4, nous présentons la manière dont les triggers inter-langues ont été intégrés à un processus complet de traduction automatique. Nous terminons enfin par une conclusion qui met en avant les points forts de notre méthode et donne quelques perspectives futures des travaux de notre groupe de recherche.
Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues 2 Rappel sur les triggers Le concept de triggers est très souvent cité en modélisation statistique du langage et plus particulièrement en reconnaissance de la parole. Les triggers permettent entre autre d’améliorer et de généraliser le modèle Cache (Kuhn & DeMori, 1990). Le modèle Cache favorise la probabilité d’un mot wi récemment apparu dans le contexte gauche. Un modèle de triggers va plus loin et accorde une probabilité plus importante à une liste de mots corrélés au mot wi (Tillmann & Ney, 1996). Les triggers sont sélectionnés selon la valeur de l’Information Mutuelle (IM) donnée par la formule suivante : P (x, y) IM(x, y) = P (x, y)log                                           (1) P (x)P (y) Chaque mot appartenant au vocabulaire est alors associé à n mots qui lui sont le plus fortement corrélés d’après la valeur de l’IM. Un trigger est un ensemble composé d’un mot appelé déclencheur et d’une liste de mots qu’il déclenche appelés déclenchés. La figure 1 illustre un exemple de triggers anglais.
Les triggers ont beaucoup été utilisés en reconnaissance de la Parole o`u ils sont combinés avec un modèle n-gramme classique (Tillmann & Ney, 1997).
Garry Kasparov is a chess champion 
F IG . 1 – Exemples de triggers classiques 3 Les triggers inter-langues Nous proposons dans ce qui suit d’étendre ce concept pour l’utiliser avec des corpus bilingues alignés. Nous appelons ce concept triggers inter-langues. Un trigger inter-langue est défini comme étant un ensemble composé d’un mot déclencheur d’une langue source et des mots déclenchés d’une langue cible qui lui sont fortement corrélés. Ainsi, chaque mot f du vocabulaire français VF est associé à n mots anglais ou triggers inter-langues qui lui sont le plus fortement corrélés au sens de l’IM. Plus formellement, 
∀fi ∈ VF , T rign (fi ) est l’ensemble des n triggers inter-langues de fi 
De la même façon, chaque mot e du vocabulaire anglais VE est associé à n mots français : 
∀ei ∈ VE , T rign (ei ) est l’ensemble des n triggers inter-langues de ei .

Les triggers inter-langues sont déterminés suivant la valeur de l’Information Mutuelle calculée sur un corpus aligné au niveau de la phrase. Ce corpus est constitué de paires (E, F ) o`u F est la traduction de E. Les triggers permettent de repérer les éléments en relation d’une langue à l’autre. Les triggers sont estimés en utilisant la formule (2).
P (f, e) IM(f, e) = P (f, e) ∗ log(                  )                        (2) P (f ) ∗ P (e) Caroline Lavecchia, Kamel Smäıli, David Langlois N(X)                          N(f, e) P (X) =                    P (f, e) =                                   (3) |Corpus|                      |Corpus| – e et f sont des éléments de la paire de phrases (E, F ) – N(X) est le nombre de phrases dans lesquelles le mot X apparaît – N(e, f ) est le nombre de paires (E, F ) de phrases du corpus aligné dans lesquelles les mots e et f co-occurent.
– |Corpus| est le nombre de paires de phrases constituant le corpus aligné.
La figure 2 montre un exemple de triggers inter-langues de l’Anglais vers le Français. Ce qui Garry Kasparov is a chess champion Garry Kasparov est un champion d’ échecs F IG . 2 – Exemples de triggers inter-langues 
motive l’utilisation de cette notion est le fait que l’on espère trouver la traduction du mot déclencheur dans la liste des mots déclenchés.
Notons que ce principe de triggers inter-langues est utilis éen modélisation du langage pour enrichir des langues faiblement dotées à partir d’autres langues très riches en termes de corpus (Kim & Khudanpur, 2004).
4 La traduction automatique avec les triggers inter-langues La première étape pour la mise en place de notre système de traduction est l’apprentissage des triggers inter-langues. Pour ce faire, nous les déterminons sur un corpus parallèle extrait des actes du Parlement Européen dont les statistiques sont résumées dans le tableau 1.

TAB . 1 – Corpus d’apprentissage 
Français Anglais Paires de phrases                596K Taille (en mots)           17.3M     15.8M Vocabulaire (en mots)      77.5K      60.3K Nous appliquons les formules (2) pour détecter les couples (e, f ) les plus corrélés et qui constituerons les triggers inter-langues.
Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues Quelques exemples de triggers Anglais-Français sont pré sentés dans le tableau 2, de même des exemples de triggers Français-Anglais sont présentés dans le tableau 3. La troisième colonne des tableaux indique pour chaque couple de mots déclencheur-déclenché la valeur de l’Information Mutuelle qui lui est associée. Une analyse qualitative de nos triggers montre que les mots déclenchés peuvent souvent ê tre apparentés à de possibles traductions du mot déclencheur ou à des mots vraiment très proches du point de vue du sens. Par ailleurs, comme le montrent les exemples des tableaux, les triggers détectent également les différents sens des homographes (ainsi, deux sens de ’porte’ sont détectés avec de forts taux d’Information Mutuelle). Ces constats sont valables dans les deux sens de traduction.

TAB . 2 – Exemples de mots français déclenchés par des mots anglais 
Déclencheur Déclenchés             IM             Déclencheur Déclenchés                IM anglais      français                (10−4)         anglais      français                   (10−4 ) pion                     0, 33                       champion                    2, 38 chess        échiquier              0, 29          champion     championne                  1, 00 échecs                 0, 26                       homme                       0, 28 porte                    20, 96                      sens                        69, 06 door         ouverte                  5, 15          sense        bon                         8, 91 portes                   2, 73                       sentiment                   7, 23 traduction               34, 16                      usine                       7, 54 translation  erreur                   2, 73          plant        installation                3, 92 version                  1, 49                       plantes                     3, 59 TAB . 3 – Exemples de mots anglais déclenchés par des mots français 
Déclencheur Déclenchés             IM             Déclencheur Déclenchés                IM français    anglais                  (10−4)         français    anglais                     (10−4 ) failures                 5, 88                       champion                    2, 38 échecs     failure                  0, 88          champion     expert                      0, 25 chess                    0, 26                       champions                   0, 24 door                     20, 96                      sense                       69, 06 porte        relates                  5, 21          sens         direction                   28, 68 concerns                 4, 23                       meaning                     11, 61 translation              34, 16                      plants                      19, 20 traduction   error                    2, 51          plantes      plant                       3, 59 version                  1, 49                       crops                       1, 98 Nous proposons dans ce qui suit, d’utiliser l’ensemble des triggers inter-langues pour mettre en place notre système de traduction. Nous le comparons ensuite à un système état de l’art reposant sur le modèle 3 d’IBM (Brown & al., 1993). Pour ce faire, nous avons utilisé le décodeur Pharaoh1 (Koehn, 2004), afin de traduire automatiquement un corpus de test de 1444 phrases 
Le modèle de langage de la langue cible est un modèle trigram (méthode de lissage de Good-Turing. Les poids des différents modèles sont les suivants : 1 pour le modèle de langage, 1 pour le modèle de traduction, 1 pour le modèle de ré-ordonnancement et enfin une pénalité de mot de 0. Le décodage est fait avec ré-ordonnancement.
Caroline Lavecchia, Kamel Smäıli, David Langlois anglaises. Les traductions produites sont ensuite comparées à l’aide de la mesure Bleu, une mesure automatique couramment employée en traduction automatique (Papineni & al., 2001).
Dans les sections suivantes, nous présentons trois façons d’identifier les traductions potentielles d’un mot au sein de notre système à partir des triggers inter-langues déterminés auparavant.
Elles donnent lieu à l’estimation de trois tables de traduction.
4.1 Les tables de traduction Trig-n 
Dans un premier temps, nous estimons que tous les triggers inter-langues peuvent ê tre assimilés à des traductions possibles. Par conséquent, nous les ajoutons tous dans la table de traduction.
Ainsi, un mot anglais ei est une traduction probable du mot français fj s’il fait partie de ses triggers inter-langues. La probabilité associée à cette traduction est la valeur de l’Information Mutuelle normalisée du couple (ei , fj ).

IM(fj , ei ) ∀fj ∈ VF , ∀ei , ek ∈ T rign (fj ) P (ei |fj ) =   n                             (4) k=1 IM(fj , ek ) 
Par la suite, nous appellerons les tables de traduction ainsi construites Trig-n avec n le nombre de triggers inter-langues retenus pour chaque mot français du vocabulaire.
L’évaluation de notre système mis en place avec les tables de traduction Trig-n, n variant de 10 à 200, est décrite par la série Trig-n de l’histogramme de la figure 3. Dans un premier temps, nous remarquons une amélioration du score Bleu de plus de 2 points entre Trig-10 et Trig20. Ceci montre que, globalement, les traductions correctes d’un mot déclencheur sont dans les 20 meilleurs déclenchés. Toutefois, lorsque n prend des valeurs au delà de 20, l’impact est beaucoup plus faible. Il faut préciser que, dans la configuration utilisée, Pharaoh, dans un souci de rapidité de recherche, ne prend en compte que les 20 meilleures traductions d’un mot donné.
Donc, il est inutile d’aller au delà de 20. Toutefois l’impact montré n’est pas nul car le fait de normaliser les probabilités sur 20, 50 ou 100 triggers modifie l’échelle des valeurs de la table de traduction et donc le poids de cette table dans le processus de recherche. Notons que nous avons modifié cette configuration afin de permettre à Pharaoh de tenir compte de plus de 20 traductions, mais que cela n’a pas eu d’impact positif sur les performances.
4.2 Les tables de traduction Sym-n 
La deuxième méthode de construction d’une table de traduction consiste à considérer comme traductions possibles les couples (fj , ei ) qui respectent la contrainte de symétrie suivante : 
Si ei ∈ T rign (fj ) et fj ∈ T rign (ei ) Alors ei ∈ Symn (fj )                  (5) 
ei appartient aux traductions possibles de fj (Symn (fj )), si ei fait partie des triggers interlangues de fj et inversement si fj est un trigger inter-langue de ei comme l’illustre la figure 4.
Cette contrainte de symétrie nous permet d’affiner la liste des triggers inter-langues de fj pour ne retenir que les plus pertinents. Nous supposons que si ei est un des n mots les plus corrélés avec fj et que fj est également dans les n mots les plus déclenchés par ei , alors il y a de fortes chances que ei soit une traduction de fj . La probabilité associée à ce couple est calculée de la Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues 
Trig-n Sym-n Smooth-n M3 28.5 
27.5 Bleu 
26.5 
25.5 10             20             50             100      200 F IG . 3 – Evaluation des traductions produites à l’aide des tables de traduction Trig-n, Sym-n et Smooth-n en fonction de n Triggers anglais−français Triggers français−anglais e e 11   12 ...    e.     . .   e1k 1 
f    1 Traductions potentielles f    2           e e 21   22 . . . . . .         e2k 2 f                                                                    .
3                                                               .
e            .                                                             e:f. 1, fi , f n f    i           e e e i1    i2 . .. . .      eik i .                                                                   .
.                                                                   .
f    n e e          .. .    e.      . . en kn 11    n2 F IG . 4 – Identification des traductions potentielles d’un mot par symétrie 
manière suivante : 
IM(fj , ei ) ∀fj ∈ VF , ∀ei , ek ∈ Symn (fj ) Psym (ei |fj ) =                                                  n                  (6) k=1 IM(fj , ik ) 
La contrainte de symétrie réduit considérablement le nombre de couples retenus parmi les triggers inter-langues. En moyenne, seuls 21% des triggers inter-langues respectent la contrainte de symétrie (5). Ainsi, nous espérons n’avoir retenu que les triggers les plus pertinents.
La série Sym-n de l’histogramme de la figure 3 présente l’évaluation de notre système fondé sur les tables de traduction Sym-n. Nous observons à nouveau une nette amélioration du score Bleu lorsque l’on utilise Sym-20 au lieu de la table Sym-10. Nous notons, également, une légère amélioration du score Bleu qui passe de 25, 84 pour Trig-10 à 25, 91 pour Sym-10. La contrainte de symétrie nous permet donc, dans ce cas, d’écarter des triggers inter-langues qui ne seraient pas de réelles traductions. Malheureusement, cette observation ne s’étend pas aux autres tables Sym-n (avec n > 10) puisque leur score Bleu reste inférieur à ceux obtenus avec les tables Trig-n. Même si cette intuition semble naturelle, la contrainte de symétrie semble donc ê tre trop restrictive pour améliorer les performances de notre syst è me.
Caroline Lavecchia, Kamel Smäıli, David Langlois Nous proposons donc une troisième façon d’identifier et d’estimer les traductions potentielles pour assouplir cette contrainte de symétrie. Pour cela, nous décidons d’utiliser une technique de lissage des probabilités (smoothing).
4.3 Les tables de traduction Smooth-n 
Afin de ne pas affecter une probabilité nulle aux couples (f, e) qui ne satisfont pas la contrainte de symétrie “e déclenche f et f déclenche e”, nous proposons d’utiliser une technique de lissage pour estimer une troisième table de traduction que nous appelons par conséquent Smooth-n. En modélisation du langage, ces techniques dites de smoothing permettent de lisser les probabilités de manière à ce que chaque évènement, même impossible, se voit affecter une probabilité (Ney et al., 1994). Nous proposons d’employer le même type de technique. Pour ce faire, nous réduisons la probabilité des triggers symétriques des tables Sym-n. La masse ainsi récupérée est répartie uniformément sur les triggers non symétriques. Cette nouvelle estimation est calculée de la manière suivante : 
Psym (ei |fj ) − ǫ   si ei ∈ Symn (fj ) ∀ei ∈ T rign (fj ) Psmooth (ei |fj ) =                                                 (7) γ                    sinon 
Pour un mot français, nous retirons une quantité ǫ à chaque probabilité de traduction assignée à ses triggers inter-langues symétriques et nous redistribuons la masse récoltée uniformément sur ses autres triggers inter-langues non symétriques.
La dernière série de l’histogramme de la figure 3 indique les performances de notre système reposant sur les tables Smooth-n. Rappelons que n est le nombre de triggers inter-langues retenus pour chaque mot du vocabulaire français. L’allure de la série est la même que pour les expériences précédentes. Toutefois, nous pouvons constater que notre système est plus performant avec les tables Smooth-n qu’avec les tables Sym-n. Par conséquent, nous pouvons dire que la contrainte de symétrie est en effet trop restrictive, et que le fait de conserver les triggers non-symétriques permet bien d’améliorer les performances. En revanche, malgré ces efforts de lissage, notre système reste le plus performant lorsque chaque trigger inter-langue est considéré comme une traduction potentielle qu’il respecte la contrainte de symétrie ou non (série Trig-n).
Ces résultats pourraient indiquer que la contrainte de sym étrie est trop forte et que le processus de traduction n’est pas nécessairement symétrique. Cela serait à confirmer par une étude au cas par cas.
4.4 Comparaison avec le modèle 3 de traduction d’IBM 
Afin d’évaluer la pertinence de notre système fondé sur les triggers inter-langues, nous avons comparé ses performances avec celles d’un système état de l’art reposant sur le modèle 3 d’IBM et que nous appelons M3. Ce dernier a été entraîné, à l’aide de l’outil Giza++ (Och & Ney, 2000), sur le même corpus parallèle d’apprentissage que les triggers inter-langues et testé avec le même décodeur sur les mêmes 1444 phrases. Les performances du système M3 sont inférieures à celle de notre système. En effet, nous obtenons un score BLEU de 28, 07 ( cf. courbe M3 de la figure 3) par rapport à un score de 28, 49 pour Trig-100.
Toutefois, comme nous l’avons dit précédemment, le décodeur Pharaoh ne prend en compte pour chaque mot français que les 20 meilleures traductions dans le but de réduire son espace Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues de recherche. Afin d’optimiser les performances de notre système, nous avons paramétré le décodeur de telle sorte de lui laisser la possibilité de prendre en compte plus de 20 traductions par mot français. Pour cela, nous faisons varier le paramètre ttable-limit. Nous optimisons également le paramètre ttable-threshold qui permet d’écarter de l’espace de recherche les couples de traductions dont la probabilité est inférieure à un certain seuil. L’optimisation est réalisée indépendemment pour les deux systèmes. Les résultats en terme de score Bleu sont présentés dans le tableau 4. Les performances de notre système sont optimales lorsque TAB . 4 – Optimisation des paramètres ttable-limit et ttable-threshold 
Modèle     ttable-limit    ttable-threshold      Bleu Trig-100         22               0, 04          28, 95 M3            53               0, 00          28, 27 le décodeur restreint son espace de recherche aux 22 meilleures traductions par mot français dont la probabilité est supérieure ou égale à 0, 04. Celles du système M3 le sont lorsque le décodeur réduit son espace de recherche aux 53 meilleures traductions pour un mot français sans contrainte sur la valeur des probabilités. Notre syst è me fondé sur les triggers inter-langues apporte une amélioration de 2, 4% en termes de score BLEU par rapport au système état de l’art.
5 Conclusion et perspectives 
Nous avons présenté dans cet article une alternative aux modèles d’IBM pour la traduction statistique. La méthode est fondée sur les triggers inter-langues. Ces triggers ont été sélectionnés à partir d’un corpus parallèle aligné au niveau de la phrase extrait des actes du Parlement Européen. Ils permettent de définir pour chaque mot (français ou anglais) une liste des mots (français ou anglais) qui lui sont fortement corrélés. Ainsi un mot français est associé à une liste de mots anglais et vice versa.
Dans le but d’évaluer la pertinence des triggers inter-langues en tant que traductions potentielles, nous avons mis en place un système de traduction de mots basé uniquement sur les triggers inter-langues. Nous avons ensuite comparé ses performances à celles d’un système de référence état de l’art reposant sur les modèles d’IBM. Après optimisation des deux systèmes, les tests menés ont montré qu’en ne retenant que 22 traductions potentielles pour chaque mot français, les performances de notre système apportent une amélioration de 2, 4% du score BLEU par rapport au système de référence.
Ces premiers résultats révèlent la faisabilité de l’utilisation des triggers inter-langues en traduction automatique statistique. Par ailleurs, le concept de triggers inter-langues est un formalisme souple et nous nous sommes concentrés ici que sur des triggers d’ordre 1-1, c’est-à-dire qu’un mot est traduit par un seul mot. Nous proposons dans (Lavecchia et al., 2008) un système de traduction fondé sur les triggers d’ordre n-m, o`u plusieurs mots peuvent ê tre traduits par plusieurs mots. Ainsi, notre système devient un système de traduction de séquences de mots et non plus de mots.
A plus long terme, nous pouvons envisager beaucoup d’autres manières d’utiliser les triggers inter-langues en traduction statistique, comme par exemple en tant que mesure de confiance. De plus, nous venons de voir qu’ils permettent de prendre en compte des séquences de mots, mais Caroline Lavecchia, Kamel Smäıli, David Langlois nous pouvons également imaginer déterminer des triggers inter-langues d’autre nature que le mot comme par exemple des triggers de traits syntaxiques.
Nous pouvons aussi combiner les tables de traduction de Giza++ et les nôtres afin de mesurer leur apport respectif.
Plusieurs autres applications des triggers inter-langues ont été envisagées et sont en cours de développement dans notre groupe de recherche.

Remerciements Ce travail est subventionné par la fondation d’entreprises EADS (European Aeronautic Defence and Space Company) dans le cadre d’une thèse sur la traduction Parole-Parole 


Génération de reformulations locales par pivot pour l’aide à la révision 
Aurélien Max LIMSI-CNRS et Université Paris-Sud 11 Orsay, France aurelien.max@limsi.fr Résumé.          Cet article présente une approche pour obtenir des paraphrases pour de courts segments de texte qui peuvent aider un rédacteur à reformuler localement des textes. La ressource principale utilisée est une table d’alignements bilingues de segments d’un système de traduction automatique statistique. Un segment marqué par le rédacteur est tout d’abord traduit dans une langue pivot avant d’être traduit à nouveau dans la langue d’origine, ce qui est permis par la nature même de la ressource bilingue utilisée sans avoir recours à un processus de traduction complet. Le cadre proposé permet l’intégration et la combinaison de différents modèles d’estimation de la qualité des paraphrases. Des modèles linguistiques tentant de prendre en compte des caractéristiques des paraphrases de courts segments de textes sont proposés, et une évaluation est décrite et ses résultats analysés. Les domaines d’application possibles incluent, outre l’aide à la reformulation, le résumé et la réécriture des textes pour répondre à des conventions ou à des préférences stylistiques. L’approche est critiquée et des perspectives d’amélioration sont proposées.
Abstract. In this article, we present a method to obtain paraphrases for short text spans that can be useful to help a writer in reformulating text. The main resource used is a bilingual phrase table containing aligned phrases, a common resource in statistical machine translation.
The writer can mark a segment for paraphrasing, and this segment is first translated into a pivot language before being back-translated into the original language, which is possible without performing a full translation of the input. Our proposed framework allows integrating and combining various models for estimating paraphrase quality. We propose linguistic models which permits to conduct empirical experiments about the characteristics of paraphrases for short text spans. Application domains include, in addition to paraphrasing aids, summarization and rephrasing of text for conforming to conventional or stylistic guidelines. We finally discuss the limitations of our work and describe possible ways of improvement.
Mots-clés :            Paraphrase, Traduction Automatique Statistique basée sur les segments, Aide à la rédaction.

Keywords:          Paraphrasing, Phrase-Based Statistical Machine Translation (PBSMT), Authoring aids.
Aurélien Max 1 Introduction 
La vie d’un texte est souvent pleine de rebondissements. Un auteur peut le réviser pour lui apporter des corrections, le rendre plus court, l’adapter à un lectorat voire le traduire dans une autre langue. Lors de la phase de maturation d’un texte, celui-ci peut subir de nombreux changements avant de prendre sa forme définitive. À contenu informationnel (plus ou moins) constant, l’auteur cherche à tendre vers des formulations qui seront plus adaptées au contexte en termes de correction linguistique et de compréhensibilité. La question de la génération automatique de reformulations, même locales, et de l’évaluation de leur adaptation à leur contexte semble donc particulièrement pertinente alors que les aides à la rédaction sont encore trop peu sensibles à la nature linguistique des textes manipulés.
Des travaux en linguistique distinguent la reformulation à visée explicative, qui tente d’expliciter le sens, et la reformulation à visée imitative, qui tente de substituer des formulations équivalentes (Fuchs, 1994). Ce dernier cas pose la difficile question de la prise en compte d’un seuil de distortion au-delà duquel une reformulation n’est plus admissible. Les systèmes de transformation automatique de texte butent en effet sur la prise en compte d’un tel seuil, qui n’est pas explicité dans les principales mesures d’évaluation utilisées, telles que BLEU (Papineni et al., 2002) pour la traduction automatique ou ROUGE (Lin, 2004) pour le résumé. Une certaine modélisation de la reformulation mène à des techniques d’analyse et de reconnaissance de textes qui sont des paraphrases les uns des autres à des fins d’extraction d’informations, mais où cette notion de seuil est souvent éclipsée au profit du rappel.
Dans cet article, nous présentons une approche permettant de proposer à un rédacteur des reformulations pour de courts segments de texte (par ex. dans de bonnes conditions, maintenir le contact, la plus étroite) au cours de l’activité de révision. Ce type d’aide reprend les principes de certains travaux visant à faire des suggestions lexicales, par exemple en enrichissant des dictionnaires avec des index d’associations, telles que des mots liés thématiquement (Ferret & Zock, 2006). Dans cet article, nous commençons par décrire brièvement les travaux existant en paraphrasage automatique, puis nous décrivons les fondements de notre approche inspirée de (Bannard & Callison-Burch, 2005), qui consiste à utiliser des traductions de segments en pivot pour produire des reformulations et sélectionner parmi celles-ci celles qui sont préférées par différents types de modèles. Une évaluation est décrite et ses résultats sont analysés, ce qui met en évidence le caractère prometteur de l’approche proposée et suggère de nouvelles voies de recherche. En particulier, nous soulignons l’importance d’utiliser le contexte de la phrase d’origine contenant le segment à paraphraser pour le choix des segments pivots, importance qu’on retrouve dans le domaine de la traduction automatique.
2 Travaux antérieurs 
La possibilité d’utiliser de grands corpus comparables et parallèles a suscité récemment une vague de travaux autour du paraphrasage. Des travaux ont par exemple porté sur l’apprentissage et l’utilisation de paraphrases pour améliorer des tâches telles que la recherche d’informations précises (Duclaye et al., 2003) ou la déduction sur textes, et des applications texte-à-texte, telle que la traduction automatique (Callison-Burch, 2007), ou encore l’évaluation de ce type d’applications en traduction (Kauchak & Barzilay, 2006) ou en résumé (Zhou et al., 2006).
Génération de reformulations locales par pivot pour l’aide à la révision Les systèmes de génération automatique de texte non-déterministes offrent un cadre naturel pour la génération de paraphrases, dont les plus « naturelles » peuvent être sélectionnées par un modèle de langue (Landkilde & Knight, 1998). Si un point fort de ce type d’approche est qu’il est possible de produire des paraphrases de nature très différentes, la construction d’un tel système permettant de produire une grande variabilité de textes en sortie est difficile, et ces systèmes attendent des entrées qui sont soit sous forme de concepts, soit sous forme de spécifications de phrases.
Des alignements appris à partir de corpus comparables (monolingues) permettent de générer des reformulations en se passant d’un tel générateur. Par exemple, (Barzilay & Lee, 2003) apprennent des treillis factorisant l’ensemble des reformulations possibles au niveau des phrases, ce qui est rendu possible par la nature même de leur corpus d’apprentissage (documents journalistiques décrivant les mêmes événements). Pour une phrase en entrée, si un treillis qui lui correspond est trouvé, celui-ci est utilisé pour produire un ensemble de formulations correspondant aux chemins du treillis. Si ce type d’approche peut parfois produire de très bonnes reformulations phrastiques, une bonne couverture des phénomènes linguistiques s’avère difficile à obtenir. En outre, des reformulations plus locales sont moins susceptibles d’altérer le sens des phrases. (Quirk et al., 2004) proposent une approche consistant à apprendre un système de traduction statistique sur un corpus monolingue de phrases alignées automatiquement à partir d’un corpus comparable, qui fonctionne par décodage monotone et donc opère par reformulations locales. Si cette absence de transformations profondes est souvent perçue comme l’une des principales limitations des systèmes de traduction statistiques actuels, elle permet néanmoins de limiter les risques de déformation du sens. D’autres travaux ont exploité des corpus parallèles monolingues, comme différentes traductions d’un même texte, pour apprendre des treillis permettant de générer des paraphrases (Pang et al., 2003).
Si ces approches s’attaquent toutes au paraphrasage d’énoncés complets, il est également intéressant de proposer des reformulations pour des unités plus petites. À partir de corpus parallèles bilingues, ressources traditionnelles pour l’apprentissage des systèmes de traduction statistique, (Bannard & Callison-Burch, 2005) ont proposé une approche pour le paraphrasage de courts segments de mots par traduction dans une langue puis par rétro-traduction et sélection dans la langue d’origine. Le problème de la validité d’une paraphrase en contexte pose notamment la question de la prise en compte de son contexte d’apparition, problème qui a récemment été abordé en traduction automatique statistique (Stroppa et al., 2007). Des travaux existent au niveau des paraphrases lexicales, comme ceux de (Connor & Roth, 2007) qui proposent un classifieur pour décider si un mot peut en remplacer un autre dans un certain contexte.
3 Reformulation de courts segments de texte par pivot 
3.1 Description générale de l’approche 
La traduction automatique statistique (Statistical Machine Translation (SMT)) est fondée sur l’apprentissage et l’utilisation d’alignements entre mots appris sur des corpus parallèles bilingues. La SMT basée sur des segments (Koehn et al., 2003) a étendu la notion d’alignements entre segments de taille quelconque, ce qui permet une meilleure prise en compte du contexte local, sans que ces segments n’aient à correspondre à une segmentation motivée linguistiquement. Des techniques d’alignement permettent d’apprendre des probabilités de traduction de Aurélien Max F IG . 1 – Exemple de paraphrasage de segment par consultation de tables de traduction. Les valeurs indiquent la probabilité conditionnelle du segment étant donné le segment à sa gauche.

segments. Par exemple, (Koehn et al., 2003) partent d’alignements 1 → N entre mots pour une paire de langues dans les deux directions, symétrisent ces alignements en prenant leur intersection, puis construisent des alignements N → M entre mots de façon incrémentale en ajoutant des éléments de l’union des deux alignements initiaux. Pour qu’un alignement soit construit à partir des alignements existant à une itération précédente, tous les mots d’un segment source doivent être uniquement alignés avec les mots d’un segment cible et inversement. À partir de l’ensemble des segments alignés extraits d’un corpus parallèle, les probabilités de traduction sont en général estimées à partir de fréquences relatives correspondant au rapport du nombre de fois où un segment source s et un segment cible c sont alignés sur le nombre d’occurrences du segment source : P (c|s) = compte(c,s) compte(s) Des tables de traduction de segments sont créées en utilisant notamment ces probabilités entre segments. (Bannard & Callison-Burch, 2005) ont proposé d’utiliser ce type de probabilités à des fins de paraphrasage, en définissant une probabilité de paraphrasage entre des segments seg1 et seg2 qui utilise l’alignement qu’entretiennent ces deux segments avec un segment pivot dans une autre langue, pivot : ˆ 2 = arg max P (seg2 |seg1) = arg max seg                                                           P (seg2|pivot)P (pivot|seg1 )         (1) seg2 =seg1                     seg2 =seg1 pivot Dans l’équation 1, la recherche se fait en excluant le segment d’origine seg1 et en sommant sur l’ensemble des pivots possibles pour une paire (seg1 , seg2 ). L’exemple de la figure 1 illustre le processus de construction de paraphrases d’un segment par pivot.
Outre la probabilité de paraphrasage décrite ci-dessus, (Callison-Burch, 2007) a utilisé différentes sources d’information pour mesurer l’importance de différents facteurs dans la qualité des reformulations1 : – qualité des alignements entre segments : la construction manuelle d’un corpus dont les alignements sont faits par un humain permet une amélioration significative de la qualité des paraphrases obtenues.
– utilisation de plusieurs corpus alignés : l’utilisation de plusieurs paires de langues pour obtenir les paraphrases (les pivots sont donc multilingues) permet d’éliminer partiellement les défauts d’alignements et d’obtenir une meilleure performance.
– contrôle du sens des segments : sans qu’il ne s’agisse de désambiguïsation sémantique des 
Dans ses expériences, Callison-Burch utilise 46 segments en anglais choisis aléatoirement parmi des expressions composées de plusieurs mots de WordNet (ex : at work, concentrate on, big business), et 289 phrases qui les contiennent. L’évaluation est alors effectuée par deux juges qui doivent attribuer aux reformulations des scores de conservation du sens (adequacy) et de caractère naturel (fluency).
Génération de reformulations locales par pivot pour l’aide à la révision segments (qui peuvent avoir, comme les mots, plusieurs sens dépendant de leur contexte d’apparition), paraphraser des segments appartenant à des phrases alignées avec des phrases dans une autre langue permet de restreindre les traductions possibles du segment, et améliore sensiblement les résultats.
– contrôle de la vraisemblance des paraphrases produites : l’utilisation d’un modèle de langue trigramme permet d’améliorer la grammaticalité des paraphrases produites, mais a un impact négatif sur la conservation du sens.
Notre travail se base sur cette approche en proposant une intégration de différents modèles pour aider à la sélection des paraphrases. L’utilisation d’un corpus de paraphrases évaluées par un humain peut alors servir à étudier la contribution de chacun des modèles, en particulier dans une tâche d’aide à la reformulation. Le score d’une reformulation peut être évalué en utilisant une combinaison linéaire de logarithmes correspondant à des scores de modèles telle que traditionnellement utilisée en SMT2 (M représente les modèles utilisés, et λm et hm représentent respectivement le poids et la fonction de score d’un modèle) : ˆ 2 = arg max P (seg2 |seg1 ) = arg max seg                                                       λm hm (seg1 , seg2 )              (2) seg2                             seg2 m∈M 3.2 Modèles pour la sélection des reformulations 
Nous présentons dans cette section les modèles que nous avons utilisés pour évaluer les reformulations.3 Modèle pivot (P IV) Nous utilisons un score dérivé de la probabilité de paraphrasage de (Bannard & Callison-Burch, 2005) en utilisant une seule langue pivot, qui nous servira de référence (baseline) : P iv(p1, p2 ) = log(           P (p2 |pivot)P (pivot|p1))                         (3) pivot Modèle de conservation de dépendances (D EP) Ce modèle vise à prendre en compte une certaine proportion des relations de dépendance qui sont conservées par la reformulation. Il prend en compte les dépendances externes au segment avant et après reformulation (resp. D1extra et D2extra ) sous la forme (dépendance, gouverneur, dépendant), ainsi que les dépendances entrant ou sortant du segment avant et après reformulation (resp. D1inter et D2inter ) sous la forme (dépendance, cible_hors_segment) : 
1 + |D1extra ∩ D2extra | + |D1inter ∩ D2inter | Dep(p1 , p2 , context) = log                                                                    (4) 1 + |D1extra| + |D1inter | 
L’approche choisie pourrait suggérer l’utilisation de systèmes de SMT complets pour le paraphrasage par pivot d’énoncés entiers, mais les performances des systèmes actuels, qui butent notamment sur la prise en compte du contexte source et sur la conservation du sens et de la grammaticalité en cible, rendent pour le moment cette approche problématique. (Quirk et al., 2004) attaquent eux ce problème avec un système SMT appris avec des alignements monolingues, ce qui constitue une voie de recherche intéressante.

Nous avons également fait des expériences avec des modèles basés sur les catégories morphosyntaxiques des mots, comme par exemple modélisant la probabilité de la suite de catégories d’un segment étant donné son contexte constitué des catégories à gauche et à droite du segment, mais ces modèles n’ont permis d’améliorer les résultats que nous présenterons en section 4.
Aurélien Max Le schéma ci-dessous illustre les cas où deux dépendances entrante et sortante sont retrouvées (reformulation A) et où une dépendance entrante n’est pas retrouvée (formulation B).
Modèle de lemmes (L EM) Ce modèle mesure une certaine proportion de lemmes de mots pleins communs au segment initial p1 et au segment après reformulation p2 (resp. L1 et L2 ) : 
1 + |L2| − |L1 ∩ L2 | Lem(p1 , p2 ) = log                                                (5) 1 + |L1 ∪ L2 | 4 Expériences et évaluation Les tables de traduction utilisées ont été apprises par la méthode décrite dans la section précédente sur les parties française et anglaise du corpus Europarl4 , qui comprend environ 1,2 million de phrases alignées. Les tables contiennent environ 42 millions de segments alignés (d’une taille maximale de 10 éléments (tokens)) avec des scores de traduction dans les deux directions. Nous avons choisi de travailler avec le français comme langue principale (et donc l’anglais comme seule langue pivot pour le moment), ce qui rend plus manifeste le besoin d’utiliser des segments rendant compte des dépendances ainsi que des accords entre mots qui en découlent. Nous avons utilisé l’analyseur syntaxique robuste pour le français S YNTEX (Bourigault et al., 2005) pour obtenir une segmentation en unités lexicales, la lemmatisation de ces unités et une analyse en dépendances. Outre les modèles décrits en section 3.2, nous avons utilisé un modèle de langue 5-grammes (5 GRAM) appris sur la partie française du corpus avec un lissage Kneser-Ney.
Nous avons constitué manuellement un corpus de test de 82 phrases issues d’une partie du corpus Europarl n’ayant pas servi à l’apprentissage des modèles de traduction et du modèle de langue. Pour chacune de ces phrases, un évaluateur à qui il était demandé de simuler la tâche d’un rédacteur en phase de révision a choisi un segment d’intérêt pour la reformulation, celui-ci étant accepté s’il appartenait à la table de traduction français → anglais (ex : dans de bonnes conditions, maintenir le contact, attendent avec impatience, la plus étroite, etc.).
Nous souhaitions disposer d’un corpus pouvant servir de référence pour différentes expériences impliquant plusieurs modèles. Ne disposant pas d’une métrique automatique acceptable pour évaluer la qualité des reformulations, et souhaitant ne pas avoir à conduire plusieurs évaluations manuelles, nous avons construit automatiquement un premier ensemble de reformulations pour chaque couple (phrase, segment à paraphraser). Afin de limiter le travail d’évaluation, nous avons choisi de ne retenir au plus que les 20 premières reformulations en utilisant P IV seul (ce qui de fait introduit un biais dans nos expériences, en restreignant l’ensemble des reformulations considérées). Pour chacune des 1648 phrases à évaluer, les juges avaient à indiquer les scores suivants sur une échelle de 1 à 5 : – score de grammaticalité : indique si la paraphrase est grammaticalement correcte en l’état (5), nécessite différents niveaux de révision (4 à 2) ou est complètement inexploitable (1).

Version du corpus utilisée pour la tâche WMT08 (http://www.statmt.org/wmt08).
Génération de reformulations locales par pivot pour l’aide à la révision Résultat au premier rang           Résultats au 8 premiers rangs gram. sens rédact. moy.              gram. sens rédact. moy.
P IV (baseline)    4.46 4.18       3.62    4.09        11.66 10.60       9.10    10.45 5 GRAM     4.28 3.62       3.45    3.78        11.52 9.72        9.20    10.15 D EP    4.35 3.68       3.43    3.82        11.47 9.70        8.91    10.03 L EM    4.05 3.21       3.28    3.51        10.68 8.74        8.59     9.33 P IV +5 GRAM      4.65 4.06       3.82    4.18        11.95 10.30       9.58    10.61 P IV +D EP    4.58 4.27       3.66    4.17        11.85 10.68       9.38    10.64 P IV +L EM     4.37 4.00       3.76    4.05        11.53 10.14       9.56    10.41 5 GRAM +D EP       4.49 3.81       3.68    3.99        11.79 9.95        9.51    10.42 5 GRAM +L EM       4.28 3.59       3.56    3.81        11.46 9.57        9.37    10.13 P IV +5 GRAM +D EP        4.65 4.05       3.92    4.21        12.04 10.35       9.71    10.70 P IV +5 GRAM +L EM        4.61 4.02       3.97    4.20        11.86 10.11       9.74    10.57 P IV +D EP +L EM      4.57 4.17       4.02    4.25        11.82 10.33       9.81    10.65 5 GRAM +D EP +L EM         4.37 3.69       3.64    3.90        11.65 9.75        9.54    10.31 P IV +5 GRAM +D EP +L EM         4.68 4.09       4.05    4.27        12.01 10.24       9.87    10.71 F IG . 2 – Résultats de l’évaluation automatique sur les 82 phrases de notre corpus d’évaluation (les notes au premier rang sont entre 1 et 5, et entre 2.71 et 13.59 pour les 8 premiers rangs) 
– score de conservation du sens : indique si la paraphrase reprend exactement le sens de la phrase d’origine (5), comporte différents niveaux d’ajout ou de retrait d’information (4 à 2) ou est d’un sens complètement différent (1).
– score d’intérêt pour un rédacteur : indique si la paraphrase pourrait être réutilisée en l’état pour une reformulation (5), avec une modification mineure (4), présente des éléments intéressants qui peuvent participer à une reformulation (3), présente des éléments qui peuvent suggérer une reformulation (2) ou correspond à du bruit (1).
Les scores sont obtenus en prenant la moyenne des scores de deux juges francophones.5 Le tableau de la figure 2 présente les résultats obtenus par différentes combinaisons de modèles pour notre corpus d’évaluation.6 Nous avons ici décidé d’utiliser des poids λm uniformes pour la combinaison des modèles, leur optimisation automatique en fonction de caractéristiques choisies par un utilisateur faisant partie de nos travaux futurs. Le deuxième groupe de colonnes indique les moyennes des différents scores et leur moyenne pour la reformulation classée au premier rang. Le troisième groupe de colonnes donne un score combinant les scores des 8 meilleurs résultats7 , calculé comme suit : 8rang=1 rang1 score(rang).
En ce qui concerne la grammaticalité des paraphrases, les modèles P IV et 5 GRAM sont les meilleurs contributeurs. La performance de P IV peut s’expliquer par la nature des alignements, dont les plus forts peuvent correspondre à des patrons morpho-syntaxiques cohérents. La contribution d’un modèle de langue était attendue, mais on constate que 5 GRAM seul a une performance légèrement inférieure à D EP. La combinaison P IV +5 GRAM mène cependant à une 
L’écart-type des différences de scores entre les deux juges est de 0.59 pour la grammaticalité, 0.7 pour la conservation du sens, et 0.8 pour l’intérêt pour un rédacteur, ce qui rend assez bien compte des différents niveaux de subjectivité de ces scores.

Contrairement à ce qui se passe en traduction statistique sur des phrases complètes, la taille de notre espace de recherche permet ici une exploration complète, et l’on a donc la garantie de trouver le meilleur score global (parmi les résultats présélectionnés par P IV).

Ce type de mesure est motivé par la finalité de nos travaux, i.e. proposer un nombre raisonnable de suggestions de reformulation à un rédacteur.
Aurélien Max meilleure performance que la combinaison P IV +D EP, ce qui semble indiquer que P IV et D EP opèrent des sélections plus similaires que P IV et L M. À l’examen des données, il apparaît qu’obtenir des reformulations grammaticales requiert parfois des modifications en dehors du segment.
Il serait possible d’essayer d’étendre les segments automatiquement en cherchant à obtenir des reformulations de meilleure qualité, mais en conservant l’approche actuelle, on peut remarquer qu’un critère strict de grammaticalité n’est pas nécessairement le plus important pour le rédacteur.
L’évaluation au niveau de la conservation du sens fait ressortir qu’il est difficile de faire mieux que la baseline P IV. Il s’agit cependant certainement là d’un biais imputable au corpus d’apprentissage des tables de traduction (les débats parlementaires européens), qui contient vraisemblablement peu d’ambiguïtés sémantiques au niveau des segments dont les scores d’alignement sont les plus forts. Si la combinaison avec d’autres modèles a plutôt tendance à dégrader les scores, car ils entraînent vraisemblablement une déformation du sens en préférant des énoncés grammaticaux, le modèle D EP entraîne une amélioration lorsque combiné avec P IV, alors que seul il obtient une performance bien moindre. La conservation des relations de dépendances, et en particulier du type de celles-ci pour les dépendances entrant ou sortant dans le segment paraphrasé, participe certainement à cela.8 La dégradation observée avec P IV +5 GRAM est cohérente avec les résultats obtenus par (Callison-Burch, 2007). Les scores observés en utilisant le modèle L EM semblent indiquer que les reformulations contenant plusieurs mots pleins différents correspondent fréquemment à des sens jugés différents.
Les meilleurs résultats concernant l’intérêt pour le rédacteur sont obtenus en combinant tous les modèles. On constate qu’une mauvaise grammaticalité ou une mauvaise conservation du sens ont tendance à pénaliser ce score, ce qui est cohérent avec les directives d’évaluation. Le modèle 5 GRAM se combine à nouveau favorablement avec P IV, et toutes les combinaisons impliquant P IV améliorent le score obtenu par ce modèle seul. Le modèle L EM permet d’améliorer les résultats, vraisemblablement parce qu’il permet de favoriser les reformulations les plus différentes du segment d’origine, qu’un rédacteur peut juger plus utiles qu’un segment très proche.
Il permet ainsi parfois de sélectionner des reformulations qui obtiennent par ailleurs de mauvais scores en grammaticalité et/ou en conservation du sens, comme dans l’exemple suivant : Phrase d’origine : ceux qui viennent dire ici que l’ europe ne doit pas adopter de directive énonçant les valeurs que nous voulons tous défendre se trompent .
Reformulation : ceux qui viennent dire ici que l’ europe ne doit pas adopter de directive énonçant les valeurs que nous voulons tous défendre devrions à nouveau réfléchir .
L’évaluation prenant en compte les 8 premiers résultats ne fait pas ressortir de différences significatives avec le résultat au premier rang. Les exemples ci-dessous illustrent deux cas où les premières propositions du système en combinant tous les modèles obtiennent de très bons scores : Phrase initiale : et , à cet égard bien précis , je suis d’ accord avec vous , monsieur le commissaire Reformulations : je partage votre point de vue, je pense comme vous, je partage votre avis, je vous rejoins 
Ce type de modèle dépend cependant très fortement de la robustesse de l’analyseur syntaxique utilisé pour analyser des énoncés plus ou moins corrects.
Génération de reformulations locales par pivot pour l’aide à la révision Phrase initiale : notre voisin s’ est efforcé résolument pendant la décennie écoulée de remplir les critères de l’ adhésion .
Reformulations : satisfaire aux exigences, satisfaire aux conditions, répondre aux exigences, respecter les exigences, répondre aux critères, remplir les conditions, satisfaire aux critères 5 Conclusions et perspectives 
Dans cet article, nous avons décrit une approche inspirée de (Bannard & Callison-Burch, 2005) pour produire des reformulations locales en utilisant des tables de traduction de segments et en combinant les scores de différents modèles. Nos évaluations, basées sur trois critères dont un concernant directement l’intérêt des reformulations proposées pour le rédacteur, ont plus particulièrement permis de dégager la contribution de notre modèle basé sur la conservation des relations de dépendance entre un énoncé et ses reformulations. Cependant, l’approche proposée comporte de nombreuses limitations, que nous nous efforcerons de corriger dans nos travaux ultérieurs.
La principale source d’amélioration selon nous consiste à mieux prendre en compte le contexte du segment à paraphraser dans la phrase source. Alors que (Callison-Burch, 2007) a montré l’importance de la prise en compte du contexte pour la génération de paraphrases, ses expériences se sont basées sur un choix de pivot issu directement d’un corpus parallèle bilingue, ce qui revient à faire une désambiguïsation supervisée. Des travaux récents en traduction statistique tels que (Stroppa et al., 2007) ont montré la possibilité d’intégrer dans des systèmes basés sur des segments des modèles permettant d’améliorer la sélection des segments cibles.9 Nous travaillons par ailleurs sur ces aspects dans le cadre d’un système de traduction statistique basé sur des segments, et espérons que les résultats bénéficieront au travail présenté ici.
Nous allons par ailleurs poursuivre l’analyse de nos données pour proposer de nouveaux modèles, permettant par exemple de regrouper des sens dans les segments. Dans le cadre d’une intégration dans un système d’aide à la reformulation, nous serons intéressé par la possibilité de corriger les paraphrases produites, pour respecter par exemple des contraintes d’accords grammaticaux. Il nous semble également intéressant de travailler sur le problème du repérage des segments qui seraient de bons candidats à la reformulation (gallicismes en anglais, phraséologie mal adaptée à un genre documentaire, etc.). En outre, nous aurons à considérer l’intégration de segments alignés provenant de corpus comparables, qui sont des ressources beaucoup plus faciles à construire que les corpus alignés. Enfin, ce type de recherche devrait tendre vers plus de généralisation dans le processus de reformulation, et la possibilité de produire des paraphrases plus profondes au niveau d’énoncés, voire de discours. Un type d’application particulièrement intéressant serait alors l’aide à la condensation d’articles scientifiques pour tenir dans des contraintes de taille imposées.
Remerciements L’auteur remercie Daniel Déchelotte pour la préparation de certaines données utilisées dans ce travail, et Didier Bourigault pour l’utilisation de S YNTEX.

Il est possible cependant que la nature des corpus utilisés ne permette pas d’amélioration très sensible des résultats, car le besoin de désambiguïsation est peut-être assez faible dans l’ensemble.
Aurélien Max 

Les architectures linguistiques et computationnelles en traduction automatique sont indépendantes 
Christian BOITET 
Laboratoire LIG, GETALP – Université Joseph Fourier, 385 rue de la bibliothèque, BP 53, 38041 Grenoble, Cedex 9, France Christian.Boitet@imag.fr Résumé Contrairement à une idée répandue, les architectures linguistiques et computationnelles des systèmes de traduction automatique sont indépendantes. Les premières concernent le choix des représentations intermédiaires, les secondes le type d'algorithme, de programmation et de ressources utilisés. Il est ainsi possible d'utiliser des méthodes de calcul « expertes » ou « empiriques » pour construire diverses phases ou modules de systèmes d'architectures linguistiques variées. Nous terminons en donnant quelques éléments pour le choix de ces architectures en fonction des situations traductionnelles et des ressources disponibles, en termes de dictionnaires, de corpus, et de compétences humaines.
Abstract     Contrary to a wide-spread idea, the linguistic and computational architectures of MT systems are independent. The former concern the choice of the intermediate representations, the latter the type of algorithm, programming, and resources used. It is thus possible to use "expert" or "empirical" computational methods to build various phases or modules of systems having various linguistic architectures. We finish by giving some elements for choosing these architectures depending on the translational situations and the available resources, in terms of dictionaries, corpora, and human competences.
Mots-clés : Traduction Automatique, TA, TAO, architecture linguistique, architecture computationnelle, TA experte, TA par règles, TA empirique, TA statistique, TA par l'exemple Keywords: Machine Translation, MT, linguistic architecture, computational architecture, expert MT, rule-based MT, empirical MT, statistical MT, example-based MT.
Introduction Il y a un certain nombre d'idées fausses qui circulent parmi les chercheurs en TA, et freinent à notre avis les progrès dans ce domaine. La première est que la plupart des systèmes opérationnels utilisent la TA statistique, alors que la plupart (voir le Compendium (Hutchins & al. 2005) publié par l'EAMT) utilisent des méthodes « expertes » (« à règles », mais pas seulement à règles). L'autre est que les systèmes utilisant un « pivot interlingue », évidemment très adapté à la communication multilingue, sont nécessairement « à règles » (TAFR, en anglais RBMT ou « rule-based MT »), et donc très coûteux à construire (ce « donc » est faux aussi…).
Il ne faut pas faire l'amalgame entre l'architecture linguistique d'un système de TA, caractérisée par les représentations intermédiaires qu'il utilise durant le processus de traduction, et son architecture computationnelle, caractérisée par les méthodes de calcul et les ressources utilisées dans ses diverses « phases » transformant une représentation intermédiaire en sa suivante dans le processus.
Christian BOITET 
Après une brève partie consacrée aux définitions des variantes de ces architectures, nous montrerons que, pour à peu près chaque architecture linguistique, on trouve des systèmes utilisant diverses architectures computationnelles. De plus, une bonne partie des systèmes utilisent plusieurs architectures computationnelles dans leurs différentes phases. Nous essaierons enfin de dégager quelques indications sur les choix d'architecture appropriés aux diverses situations traductionnelles et des ressources disponibles, en termes de dictionnaires, de corpus, et de compétences humaines.
1 Architectures des systèmes de TA 
1.1 Architectures linguistiques Ces architectures correspondent aux « chemins » dans le fameux « triangle de Vauquois ».
Figure 1 : triangle de Vauquois (Vauquois & Boitet 1985, Analectes de Vauquois — Boitet 1988) Les systèmes directs n'utilisent que deux représentations, le texte d'entrée et le texte de sortie. Pour les langues ayant des systèmes d'écriture à séparateurs de mots ou de syllabes, le texte d'entrée n'est souvent pas strictement le flot de caractères tel quel, mais une suite de « mots typographiques » séparés grâce à des règles simples. Les systèmes semi-directs ont une phase de segmentation ou d'analyse morphologique, voire morphosyntaxique, et une phase de génération morphologique. C'est le cas des systèmes de « première génération » (russe-anglais aux USA et anglais-russe en URSS dès les années 1950), et un certain nombre de systèmes commerciaux actuels sont toujours de ce type.
Il existe au moins 7 variantes des systèmes à transfert. La structure obtenue en fin d'analyse peut être syntagmatique (basée sur des constituants la plupart du temps connexes), ou bien dépendancielle, et dans ce cas surfacique (fonctions syntaxiques comme sujet, objet direct, épithète, attribut…) ou profonde (relations sémantiques comme agent, patient, cause, concession…). Les systèmes à transfert profond fondés sur les théories de Tesnière, puis de l'Ecole de Prague et de celle de Moscou, utilisent des représentations logico-sémantiques distinguant les arguments des circonstants.1 
Les circonstants portent des relations sémantiques (cas profonds), tandis que les arguments ne portent en général qu'un numéro (Arg0, Arg1… Arg4 ou Arg5 au maximum), car il est très difficile sinon impossible d'affecter fiablement une relation sémantique à un argument, si le répertoire de ces relations est celui utilisé pour les circonstants. Le projet FrameNet montre d'ailleurs bien que, si on veut définir des relations Indépendance des architectures linguistiques et computationnelles en traduction automatique 
On dit qu'il y a « transfert lexical » quand on passe directement de « l'espace lexical » de la langue source à celui de la langue cible. Par « espace lexical », on entend tout le système lexical, qui va des « formes » de surface aux « acceptions », en passant par les lemmes et éventuellement par les « unités lexicales » (familles dérivationnelles) ou « prolexèmes » (les mêmes, un peu élargies).
Le « pivot hybride » (terme dû à Shaumyan) des systèmes du CETA des années 1965-70 était un type de représentation utilisant des attributs et relations interlingues, et des unités lexicales de chacune des langues. Ces systèmes étaient donc à transfert simple, alors qu'on a un double transfert en « pivot ».
Les structures multiniveau de Vauquois sont basées sur un graphe syntagmatique abstrait (suppression des auxiliaires, regroupement de lexèmes discontinus comme give...up, etc.), lexicalisé (chaque nœud interne domine un « gouverneur » lexical), et contenant aussi bien les informations et relations profondes que celles de surface. De telles structures sont « génératrices » des structures mononiveau usuelles, et offrent une sorte de « filet de sécurité ».
Les systèmes à véritable interlingua (comme ATLAS-II de Fujitsu ou PIVOT/Crossroads de NEC, ou KANT/CATALYST de CMU/Caterpillar, ou UNL, ou MASTOR-1 d'IBM, ce dernier en TA de parole) utilisent 3 espaces lexicaux, car un véritable interlingua possède son propre vocabulaire, même si ce vocabulaire est construit comme union des acceptions2 d'un certain nombre de langues, comme UNL (Uchida 1996, 2004). Dans les systèmes de TA, il existe des interlinguas « linguisticosémantiques » (comme KANT, ULTRA, UNL) dont les « lexèmes » sont construits à partir des lemmes et des lexies de dictionnaires d'une ou plusieurs langues naturelles, et des interlinguas « sémantiques » ou « sémantico-pragmatiques », dont les lexèmes sont construits à partir des entités, propriétés, actions et processus d'un domaine précis et d'un ensemble de tâches bien identifiées (par exemple, réservation touristique).
Enfin, si la plupart des systèmes de TA ont comme « unité de traduction » le « segment » (phrase ou titre) des systèmes d'aide au traducteur utilisant des mémoires de traductions, certains ont des unités de traduction de l'ordre de la page (Ariane-G5), ce qui permet de mieux traiter certains phénomènes comme la concordance des temps et de résoudre des anaphores hors du contexte de la phrase.

1.2 Architectures computationnelles Pour ce qui est des processus automatiques, on distingue entre méthodes expertes et méthodes empiriques. Il y a aussi des distinctions à faire si le processus de traduction est interactif.

1.2.1      Méthodes « expertes » Les méthodes « expertes » sont plus ou moins procédurales ou déclaratives, et font appel à de la programmation directe ou fondée sur des « modèles de calcul » abstraits, d'où l'utilisation de LSPL (langages spécialisés pour a programmation linguistique). On a en bref : •      la programmation directe dans un langage algorithmique classique (souvent employée au niveau des traitements typographiques ou morphologiques).
•      la programmation directe dans un langage de haut ou très haut niveau (Lisp, Prolog) offrant des structures de données et de contrôle plus adaptées à la programmation linguistique, mais demandant une grande expertise en programmation.
•      la programmation dans des LSPL d'automates (comme les transducteurs finis, les ATN ou les transformateurs d'arbres, abusivement dits « grammaires » transformationnelles).
•      la programmation dans des formalismes de grammaires déclaratives (ou presque) comme LFG, GPSG, HPSG, ou TAG.

sémantiques pour les arguments, il faut le plus souvent les lexicaliser ("donner" aura alors "donateur/donneur" pour Arg0, "don" pour Arg1, "donataire" pour Arg2).

Une "acception" est un sens d'un mot, au sens de lemme ou terme, dans l'usage de la langue. Une "lexie" est un sens de mot dans un dictionnaire.
Christian BOITET 
Il est abusif de parler de systèmes « à règles » pour les deux premiers. Ainsi, Systran utilise des automates (transducteurs d'états finis) pour l'analyse morphologique, tandis que l'analyse syntaxique n'est pas faite par « règles », mais par un programme instanciant un schéma procédural fixe (écriture de « macros » déterminant des décisions locales par examen d'une « fenêtre courante » sur un graphe sans boucle représentant la phrase).

1.2.2   Méthodes empiriques Ce sont les méthodes fondées sur les corpus : •   TA statistique (SMT) et TA statistique à syntagmes (PSMT, ou « phrase-based » SMT), •   TA fondée sur les exemples (EBMT), avec 3 variantes.
Notons que « TA statistique » est un assez mauvais terme, car on devrait plutôt parler de TA « probabiliste ». En effet, un « modèle de langage » est une collection de probabilités estimées d'après des comptages sur de gros ou très gros corpus.
La différence essentielle entre SMT et EBMT est que, en EBMT, les exemples sont utilisés directement durant le processus de traduction, tandis que la SMT utilise les résultats d'une sorte de gigantesque « compilation » de l'ensemble des exemples (corpus aligné).
Les variantes de l'EBMT sont les suivantes : •   En EBMT classique, on étend les techniques de recherche de segments voisins des systèmes d'aide aux traducteurs avec mémoire de traductions, et on propose, pour les mots différenciant le segment à traduire et le segment trouvé, des remplacements venant d'autres exemples ou de dictionnaires. Le système Similis™(dérivé de (Planas 1998)) d’aide au traducteur en est proche.
•   En EBMT par analogie (Lepage & Denoual 2005), si S1 est le segment à traduire (en langue L1), on cherche les « rectangles analogiques » P1:Q1::R1:S1 tels qu'on dispose des exemples de traduction (P1,P2), (Q1,Q2), (R1,R2), et on résout en X (dans la langue L2) l'équation analogique P2:Q2::R2:X. On obtient en général plusieurs traductions X, qu'on filtre pour la fluidité par un modèle n-gramme. Si on ne trouve pas de tel rectangle, on résout en Y (dans la langue L1) l'équation P1:Q1::Y:S1 et on continue récursivement. Il n'y a donc pas de « décomposition en morceaux qui se correspondent » puis de « recomposition ».
•   Dans le système EBMT par exemples de correspondances structurées de Al-Adhaileh et Tang (USM, Penang), on utilise un corpus parallèle annoté par des S-SSTC (correspondances chaînearbre structurées synchronisées). La traduction se fait par analyse-synthèse. Une correspondance (C1, A1)—c—(C2, A2) est élémentaire ou composée (= {(C1i, A1i)—ci—(C2i, A2i)}i).
Quand on en trouve une car on a identifié un morceau C1 du segment S1 à traduire, ou bien les correspondances la constituant, on a d'un seul coup les 3 autres éléments et leur synchronisation.
2 Variété des architectures computationnelles Voici maintenant une étude synthétique (non exhaustive) des architectures computationnelles utilisées dans des systèmes de TA basés sur 11 architectures linguistiques différentes. Pour la clarté, nous utilisons des tableaux, organisés de la façon la plus homogène possible. Il n’a malheureusement pas été possible de suivre la suggestion d’un relecteur, et de faire un seul grand tableau croisant les deux architectures, car trop de systèmes utilisent différentes architectures computationnelles dans différentes phases du traitement. Pour des raisons de place, il n’a pas non plus été possible de mettre autant de références qu’on l’aurait souhaité. D’un autre côté, les références sur les systèmes opérationnels (commerciaux comme Systran, ATLAS, The Translator, Honyaku-no-oo-sama, ProMT, Softissimo, Tracy, PIVOT/Crossroads, ALTFlash, METAL/Compendium, LanguageWeaver, etc., et non commerciaux ou semi-commerciaux comme PAHO-MTS, ALT/JE ou Google Translator) sont très rares et souvent anciennes. Le « Compendium » (Hutchins & al. 2005) est une source importante, mais ne donne pas de détails précis sur la façon dont les systèmes cités sont construits.
Indépendance des architectures linguistiques et computationnelles en traduction automatique 
2.1 Systèmes de traduction directe Type Étapes           Méthode               Commentaires                            Exemples RBMT Segmentation FST (règles + dict.) Convient pour des langues très voisines ATLAS-I Fujitsu,76-78 1975— Trad. mot à mot règles                japonais ↔ coréen, hindi ↔ urdu …       (coréen↔japonais) SMT Segmentation, Alignement +              SMT = première idée sur la TA par les Beaucoup de systèmes 1980— réarrangement… « décodage »           cryptographes de la 2° guerre mondiale statistiques (SMT) statistique           (W. Weaver 1949)                        IBM 1980EBMT Pas de           Résolution analogique Résultats ≈ ceux de la SMT              ALEPH 2000— prétraitement   + filtrage n-grammes Nagao 1984 (plutôt TA par similarité) ATR 2000EBMT « pure » analogique              Lepage 2000 (vraie analogie à 4 termes) GREYT, Caen 2006— Le plus souvent, ces systèmes sont « empiriques », mais certains utilisent une approche « experte », comme ATLAS-I (différent de ATLAS-II).

2.2 Systèmes de traduction semi-directe Type   Étapes            Méthode                   Commentaires         Exemples 1G-MT Segmentation & Consultation de               Tables + macros sur  GAT (Georgetown) 1950— Lemmatisation par dictionnaire + "macros"    des chaînes          EURATOM, Ispra, 1965—69 programme         de réarrangement          procédural           SPANAM-1, PAHO, ≈1975— procédural                                     GLOBALINK ← Spanam-1 (PAHO) SMT Lemmatisation        Procédural + règles       Modèle de langue     Candide IBM, 1980—, Google 20051990— Décodage           statistique               probabiliste         Beaucoup de systèmes statistiques Trad. Lemmatisation      Traitement de chaînes     procédural (snobol4) Idée de B. Harris pidgin Transfert lexical règles en systèmes-Q      Énoncé =             (TAUM, « traductologiste ») Réarrangement     --                        graphe de chaînes    rus → eng, fre (Boitet 1972) Génération        --                        d'arbres étiquetés GlobaLink a été fait à partir d'une copie de Spanam-1. Spanam-2 est de type expert (ATN).
Les systèmes actuels de Google sont (sans doute) plus PSMT (phrase-based SMT) que SMT.

2.3 Systèmes à transfert descendant de constituants Type Étapes                  Méthode               Commentaires        Exemples RBMT Analyse par ATN         LSPL étendant Lisp ou règles + dict. +    ENGSPAN, SPANAM-2, ou 1970—                        un autre Lprog        transformation      ‘PAHO-MTS’ (PAHO, ≈1978—) Transfert/génération   Descente récursive    procédural + règles AS-Transac (Toshiba, 1982—) Reverso ProMT, 1986— RBMT    Analyse par ECFG LSPL étendant Lisp ou grammaire+dict.         METAL (TUA+Siemens, 1982—) 1980—   (hors-contexte        un autre Lprog       règles              Duet-2 (Sharp, 1984—) étendu)                                                        Shalt-1 (IBM-Japon, 1982—) Transfert /génération Descente récursive   procédural + règles Kate KDD (1983—) RBMT    Lemmatisation         Dictionnaire +tables procédural          LMT (IBM-US, 1983—) 1984—   Slot-grammars         LSPL étendant Prolog règles              PT-1 (Personal Tanslator) de T+G en Prolog         Descente récursive   procédural + règles Linguatec, dérivé de LMT, —2000 Les systèmes récents de type PSMT de LanguageWeaver sont sans doute aussi de ce type.

2.4 Systèmes à transfert descendant de dépendances Type    Étapes                  Méthode                            Commentaires          Exemples 1.5G-MT Lemmatisation           FST (+ dictionnaires)              règles                Systran 1990— 1990— Analyse produisant un     macros C + dictionnaire            procédural graphe de dépendances   Descente récursive                 procédural Transfert /génération RBMT Segm.+ lemmatisation       dictionnaire + tables              procédural            JETS (IBM-Japon, 1985— Analyse de                LSPL pour les grammaires de        grammaire + dict.     1985-90) dépendances             dépendances + contraintes          règles Désamb. interactive     limitées (1 seul quantificateur)   contraintes Transfert /génération   Descente récursive                 procédural + règles Christian BOITET 
RBMT     Segmentation et          Programmation                       procédural + règles        Neon (Xiamen) /SMT     lemmatisation multiple   en Pascal puis C                    Version hybride            En-Ch & Ch-En, 2000—    Analyse de               + dictionnaire                      (TA experte + SMT)         2000— dépendances              Algorithme factorisant (DP)         depuis 2006 Tranfert/génération      Descente récursive                  + statistiques Systran est très ancien (1966), mais depuis 1990 environ il intègre des FST pour les traitements morphologiques, et les macros utilisées pour la suite du traitement sont développées en C et plus en assembleur. Dans JETS (ancêtre de Honyaku no oo-sama, actuellement commercialisé par IBMJapon), les dépendances sont les « cas profonds » correspondant aux particules casuelles du japonais.

2.5 Systèmes à transfert horizontal de constituants Type Analyse/données       Transfert/préparation        Génération/méthode           Exemples RBMT Lemmatisation +       Contient la génération       Descente récursive           PT (= LMT d'IBM) 1995— Slot Grammars        Prolog                       grammaire+dict.              Linguatech, 1995—2000 règles               procédural + dict.           règles EBMT Données initiales:    Préparation: construction    Traduction: 3 étapes         « EBMT » (ou ‘Banturjah’) 2000— corpus // bilingue   autom. de S-SSTCs puis       en parallèle (A//T//G)       UTMK, USM, 2000— dictionnaire         édition (humaine)            combinaison ascendante       basé sur un corpus de S-SSTC PSMT Lemmatisation         Alignement                   Aplatissement de l'arbre     LanguageWeaver 2002— PSCFG Chunking             Décodage                     Post-traitement              Google 2005— 2002— statistique          statistique                  statistique                  +Wu, Melamed 1997, 2004 La différence avec les systèmes précédents est que le transfert produit une structure de même nature que ce que produirait l'analyse de l'unité de traduction cible. Cela permet éventuellement de composer deux systèmes de TA en perdant beaucoup moins d'information et en introduisant beaucoup moins d'erreurs qu'en mettant bout à bout deux systèmes complets, i.e. en passant par un « pivot textuel ».

2.6 Systèmes à transfert horizontal de dépendances Type     Analyse                  Transfert                       Génération               Exemples RBMT     Grammaire + dict.        Dictionnaires                   Aplatissement de l'arbre ETAP-2, ETAP-3 1975—    Anal. de dépendance      Transformations d'arbres        grammaire+dict.          IPPI, Moscou, 1977— règles                   règles                          règles RBMT     Lemmatisation +          Dictionnaire de « treelets »    Aplatissement de l'arbre TDMT, Furuse (prototype 1992—    patrons linéaires        + thesaurus sémantique          grammaire+dict.          pour la TA de parole) règles                   règles                          règles                   ATR, 1992—1998 RBMT+ Analyseurs de MSR           Apprentissage du transfert Générateurs de               MTS-1 SMT   (Microsoft)                 à partir de paires (lf_s, lf_t) Microsoft               (prototype sur de la 1999— règles (en G)               statistique                     règles (en G)           documentation technique) LMT (MacCord, IBM), est rangé ici car les « slots » correspondent à des fonctions syntaxiques.

2.7 Systèmes à transfert multiniveau horizontal Type Étapes                            Méthode                     Commentaires               Exemples RBMT Lemmatisation                     Dictionnaire + tables       procédural + dict.         ITS-2 (Genève, 1990—) 1990— Analyse multiple par ECFG        Programmation en            dict. + grammaire (gouvernement & liage)           langage évolué              procédural + règles Désambiguïsation interactive     (Modula)                    interactif si pas assez de place            --                          procédural + règles Transfert autonome               --                            + dictionnaire Génération                       descente récursive          aplatissement de l'arbre RBMT Lemmatisation +                   LSPL grammatical,           procédural + dict.         PT-2 (Linguatec et 2000— Slot Grammars                    analyse multiple            dict. + gram.              Lingenio) depuis 2000 Transfert autonome               dictionnaire de treelets    procédural + règles Génération                       descente récursive          (en Prolog) Passer d'une architecture à transfert descendant à celle de transfert « horizontal » a été très difficile (communication personnelle de K. Eberle de Linguatec à COLING-2000). Cela a été aussi tenté sur METAL (par Siemens puis Sietech), mais sans succès.
Indépendance des architectures linguistiques et computationnelles en traduction automatique 
2.8 Systèmes à transfert ascendant multiniveau Type Étapes                  Méthode                  Commentaires                  Exemples RBMT Analyse morphologique dictionnaire + automate LSPL (5 au total)                Systèmes en Ariane-G5 1978— Analyse structurale    transformations d'arbres règles                        1974Tansfert lexical       règles de réécriture     pour toutes les               ru-de→ru, en→my-th 80-87 Transfert structural   dictionnaires            phases                        fr→en (BV/aero) 85-92 Génération structurale transformations d'arbres dictionnaires pour            fr→en-de-ru (LIDIA) 90-96 Génération morphol.    dictionnaire + automate certaines phases               HICATS Hitachi (1990-) Jemah USM, NUS (1990-) Ici, le transfert produit une structure multiniveau « génératrice » dans laquelle les informations non interlingues correspondent à celles de la langue source de façon « contrastive », et sont à utiliser par le générateur comme des préférences ou des ordres en fonction des valeurs de certains attributs « tactiques ». La première phase de l'étape de génération consiste alors à « sélectionner une paraphrase » en recalculant les informations de surface.

2.9 Systèmes à transfert sémantique ou « conceptuel » Type Étapes                     Méthode                  Commentaires           Exemples RBMT Segm. +lemmatisation       Programmation en C       procédural             MU (Kyodai, 82-87) 1982— Autres phases             Transformations d'arbres règles (gram.s + dict) MAJESTIC (JICST, 87—) On pourrait ajouter les systèmes du CETA (1962-70), à « pivot hybride », décrit plus haut.

2.10 Systèmes à interlingua sémantique ou « linguistico-sémantique » Il s'agit de systèmes utilisant un interlingua muni d'un vocabulaire « autonome ».
Type Enconversion                      Déconversion          Commentaires              Exemples RBMT Lemmatisation directe             Transformations       procédural                ATLAS-II 1980— Transformations chaîne-graphe    graphe-chaîne         +                         Fujitsu, 1980— règles                           règles                règles                    PIVOT Nec, 1983— RBMT Formalisme proche des DCG         LSPL fondé sur des règles                       ULTRA NMSU, 89-95 1980— règles                           règles Prolog RBMT Selon les partenaires             Selon les partenaires graphe UNL = structure    UNL 1996— 1997— règles (jusqu'à présent)         règles                « anglo-sémantique » Les graphes UNL sont « linguistico-sémantiques ». Le vocabulaire (UW) est l'union des acceptions des différentes langues traitées, comme dans ULTRA, mais les relations sémantiques et le traitement des idiomes sont liés à l'anglais (et tant mieux, car les langues voient assez souvent différemment les relations sémantiques dans des énoncés synonymes).

2.11 Systèmes à ontologie Ces systèmes sont les seuls à faire de la « compréhension explicite », leur interlingua étant « projeté » dans une ontologie Ω, soit de façon séparée, soit de façon interne.
Type Enconversion             Projection dans une Ω     Déconversion          Examples KBMT Lemmatisation &          Oui, de tout sauf les     Planification de la   KBMT-89 CMU, 1989—91 1980— EPSG+f-structures       éléments de discours      structure profonde    KANT/Catalyst +pseudo-unification     dict. + règles            Descente récursive    CMU+Caterpillar, Règles (Univ. Parser)   + désamb. interactive     règles                en→fr-sp-de-? 1992— RBMT Dictionnaire + FST       Pas d'ontologie           dictionnaire + FST    CSTAR-II & Nespole! 1997— règles                  explicite séparée :       règles                GETA 97-03, ETRI (Corée) 97-99 SMT Appris à partir de        c'est l'idée (ancienne)   Appris à partir de    CSTAR-II & Nespole! 2003— couples (chaîne,IF)     des « grammaires          couples (IF,chaîne)   Irst 98-03 statistique             sémantiques »             statistique           Mastor-1 (IBM 2003), sur PDA L'IF (interface format) réfère à une ontologie implicite, pas explicite.
Christian BOITET 
3 Éléments pour le choix d'architectures en TA 
3.1 Taille et coût des ressources / architectures computationnelles Le tableau suivant donne une estimation des ressources nécessaires pour construire un système de TA en fonction de la difficulté de la tâche, grossièrement estimée à partir de la taille moyenne des phrases.
Les coûts sont donnés ici en homme*année (h*a), M veut dire « million », et K « mille ».
•   Pour la TA empirique, il s'agit de la taille du corpus, en mots, pages (de 250 mots), phrases, et du temps humain de préparation de ce corpus. S’il s’agit de traduction, nous utilisons le taux professionnel de 1h/page (avec la révision, ce serait 1h20 par page). S’il s’agit d’annotation, les coûts ne sont la plupart du temps pas publiés, et nous utilisons des informations dont nous disposons par communications personnelles. Le coût par page est bien plus élevé, mais le corpus peut être beaucoup plus petit, et finalement bien moins coûteux, pour de meilleurs résultats.
•   Pour la TA experte, il s'agit de la taille des dictionnaires et des grammaires, et du travail d'experts humains. Contrairement à ce qu’on lit dans de nombreux cours sur la TA qu’on peut glaner sur le Web, ce coût est souvent très surévalué, et pas seulement par les tenants des méthodes empiriques.
Phrases              6.5 mots/phrase                          25 mots/phrase Type                          BTEC, METEO                              Informations (news) SMT                           0.9—3 M mots                             50—200 M mots PSMT                          3.6—12 K pages                           200—800 K pages EBMT par analogie             0.15—0.5 M phrases                       2—8 M phrases Coût : 2.4—8 h*a                                100—400 h*a (rarement disponible !) EBMT avec arbres              N/A pour ce type de phrases courtes      4—12.5 M mots SMT                           Apprentissage supervisé                  15—50 K pages Mastor-1 (IBM)                1h/page (par recoupements)               0.15—0.5 M phrases Coût :                                          10—40 h*a EBMT avec arbres et S-SSTCs N/A pour phrases courtes                   4—12.5 M mots Banturjah (USM)               Apprentissage supervisé                  0.6—1 K pages Coût : 15 h/page (10 h/p espéré)                0.006—0.01 M phrases dictionnaire (50 K) souvent disponible   6—10 h*a (travail assez spécialisé) RBMT                          Dictionnaire 3-10 K 0.6—2 h*a            Dict. 50-500 K, soit     15—150 h*a Grammaires environ       25 h*a Coût : Total 1—3 h*a                           Total ≈ 40—175 h*a 
3.2 Brève analyse 1. Il est clair que, plus les corpus sont « bruts », plus ils doivent être grands. Même à raison de 15h/page de travail humain, il semble intéressant d'utiliser une méthode comme celle de l'USM à Penang, car on n'a besoin que de 1000 pages et d'un gros dictionnaire assez simple.
2. D'autre part, la SMT (et la PSMT) sont en fait adaptées à des « niches de riches », tout comme la TA « experte » pour sous-langages. En effet, il y a très peu de corpus parallèles disponibles de 200 à 800 K pages ! Du point de vue des corpus, les différences entre couples de langues « bien dotés » et « mal dotés » sont encore plus grandes qu'en ce qui concerne les dictionnaires.
3. Créer de très gros corpus parallèles à partir de zéro est 2 à 3 fois plus coûteux que de construire un grand système de TA par approche experte (procédurale et/ou à automates et grammaires).
4. L'architecture linguistique par « pivot interlingue » peut utiliser n'importe quel paradigme computationnel, qu'il soit statistique, analogique, à règles, ou hybride.
5. En dernier ressort, le choix de l'architecture linguistique et de l'architecture computationnelle dépend des ressources disponibles en termes de corpus préalablement traduits, et d'humains plus ou moins experts. Les types d'expertise recherchée sont, par ordre de difficulté croissante (estimée via le temps de formation et la relative rareté des experts) : la traduction, la post-édition, la correction d'annotations, l'annotation à partir de rien, la terminologie, la lexicographie complexe Indépendance des architectures linguistiques et computationnelles en traduction automatique 
(vocabulaire général et tournures), l'écriture de grammaires assez déclaratives, la programmation par automates dans des LSPL adaptés, et enfin la programmation directe.
Conclusion Nous avons donc montré que les architectures linguistiques et computationnelles des systèmes de traduction automatique sont indépendantes, au sens où on peut utiliser n'importe quelle architecture computationnelle pour réaliser n'importe quelle phase de traitement dans une architecture linguistique donnée, non seulement en théorie, mais en pratique, comme l'illustre la variété des systèmes cités en exemple. Nous avons aussi donné une évaluation des tailles et des coûts de construction des ressources utilisées par différents types de systèmes de TA, ce qui donne quelques éléments pour le choix de l'architecture linguistique et computationnelle d'un système à créer, en fonction des situations traductionnelles et des ressources disponibles, en termes de dictionnaires, de corpus, et de compétences humaines.
Cette réflexion ouvre sur une perspective plus générale et « sociétale ». Si l'on veut surmonter la « barrière linguistique » entre toutes les langues, on ne pourra pas se contenter de construire des systèmes de TA entre l'anglais et les autres langues, même pas pour le tchat entre deux langues différentes de l'anglais. En effet, l'anglais intermédiaire serait nécessairement trop « grossier », entaché d'erreurs, et porteur d'ambiguïtés nouvelles en sus des anciennes (celles de la langue source). La plupart des locuteurs (ou simplement lecteurs « passifs ») seront de plus toujours bien moins compétents et à l'aise en anglais que dans leur langue.
Il faudra donc construire des systèmes fondés sur des interlingues, soit « sémantico-pragmatiques » (comme l'IF de CSTAR, Nespole! ou MASTOR-1) s'il s'agit de tâches et de domaines restreints et bien identifiés, soit « linguistico-sémantiques » (comme UNL). Cela sera d'autant plus nécessaire qu'on voudra intégrer ces systèmes au « Web sémantique », car il faudra alors demander aux internautes d'aider les systèmes d'annotation, sans doute par le même type de « désambiguïsation interactive » que celui qui permet de compenser la nécessaire « rusticité » (ou la « mauvaise qualité intrinsèque ») des systèmes de TA « tout terrain » quand on veut les utiliser en « tout automatique ».
Il ressort de ce qui précède qu'il devrait être possible de construire des systèmes de TA entre toutes les langues, passant par un niveau sémantique comme UNL, non seulement par des approches « expertes » comme c'est le cas actuellement, mais par des approches empiriques moins coûteuses et moins longues en développement, si toutefois on disposait de corpus adéquats de taille suffisante.
D'autre part, à la lumière des développements récents en alignement et en TA statistique, de tels corpus devraient pouvoir être construits par « transitivité », en alignant des corpus parallèles et des corpus annotés en IL (en UNL par exemple) s'ils ont au moins une langue en commun.

