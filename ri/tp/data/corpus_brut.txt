
Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues 
Caroline Lavecchia1, 2 Kamel Smäıli1, 2 David Langlois1, 3 (1) LORIA/Speech Group, Campus scientifique, BP 239, 54506 Vandoeuvre lès Nancy Cedex, France (2) Université Nancy2 (3) IUFM de Lorraine 
Résumé.        Dans cet article, nous présentons une nouvelle approche pour la traduction automatique fondée sur les triggers inter-langues. Dans un premier temps, nous expliquons le concept de triggers inter-langues ainsi que la façon dont ils sont déterminés. Nous présentons ensuite les différentes expérimentations qui ont été menées à partir de ces triggers afin de les intégrer au mieux dans un processus complet de traduction automatique. Pour cela, nous construisons à partir des triggers inter-langues des tables de traduction suivant différentes méthodes. Nous comparons par la suite notre système de traduction fondé sur les triggers interlangues à un système état de l’art reposant sur le modèle 3 d’IBM (Brown & al., 1993). Les tests menés ont montré que les traductions automatiques générées par notre système améliorent le score BLEU (Papineni & al., 2001) de 2, 4% comparé à celles produites par le système état de l’art.
Abstract. In this paper, we present an original approach for machine translation based on inter-lingual triggers. First, we describe the idea of inter-lingual triggers and how to determine them. Then, we present the way to make good use of them in order to integrate them in an entire translation process. We used inter-lingual triggers to estimate different translation tables. Then we compared our translation system based on triggers to a state-of-the-art system based on IBM model 3 (Brown & al., 1993). The experiments showed that automatic translations generated by our system outperform model 3 of IBM by 2.4% in terms of BLEU (Papineni & al., 2001).
Mots-clés :       Traduction Automatique Statistique, Triggers Inter-Langues, Information Mutuelle, Corpus parallèle, Décodage.

Keywords:          Statistical Machine Translation, Inter-Lingual Triggers, Mutual Information, Parallel corpus, Decoding process.
Caroline Lavecchia, Kamel Smäıli, David Langlois 1 Introduction L’objectif de la traduction automatique est de transformer une phrase donnée dans une langue source en une phrase dans une langue cible. Pour résoudre ce problème très complexe, il est possible d’intégrer le savoir faire de traducteurs humains, mais cela demande une modélisation de ce savoir qui est en soi un sujet de recherche. Il faut utiliser des modèles formels des langues source et cible issus du Traitement Automatique des Langues, et un modèle de traduction à base de règles, comme par exemple ce qui est fait dans le système de Systran (Jean Senellart, 2001).
Cet effort de conception doit ê tre répété pour chaque couple de langues (même si le savoir faire peut ê tre en partie transféré). L’approche statistique, quant à elle, utilise une voie différente. En effet, elle n’utilise pas de connaissances a priori, mais s’appuie sur des corpus bilingues. Ces corpus sont alignés, c’est-à-dire que le lien entre chaque partie du texte de la langue source est fait avec la partie correspondante dans la langue cible. Le lien est généralement fait au niveau de la phrase. Partant de ces corpus, une analyse statistique utilise les redondances existantes afin d’estimer les paramètres du processus de traduction. La traduction statistique est possible car les modèles adhoc sont couplés avec des algorithmes de programmation dynamique qui maximisent une fonction de traduction d’une phrase source vers une phrase cible. IBM a utilisé avec succès cette approche (Brown & al., 1993). La plupart des systèmes statistiques actuels sont fondés sur les modèles d’IBM.
L’approche statistique nécessite de définir un modèle de traduction qui va permettre de calculer les probabilités de traduction entre les mots, les suites de mots et les autres constituants de la phrase. Ainsi, on définit pour toute phrase s de la langue source et toute phrase t de la langue cible une valeur P (s|t) calculée à l’aide de modèles composés de nombreux paramètres. IBM propose pour estimer ces paramètres une méthode itérative engendrant 5 modèles de traduction différents, du plus simple au plus complexe. Cela aboutit à des modèles performants, mais longs et complexes à estimer. Cette complexité croit trè s vite au fur et à mesure des paramètres supplémentaires pris en compte lors du processus de traduction. En plus du modèle de traduction, cette approche utilise un modèle de langage de la langue cible qui permet d’évaluer la qualité de la phrase t. Un décodeur tel que Pharaoh (Koehn, 2004) utilise ces deux modèles afin de rechercher pour une phrase s donnée une phrase t qui peut ê tre acceptée comme traduction de s.
Dans cet article, nous proposons une nouvelle approche permettant de construire un modèle de traduction fondé sur les triggers inter-langues (extension des triggers classiques) pour construire notre système de traduction statistique. Le concept de triggers est bien connu de la communauté de la modélisation statistique du langage. Facile à mettre en oeuvre, il possède une certaine souplesse qui permet de l’appliquer à différents niveaux de lecture de la phrase (mots, genre, nombre, constituants syntaxiques). Nous montrerons que les triggers inter-langues permettent de construire un modèle de traduction efficace. Nous comparerons ses résultats à ceux fondés sur les modèles d’IBM.
Nous présentons dans la partie 2 la notion générale des triggers. La partie 3 définit le concept de triggers inter-langues qui associe à chaque mot de la langue source une liste de traductions possibles. Dans la partie 4, nous présentons la manière dont les triggers inter-langues ont été intégrés à un processus complet de traduction automatique. Nous terminons enfin par une conclusion qui met en avant les points forts de notre méthode et donne quelques perspectives futures des travaux de notre groupe de recherche.
Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues 2 Rappel sur les triggers Le concept de triggers est très souvent cité en modélisation statistique du langage et plus particulièrement en reconnaissance de la parole. Les triggers permettent entre autre d’améliorer et de généraliser le modèle Cache (Kuhn & DeMori, 1990). Le modèle Cache favorise la probabilité d’un mot wi récemment apparu dans le contexte gauche. Un modèle de triggers va plus loin et accorde une probabilité plus importante à une liste de mots corrélés au mot wi (Tillmann & Ney, 1996). Les triggers sont sélectionnés selon la valeur de l’Information Mutuelle (IM) donnée par la formule suivante : P (x, y) IM(x, y) = P (x, y)log                                           (1) P (x)P (y) Chaque mot appartenant au vocabulaire est alors associé à n mots qui lui sont le plus fortement corrélés d’après la valeur de l’IM. Un trigger est un ensemble composé d’un mot appelé déclencheur et d’une liste de mots qu’il déclenche appelés déclenchés. La figure 1 illustre un exemple de triggers anglais.
Les triggers ont beaucoup été utilisés en reconnaissance de la Parole o`u ils sont combinés avec un modèle n-gramme classique (Tillmann & Ney, 1997).
Garry Kasparov is a chess champion 
F IG . 1 – Exemples de triggers classiques 3 Les triggers inter-langues Nous proposons dans ce qui suit d’étendre ce concept pour l’utiliser avec des corpus bilingues alignés. Nous appelons ce concept triggers inter-langues. Un trigger inter-langue est défini comme étant un ensemble composé d’un mot déclencheur d’une langue source et des mots déclenchés d’une langue cible qui lui sont fortement corrélés. Ainsi, chaque mot f du vocabulaire français VF est associé à n mots anglais ou triggers inter-langues qui lui sont le plus fortement corrélés au sens de l’IM. Plus formellement, 
∀fi ∈ VF , T rign (fi ) est l’ensemble des n triggers inter-langues de fi 
De la même façon, chaque mot e du vocabulaire anglais VE est associé à n mots français : 
∀ei ∈ VE , T rign (ei ) est l’ensemble des n triggers inter-langues de ei .

Les triggers inter-langues sont déterminés suivant la valeur de l’Information Mutuelle calculée sur un corpus aligné au niveau de la phrase. Ce corpus est constitué de paires (E, F ) o`u F est la traduction de E. Les triggers permettent de repérer les éléments en relation d’une langue à l’autre. Les triggers sont estimés en utilisant la formule (2).
P (f, e) IM(f, e) = P (f, e) ∗ log(                  )                        (2) P (f ) ∗ P (e) Caroline Lavecchia, Kamel Smäıli, David Langlois N(X)                          N(f, e) P (X) =                    P (f, e) =                                   (3) |Corpus|                      |Corpus| – e et f sont des éléments de la paire de phrases (E, F ) – N(X) est le nombre de phrases dans lesquelles le mot X apparaît – N(e, f ) est le nombre de paires (E, F ) de phrases du corpus aligné dans lesquelles les mots e et f co-occurent.
– |Corpus| est le nombre de paires de phrases constituant le corpus aligné.
La figure 2 montre un exemple de triggers inter-langues de l’Anglais vers le Français. Ce qui Garry Kasparov is a chess champion Garry Kasparov est un champion d’ échecs F IG . 2 – Exemples de triggers inter-langues 
motive l’utilisation de cette notion est le fait que l’on espère trouver la traduction du mot déclencheur dans la liste des mots déclenchés.
Notons que ce principe de triggers inter-langues est utilis éen modélisation du langage pour enrichir des langues faiblement dotées à partir d’autres langues très riches en termes de corpus (Kim & Khudanpur, 2004).
4 La traduction automatique avec les triggers inter-langues La première étape pour la mise en place de notre système de traduction est l’apprentissage des triggers inter-langues. Pour ce faire, nous les déterminons sur un corpus parallèle extrait des actes du Parlement Européen dont les statistiques sont résumées dans le tableau 1.

TAB . 1 – Corpus d’apprentissage 
Français Anglais Paires de phrases                596K Taille (en mots)           17.3M     15.8M Vocabulaire (en mots)      77.5K      60.3K Nous appliquons les formules (2) pour détecter les couples (e, f ) les plus corrélés et qui constituerons les triggers inter-langues.
Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues Quelques exemples de triggers Anglais-Français sont pré sentés dans le tableau 2, de même des exemples de triggers Français-Anglais sont présentés dans le tableau 3. La troisième colonne des tableaux indique pour chaque couple de mots déclencheur-déclenché la valeur de l’Information Mutuelle qui lui est associée. Une analyse qualitative de nos triggers montre que les mots déclenchés peuvent souvent ê tre apparentés à de possibles traductions du mot déclencheur ou à des mots vraiment très proches du point de vue du sens. Par ailleurs, comme le montrent les exemples des tableaux, les triggers détectent également les différents sens des homographes (ainsi, deux sens de ’porte’ sont détectés avec de forts taux d’Information Mutuelle). Ces constats sont valables dans les deux sens de traduction.

TAB . 2 – Exemples de mots français déclenchés par des mots anglais 
Déclencheur Déclenchés             IM             Déclencheur Déclenchés                IM anglais      français                (10−4)         anglais      français                   (10−4 ) pion                     0, 33                       champion                    2, 38 chess        échiquier              0, 29          champion     championne                  1, 00 échecs                 0, 26                       homme                       0, 28 porte                    20, 96                      sens                        69, 06 door         ouverte                  5, 15          sense        bon                         8, 91 portes                   2, 73                       sentiment                   7, 23 traduction               34, 16                      usine                       7, 54 translation  erreur                   2, 73          plant        installation                3, 92 version                  1, 49                       plantes                     3, 59 TAB . 3 – Exemples de mots anglais déclenchés par des mots français 
Déclencheur Déclenchés             IM             Déclencheur Déclenchés                IM français    anglais                  (10−4)         français    anglais                     (10−4 ) failures                 5, 88                       champion                    2, 38 échecs     failure                  0, 88          champion     expert                      0, 25 chess                    0, 26                       champions                   0, 24 door                     20, 96                      sense                       69, 06 porte        relates                  5, 21          sens         direction                   28, 68 concerns                 4, 23                       meaning                     11, 61 translation              34, 16                      plants                      19, 20 traduction   error                    2, 51          plantes      plant                       3, 59 version                  1, 49                       crops                       1, 98 Nous proposons dans ce qui suit, d’utiliser l’ensemble des triggers inter-langues pour mettre en place notre système de traduction. Nous le comparons ensuite à un système état de l’art reposant sur le modèle 3 d’IBM (Brown & al., 1993). Pour ce faire, nous avons utilisé le décodeur Pharaoh1 (Koehn, 2004), afin de traduire automatiquement un corpus de test de 1444 phrases 
Le modèle de langage de la langue cible est un modèle trigram (méthode de lissage de Good-Turing. Les poids des différents modèles sont les suivants : 1 pour le modèle de langage, 1 pour le modèle de traduction, 1 pour le modèle de ré-ordonnancement et enfin une pénalité de mot de 0. Le décodage est fait avec ré-ordonnancement.
Caroline Lavecchia, Kamel Smäıli, David Langlois anglaises. Les traductions produites sont ensuite comparées à l’aide de la mesure Bleu, une mesure automatique couramment employée en traduction automatique (Papineni & al., 2001).
Dans les sections suivantes, nous présentons trois façons d’identifier les traductions potentielles d’un mot au sein de notre système à partir des triggers inter-langues déterminés auparavant.
Elles donnent lieu à l’estimation de trois tables de traduction.
4.1 Les tables de traduction Trig-n 
Dans un premier temps, nous estimons que tous les triggers inter-langues peuvent ê tre assimilés à des traductions possibles. Par conséquent, nous les ajoutons tous dans la table de traduction.
Ainsi, un mot anglais ei est une traduction probable du mot français fj s’il fait partie de ses triggers inter-langues. La probabilité associée à cette traduction est la valeur de l’Information Mutuelle normalisée du couple (ei , fj ).

IM(fj , ei ) ∀fj ∈ VF , ∀ei , ek ∈ T rign (fj ) P (ei |fj ) =   n                             (4) k=1 IM(fj , ek ) 
Par la suite, nous appellerons les tables de traduction ainsi construites Trig-n avec n le nombre de triggers inter-langues retenus pour chaque mot français du vocabulaire.
L’évaluation de notre système mis en place avec les tables de traduction Trig-n, n variant de 10 à 200, est décrite par la série Trig-n de l’histogramme de la figure 3. Dans un premier temps, nous remarquons une amélioration du score Bleu de plus de 2 points entre Trig-10 et Trig20. Ceci montre que, globalement, les traductions correctes d’un mot déclencheur sont dans les 20 meilleurs déclenchés. Toutefois, lorsque n prend des valeurs au delà de 20, l’impact est beaucoup plus faible. Il faut préciser que, dans la configuration utilisée, Pharaoh, dans un souci de rapidité de recherche, ne prend en compte que les 20 meilleures traductions d’un mot donné.
Donc, il est inutile d’aller au delà de 20. Toutefois l’impact montré n’est pas nul car le fait de normaliser les probabilités sur 20, 50 ou 100 triggers modifie l’échelle des valeurs de la table de traduction et donc le poids de cette table dans le processus de recherche. Notons que nous avons modifié cette configuration afin de permettre à Pharaoh de tenir compte de plus de 20 traductions, mais que cela n’a pas eu d’impact positif sur les performances.
4.2 Les tables de traduction Sym-n 
La deuxième méthode de construction d’une table de traduction consiste à considérer comme traductions possibles les couples (fj , ei ) qui respectent la contrainte de symétrie suivante : 
Si ei ∈ T rign (fj ) et fj ∈ T rign (ei ) Alors ei ∈ Symn (fj )                  (5) 
ei appartient aux traductions possibles de fj (Symn (fj )), si ei fait partie des triggers interlangues de fj et inversement si fj est un trigger inter-langue de ei comme l’illustre la figure 4.
Cette contrainte de symétrie nous permet d’affiner la liste des triggers inter-langues de fj pour ne retenir que les plus pertinents. Nous supposons que si ei est un des n mots les plus corrélés avec fj et que fj est également dans les n mots les plus déclenchés par ei , alors il y a de fortes chances que ei soit une traduction de fj . La probabilité associée à ce couple est calculée de la Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues 
Trig-n Sym-n Smooth-n M3 28.5 
27.5 Bleu 
26.5 
25.5 10             20             50             100      200 F IG . 3 – Evaluation des traductions produites à l’aide des tables de traduction Trig-n, Sym-n et Smooth-n en fonction de n Triggers anglais−français Triggers français−anglais e e 11   12 ...    e.     . .   e1k 1 
f    1 Traductions potentielles f    2           e e 21   22 . . . . . .         e2k 2 f                                                                    .
3                                                               .
e            .                                                             e:f. 1, fi , f n f    i           e e e i1    i2 . .. . .      eik i .                                                                   .
.                                                                   .
f    n e e          .. .    e.      . . en kn 11    n2 F IG . 4 – Identification des traductions potentielles d’un mot par symétrie 
manière suivante : 
IM(fj , ei ) ∀fj ∈ VF , ∀ei , ek ∈ Symn (fj ) Psym (ei |fj ) =                                                  n                  (6) k=1 IM(fj , ik ) 
La contrainte de symétrie réduit considérablement le nombre de couples retenus parmi les triggers inter-langues. En moyenne, seuls 21% des triggers inter-langues respectent la contrainte de symétrie (5). Ainsi, nous espérons n’avoir retenu que les triggers les plus pertinents.
La série Sym-n de l’histogramme de la figure 3 présente l’évaluation de notre système fondé sur les tables de traduction Sym-n. Nous observons à nouveau une nette amélioration du score Bleu lorsque l’on utilise Sym-20 au lieu de la table Sym-10. Nous notons, également, une légère amélioration du score Bleu qui passe de 25, 84 pour Trig-10 à 25, 91 pour Sym-10. La contrainte de symétrie nous permet donc, dans ce cas, d’écarter des triggers inter-langues qui ne seraient pas de réelles traductions. Malheureusement, cette observation ne s’étend pas aux autres tables Sym-n (avec n > 10) puisque leur score Bleu reste inférieur à ceux obtenus avec les tables Trig-n. Même si cette intuition semble naturelle, la contrainte de symétrie semble donc ê tre trop restrictive pour améliorer les performances de notre syst è me.
Caroline Lavecchia, Kamel Smäıli, David Langlois Nous proposons donc une troisième façon d’identifier et d’estimer les traductions potentielles pour assouplir cette contrainte de symétrie. Pour cela, nous décidons d’utiliser une technique de lissage des probabilités (smoothing).
4.3 Les tables de traduction Smooth-n 
Afin de ne pas affecter une probabilité nulle aux couples (f, e) qui ne satisfont pas la contrainte de symétrie “e déclenche f et f déclenche e”, nous proposons d’utiliser une technique de lissage pour estimer une troisième table de traduction que nous appelons par conséquent Smooth-n. En modélisation du langage, ces techniques dites de smoothing permettent de lisser les probabilités de manière à ce que chaque évènement, même impossible, se voit affecter une probabilité (Ney et al., 1994). Nous proposons d’employer le même type de technique. Pour ce faire, nous réduisons la probabilité des triggers symétriques des tables Sym-n. La masse ainsi récupérée est répartie uniformément sur les triggers non symétriques. Cette nouvelle estimation est calculée de la manière suivante : 
Psym (ei |fj ) − ǫ   si ei ∈ Symn (fj ) ∀ei ∈ T rign (fj ) Psmooth (ei |fj ) =                                                 (7) γ                    sinon 
Pour un mot français, nous retirons une quantité ǫ à chaque probabilité de traduction assignée à ses triggers inter-langues symétriques et nous redistribuons la masse récoltée uniformément sur ses autres triggers inter-langues non symétriques.
La dernière série de l’histogramme de la figure 3 indique les performances de notre système reposant sur les tables Smooth-n. Rappelons que n est le nombre de triggers inter-langues retenus pour chaque mot du vocabulaire français. L’allure de la série est la même que pour les expériences précédentes. Toutefois, nous pouvons constater que notre système est plus performant avec les tables Smooth-n qu’avec les tables Sym-n. Par conséquent, nous pouvons dire que la contrainte de symétrie est en effet trop restrictive, et que le fait de conserver les triggers non-symétriques permet bien d’améliorer les performances. En revanche, malgré ces efforts de lissage, notre système reste le plus performant lorsque chaque trigger inter-langue est considéré comme une traduction potentielle qu’il respecte la contrainte de symétrie ou non (série Trig-n).
Ces résultats pourraient indiquer que la contrainte de sym étrie est trop forte et que le processus de traduction n’est pas nécessairement symétrique. Cela serait à confirmer par une étude au cas par cas.
4.4 Comparaison avec le modèle 3 de traduction d’IBM 
Afin d’évaluer la pertinence de notre système fondé sur les triggers inter-langues, nous avons comparé ses performances avec celles d’un système état de l’art reposant sur le modèle 3 d’IBM et que nous appelons M3. Ce dernier a été entraîné, à l’aide de l’outil Giza++ (Och & Ney, 2000), sur le même corpus parallèle d’apprentissage que les triggers inter-langues et testé avec le même décodeur sur les mêmes 1444 phrases. Les performances du système M3 sont inférieures à celle de notre système. En effet, nous obtenons un score BLEU de 28, 07 ( cf. courbe M3 de la figure 3) par rapport à un score de 28, 49 pour Trig-100.
Toutefois, comme nous l’avons dit précédemment, le décodeur Pharaoh ne prend en compte pour chaque mot français que les 20 meilleures traductions dans le but de réduire son espace Une alternative aux modèles de traduction statistique d’IBM : Les triggers inter-langues de recherche. Afin d’optimiser les performances de notre système, nous avons paramétré le décodeur de telle sorte de lui laisser la possibilité de prendre en compte plus de 20 traductions par mot français. Pour cela, nous faisons varier le paramètre ttable-limit. Nous optimisons également le paramètre ttable-threshold qui permet d’écarter de l’espace de recherche les couples de traductions dont la probabilité est inférieure à un certain seuil. L’optimisation est réalisée indépendemment pour les deux systèmes. Les résultats en terme de score Bleu sont présentés dans le tableau 4. Les performances de notre système sont optimales lorsque TAB . 4 – Optimisation des paramètres ttable-limit et ttable-threshold 
Modèle     ttable-limit    ttable-threshold      Bleu Trig-100         22               0, 04          28, 95 M3            53               0, 00          28, 27 le décodeur restreint son espace de recherche aux 22 meilleures traductions par mot français dont la probabilité est supérieure ou égale à 0, 04. Celles du système M3 le sont lorsque le décodeur réduit son espace de recherche aux 53 meilleures traductions pour un mot français sans contrainte sur la valeur des probabilités. Notre syst è me fondé sur les triggers inter-langues apporte une amélioration de 2, 4% en termes de score BLEU par rapport au système état de l’art.
5 Conclusion et perspectives 
Nous avons présenté dans cet article une alternative aux modèles d’IBM pour la traduction statistique. La méthode est fondée sur les triggers inter-langues. Ces triggers ont été sélectionnés à partir d’un corpus parallèle aligné au niveau de la phrase extrait des actes du Parlement Européen. Ils permettent de définir pour chaque mot (français ou anglais) une liste des mots (français ou anglais) qui lui sont fortement corrélés. Ainsi un mot français est associé à une liste de mots anglais et vice versa.
Dans le but d’évaluer la pertinence des triggers inter-langues en tant que traductions potentielles, nous avons mis en place un système de traduction de mots basé uniquement sur les triggers inter-langues. Nous avons ensuite comparé ses performances à celles d’un système de référence état de l’art reposant sur les modèles d’IBM. Après optimisation des deux systèmes, les tests menés ont montré qu’en ne retenant que 22 traductions potentielles pour chaque mot français, les performances de notre système apportent une amélioration de 2, 4% du score BLEU par rapport au système de référence.
Ces premiers résultats révèlent la faisabilité de l’utilisation des triggers inter-langues en traduction automatique statistique. Par ailleurs, le concept de triggers inter-langues est un formalisme souple et nous nous sommes concentrés ici que sur des triggers d’ordre 1-1, c’est-à-dire qu’un mot est traduit par un seul mot. Nous proposons dans (Lavecchia et al., 2008) un système de traduction fondé sur les triggers d’ordre n-m, o`u plusieurs mots peuvent ê tre traduits par plusieurs mots. Ainsi, notre système devient un système de traduction de séquences de mots et non plus de mots.
A plus long terme, nous pouvons envisager beaucoup d’autres manières d’utiliser les triggers inter-langues en traduction statistique, comme par exemple en tant que mesure de confiance. De plus, nous venons de voir qu’ils permettent de prendre en compte des séquences de mots, mais Caroline Lavecchia, Kamel Smäıli, David Langlois nous pouvons également imaginer déterminer des triggers inter-langues d’autre nature que le mot comme par exemple des triggers de traits syntaxiques.
Nous pouvons aussi combiner les tables de traduction de Giza++ et les nôtres afin de mesurer leur apport respectif.
Plusieurs autres applications des triggers inter-langues ont été envisagées et sont en cours de développement dans notre groupe de recherche.

Remerciements Ce travail est subventionné par la fondation d’entreprises EADS (European Aeronautic Defence and Space Company) dans le cadre d’une thèse sur la traduction Parole-Parole 


Génération de reformulations locales par pivot pour l’aide à la révision 
Aurélien Max LIMSI-CNRS et Université Paris-Sud 11 Orsay, France aurelien.max@limsi.fr Résumé.          Cet article présente une approche pour obtenir des paraphrases pour de courts segments de texte qui peuvent aider un rédacteur à reformuler localement des textes. La ressource principale utilisée est une table d’alignements bilingues de segments d’un système de traduction automatique statistique. Un segment marqué par le rédacteur est tout d’abord traduit dans une langue pivot avant d’être traduit à nouveau dans la langue d’origine, ce qui est permis par la nature même de la ressource bilingue utilisée sans avoir recours à un processus de traduction complet. Le cadre proposé permet l’intégration et la combinaison de différents modèles d’estimation de la qualité des paraphrases. Des modèles linguistiques tentant de prendre en compte des caractéristiques des paraphrases de courts segments de textes sont proposés, et une évaluation est décrite et ses résultats analysés. Les domaines d’application possibles incluent, outre l’aide à la reformulation, le résumé et la réécriture des textes pour répondre à des conventions ou à des préférences stylistiques. L’approche est critiquée et des perspectives d’amélioration sont proposées.
Abstract. In this article, we present a method to obtain paraphrases for short text spans that can be useful to help a writer in reformulating text. The main resource used is a bilingual phrase table containing aligned phrases, a common resource in statistical machine translation.
The writer can mark a segment for paraphrasing, and this segment is first translated into a pivot language before being back-translated into the original language, which is possible without performing a full translation of the input. Our proposed framework allows integrating and combining various models for estimating paraphrase quality. We propose linguistic models which permits to conduct empirical experiments about the characteristics of paraphrases for short text spans. Application domains include, in addition to paraphrasing aids, summarization and rephrasing of text for conforming to conventional or stylistic guidelines. We finally discuss the limitations of our work and describe possible ways of improvement.
Mots-clés :            Paraphrase, Traduction Automatique Statistique basée sur les segments, Aide à la rédaction.

Keywords:          Paraphrasing, Phrase-Based Statistical Machine Translation (PBSMT), Authoring aids.
Aurélien Max 1 Introduction 
La vie d’un texte est souvent pleine de rebondissements. Un auteur peut le réviser pour lui apporter des corrections, le rendre plus court, l’adapter à un lectorat voire le traduire dans une autre langue. Lors de la phase de maturation d’un texte, celui-ci peut subir de nombreux changements avant de prendre sa forme définitive. À contenu informationnel (plus ou moins) constant, l’auteur cherche à tendre vers des formulations qui seront plus adaptées au contexte en termes de correction linguistique et de compréhensibilité. La question de la génération automatique de reformulations, même locales, et de l’évaluation de leur adaptation à leur contexte semble donc particulièrement pertinente alors que les aides à la rédaction sont encore trop peu sensibles à la nature linguistique des textes manipulés.
Des travaux en linguistique distinguent la reformulation à visée explicative, qui tente d’expliciter le sens, et la reformulation à visée imitative, qui tente de substituer des formulations équivalentes (Fuchs, 1994). Ce dernier cas pose la difficile question de la prise en compte d’un seuil de distortion au-delà duquel une reformulation n’est plus admissible. Les systèmes de transformation automatique de texte butent en effet sur la prise en compte d’un tel seuil, qui n’est pas explicité dans les principales mesures d’évaluation utilisées, telles que BLEU (Papineni et al., 2002) pour la traduction automatique ou ROUGE (Lin, 2004) pour le résumé. Une certaine modélisation de la reformulation mène à des techniques d’analyse et de reconnaissance de textes qui sont des paraphrases les uns des autres à des fins d’extraction d’informations, mais où cette notion de seuil est souvent éclipsée au profit du rappel.
Dans cet article, nous présentons une approche permettant de proposer à un rédacteur des reformulations pour de courts segments de texte (par ex. dans de bonnes conditions, maintenir le contact, la plus étroite) au cours de l’activité de révision. Ce type d’aide reprend les principes de certains travaux visant à faire des suggestions lexicales, par exemple en enrichissant des dictionnaires avec des index d’associations, telles que des mots liés thématiquement (Ferret & Zock, 2006). Dans cet article, nous commençons par décrire brièvement les travaux existant en paraphrasage automatique, puis nous décrivons les fondements de notre approche inspirée de (Bannard & Callison-Burch, 2005), qui consiste à utiliser des traductions de segments en pivot pour produire des reformulations et sélectionner parmi celles-ci celles qui sont préférées par différents types de modèles. Une évaluation est décrite et ses résultats sont analysés, ce qui met en évidence le caractère prometteur de l’approche proposée et suggère de nouvelles voies de recherche. En particulier, nous soulignons l’importance d’utiliser le contexte de la phrase d’origine contenant le segment à paraphraser pour le choix des segments pivots, importance qu’on retrouve dans le domaine de la traduction automatique.
2 Travaux antérieurs 
La possibilité d’utiliser de grands corpus comparables et parallèles a suscité récemment une vague de travaux autour du paraphrasage. Des travaux ont par exemple porté sur l’apprentissage et l’utilisation de paraphrases pour améliorer des tâches telles que la recherche d’informations précises (Duclaye et al., 2003) ou la déduction sur textes, et des applications texte-à-texte, telle que la traduction automatique (Callison-Burch, 2007), ou encore l’évaluation de ce type d’applications en traduction (Kauchak & Barzilay, 2006) ou en résumé (Zhou et al., 2006).
Génération de reformulations locales par pivot pour l’aide à la révision Les systèmes de génération automatique de texte non-déterministes offrent un cadre naturel pour la génération de paraphrases, dont les plus « naturelles » peuvent être sélectionnées par un modèle de langue (Landkilde & Knight, 1998). Si un point fort de ce type d’approche est qu’il est possible de produire des paraphrases de nature très différentes, la construction d’un tel système permettant de produire une grande variabilité de textes en sortie est difficile, et ces systèmes attendent des entrées qui sont soit sous forme de concepts, soit sous forme de spécifications de phrases.
Des alignements appris à partir de corpus comparables (monolingues) permettent de générer des reformulations en se passant d’un tel générateur. Par exemple, (Barzilay & Lee, 2003) apprennent des treillis factorisant l’ensemble des reformulations possibles au niveau des phrases, ce qui est rendu possible par la nature même de leur corpus d’apprentissage (documents journalistiques décrivant les mêmes événements). Pour une phrase en entrée, si un treillis qui lui correspond est trouvé, celui-ci est utilisé pour produire un ensemble de formulations correspondant aux chemins du treillis. Si ce type d’approche peut parfois produire de très bonnes reformulations phrastiques, une bonne couverture des phénomènes linguistiques s’avère difficile à obtenir. En outre, des reformulations plus locales sont moins susceptibles d’altérer le sens des phrases. (Quirk et al., 2004) proposent une approche consistant à apprendre un système de traduction statistique sur un corpus monolingue de phrases alignées automatiquement à partir d’un corpus comparable, qui fonctionne par décodage monotone et donc opère par reformulations locales. Si cette absence de transformations profondes est souvent perçue comme l’une des principales limitations des systèmes de traduction statistiques actuels, elle permet néanmoins de limiter les risques de déformation du sens. D’autres travaux ont exploité des corpus parallèles monolingues, comme différentes traductions d’un même texte, pour apprendre des treillis permettant de générer des paraphrases (Pang et al., 2003).
Si ces approches s’attaquent toutes au paraphrasage d’énoncés complets, il est également intéressant de proposer des reformulations pour des unités plus petites. À partir de corpus parallèles bilingues, ressources traditionnelles pour l’apprentissage des systèmes de traduction statistique, (Bannard & Callison-Burch, 2005) ont proposé une approche pour le paraphrasage de courts segments de mots par traduction dans une langue puis par rétro-traduction et sélection dans la langue d’origine. Le problème de la validité d’une paraphrase en contexte pose notamment la question de la prise en compte de son contexte d’apparition, problème qui a récemment été abordé en traduction automatique statistique (Stroppa et al., 2007). Des travaux existent au niveau des paraphrases lexicales, comme ceux de (Connor & Roth, 2007) qui proposent un classifieur pour décider si un mot peut en remplacer un autre dans un certain contexte.
3 Reformulation de courts segments de texte par pivot 
3.1 Description générale de l’approche 
La traduction automatique statistique (Statistical Machine Translation (SMT)) est fondée sur l’apprentissage et l’utilisation d’alignements entre mots appris sur des corpus parallèles bilingues. La SMT basée sur des segments (Koehn et al., 2003) a étendu la notion d’alignements entre segments de taille quelconque, ce qui permet une meilleure prise en compte du contexte local, sans que ces segments n’aient à correspondre à une segmentation motivée linguistiquement. Des techniques d’alignement permettent d’apprendre des probabilités de traduction de Aurélien Max F IG . 1 – Exemple de paraphrasage de segment par consultation de tables de traduction. Les valeurs indiquent la probabilité conditionnelle du segment étant donné le segment à sa gauche.

segments. Par exemple, (Koehn et al., 2003) partent d’alignements 1 → N entre mots pour une paire de langues dans les deux directions, symétrisent ces alignements en prenant leur intersection, puis construisent des alignements N → M entre mots de façon incrémentale en ajoutant des éléments de l’union des deux alignements initiaux. Pour qu’un alignement soit construit à partir des alignements existant à une itération précédente, tous les mots d’un segment source doivent être uniquement alignés avec les mots d’un segment cible et inversement. À partir de l’ensemble des segments alignés extraits d’un corpus parallèle, les probabilités de traduction sont en général estimées à partir de fréquences relatives correspondant au rapport du nombre de fois où un segment source s et un segment cible c sont alignés sur le nombre d’occurrences du segment source : P (c|s) = compte(c,s) compte(s) Des tables de traduction de segments sont créées en utilisant notamment ces probabilités entre segments. (Bannard & Callison-Burch, 2005) ont proposé d’utiliser ce type de probabilités à des fins de paraphrasage, en définissant une probabilité de paraphrasage entre des segments seg1 et seg2 qui utilise l’alignement qu’entretiennent ces deux segments avec un segment pivot dans une autre langue, pivot : ˆ 2 = arg max P (seg2 |seg1) = arg max seg                                                           P (seg2|pivot)P (pivot|seg1 )         (1) seg2 =seg1                     seg2 =seg1 pivot Dans l’équation 1, la recherche se fait en excluant le segment d’origine seg1 et en sommant sur l’ensemble des pivots possibles pour une paire (seg1 , seg2 ). L’exemple de la figure 1 illustre le processus de construction de paraphrases d’un segment par pivot.
Outre la probabilité de paraphrasage décrite ci-dessus, (Callison-Burch, 2007) a utilisé différentes sources d’information pour mesurer l’importance de différents facteurs dans la qualité des reformulations1 : – qualité des alignements entre segments : la construction manuelle d’un corpus dont les alignements sont faits par un humain permet une amélioration significative de la qualité des paraphrases obtenues.
– utilisation de plusieurs corpus alignés : l’utilisation de plusieurs paires de langues pour obtenir les paraphrases (les pivots sont donc multilingues) permet d’éliminer partiellement les défauts d’alignements et d’obtenir une meilleure performance.
– contrôle du sens des segments : sans qu’il ne s’agisse de désambiguïsation sémantique des 
Dans ses expériences, Callison-Burch utilise 46 segments en anglais choisis aléatoirement parmi des expressions composées de plusieurs mots de WordNet (ex : at work, concentrate on, big business), et 289 phrases qui les contiennent. L’évaluation est alors effectuée par deux juges qui doivent attribuer aux reformulations des scores de conservation du sens (adequacy) et de caractère naturel (fluency).
Génération de reformulations locales par pivot pour l’aide à la révision segments (qui peuvent avoir, comme les mots, plusieurs sens dépendant de leur contexte d’apparition), paraphraser des segments appartenant à des phrases alignées avec des phrases dans une autre langue permet de restreindre les traductions possibles du segment, et améliore sensiblement les résultats.
– contrôle de la vraisemblance des paraphrases produites : l’utilisation d’un modèle de langue trigramme permet d’améliorer la grammaticalité des paraphrases produites, mais a un impact négatif sur la conservation du sens.
Notre travail se base sur cette approche en proposant une intégration de différents modèles pour aider à la sélection des paraphrases. L’utilisation d’un corpus de paraphrases évaluées par un humain peut alors servir à étudier la contribution de chacun des modèles, en particulier dans une tâche d’aide à la reformulation. Le score d’une reformulation peut être évalué en utilisant une combinaison linéaire de logarithmes correspondant à des scores de modèles telle que traditionnellement utilisée en SMT2 (M représente les modèles utilisés, et λm et hm représentent respectivement le poids et la fonction de score d’un modèle) : ˆ 2 = arg max P (seg2 |seg1 ) = arg max seg                                                       λm hm (seg1 , seg2 )              (2) seg2                             seg2 m∈M 3.2 Modèles pour la sélection des reformulations 
Nous présentons dans cette section les modèles que nous avons utilisés pour évaluer les reformulations.3 Modèle pivot (P IV) Nous utilisons un score dérivé de la probabilité de paraphrasage de (Bannard & Callison-Burch, 2005) en utilisant une seule langue pivot, qui nous servira de référence (baseline) : P iv(p1, p2 ) = log(           P (p2 |pivot)P (pivot|p1))                         (3) pivot Modèle de conservation de dépendances (D EP) Ce modèle vise à prendre en compte une certaine proportion des relations de dépendance qui sont conservées par la reformulation. Il prend en compte les dépendances externes au segment avant et après reformulation (resp. D1extra et D2extra ) sous la forme (dépendance, gouverneur, dépendant), ainsi que les dépendances entrant ou sortant du segment avant et après reformulation (resp. D1inter et D2inter ) sous la forme (dépendance, cible_hors_segment) : 
1 + |D1extra ∩ D2extra | + |D1inter ∩ D2inter | Dep(p1 , p2 , context) = log                                                                    (4) 1 + |D1extra| + |D1inter | 
L’approche choisie pourrait suggérer l’utilisation de systèmes de SMT complets pour le paraphrasage par pivot d’énoncés entiers, mais les performances des systèmes actuels, qui butent notamment sur la prise en compte du contexte source et sur la conservation du sens et de la grammaticalité en cible, rendent pour le moment cette approche problématique. (Quirk et al., 2004) attaquent eux ce problème avec un système SMT appris avec des alignements monolingues, ce qui constitue une voie de recherche intéressante.

Nous avons également fait des expériences avec des modèles basés sur les catégories morphosyntaxiques des mots, comme par exemple modélisant la probabilité de la suite de catégories d’un segment étant donné son contexte constitué des catégories à gauche et à droite du segment, mais ces modèles n’ont permis d’améliorer les résultats que nous présenterons en section 4.
Aurélien Max Le schéma ci-dessous illustre les cas où deux dépendances entrante et sortante sont retrouvées (reformulation A) et où une dépendance entrante n’est pas retrouvée (formulation B).
Modèle de lemmes (L EM) Ce modèle mesure une certaine proportion de lemmes de mots pleins communs au segment initial p1 et au segment après reformulation p2 (resp. L1 et L2 ) : 
1 + |L2| − |L1 ∩ L2 | Lem(p1 , p2 ) = log                                                (5) 1 + |L1 ∪ L2 | 4 Expériences et évaluation Les tables de traduction utilisées ont été apprises par la méthode décrite dans la section précédente sur les parties française et anglaise du corpus Europarl4 , qui comprend environ 1,2 million de phrases alignées. Les tables contiennent environ 42 millions de segments alignés (d’une taille maximale de 10 éléments (tokens)) avec des scores de traduction dans les deux directions. Nous avons choisi de travailler avec le français comme langue principale (et donc l’anglais comme seule langue pivot pour le moment), ce qui rend plus manifeste le besoin d’utiliser des segments rendant compte des dépendances ainsi que des accords entre mots qui en découlent. Nous avons utilisé l’analyseur syntaxique robuste pour le français S YNTEX (Bourigault et al., 2005) pour obtenir une segmentation en unités lexicales, la lemmatisation de ces unités et une analyse en dépendances. Outre les modèles décrits en section 3.2, nous avons utilisé un modèle de langue 5-grammes (5 GRAM) appris sur la partie française du corpus avec un lissage Kneser-Ney.
Nous avons constitué manuellement un corpus de test de 82 phrases issues d’une partie du corpus Europarl n’ayant pas servi à l’apprentissage des modèles de traduction et du modèle de langue. Pour chacune de ces phrases, un évaluateur à qui il était demandé de simuler la tâche d’un rédacteur en phase de révision a choisi un segment d’intérêt pour la reformulation, celui-ci étant accepté s’il appartenait à la table de traduction français → anglais (ex : dans de bonnes conditions, maintenir le contact, attendent avec impatience, la plus étroite, etc.).
Nous souhaitions disposer d’un corpus pouvant servir de référence pour différentes expériences impliquant plusieurs modèles. Ne disposant pas d’une métrique automatique acceptable pour évaluer la qualité des reformulations, et souhaitant ne pas avoir à conduire plusieurs évaluations manuelles, nous avons construit automatiquement un premier ensemble de reformulations pour chaque couple (phrase, segment à paraphraser). Afin de limiter le travail d’évaluation, nous avons choisi de ne retenir au plus que les 20 premières reformulations en utilisant P IV seul (ce qui de fait introduit un biais dans nos expériences, en restreignant l’ensemble des reformulations considérées). Pour chacune des 1648 phrases à évaluer, les juges avaient à indiquer les scores suivants sur une échelle de 1 à 5 : – score de grammaticalité : indique si la paraphrase est grammaticalement correcte en l’état (5), nécessite différents niveaux de révision (4 à 2) ou est complètement inexploitable (1).

Version du corpus utilisée pour la tâche WMT08 (http://www.statmt.org/wmt08).
Génération de reformulations locales par pivot pour l’aide à la révision Résultat au premier rang           Résultats au 8 premiers rangs gram. sens rédact. moy.              gram. sens rédact. moy.
P IV (baseline)    4.46 4.18       3.62    4.09        11.66 10.60       9.10    10.45 5 GRAM     4.28 3.62       3.45    3.78        11.52 9.72        9.20    10.15 D EP    4.35 3.68       3.43    3.82        11.47 9.70        8.91    10.03 L EM    4.05 3.21       3.28    3.51        10.68 8.74        8.59     9.33 P IV +5 GRAM      4.65 4.06       3.82    4.18        11.95 10.30       9.58    10.61 P IV +D EP    4.58 4.27       3.66    4.17        11.85 10.68       9.38    10.64 P IV +L EM     4.37 4.00       3.76    4.05        11.53 10.14       9.56    10.41 5 GRAM +D EP       4.49 3.81       3.68    3.99        11.79 9.95        9.51    10.42 5 GRAM +L EM       4.28 3.59       3.56    3.81        11.46 9.57        9.37    10.13 P IV +5 GRAM +D EP        4.65 4.05       3.92    4.21        12.04 10.35       9.71    10.70 P IV +5 GRAM +L EM        4.61 4.02       3.97    4.20        11.86 10.11       9.74    10.57 P IV +D EP +L EM      4.57 4.17       4.02    4.25        11.82 10.33       9.81    10.65 5 GRAM +D EP +L EM         4.37 3.69       3.64    3.90        11.65 9.75        9.54    10.31 P IV +5 GRAM +D EP +L EM         4.68 4.09       4.05    4.27        12.01 10.24       9.87    10.71 F IG . 2 – Résultats de l’évaluation automatique sur les 82 phrases de notre corpus d’évaluation (les notes au premier rang sont entre 1 et 5, et entre 2.71 et 13.59 pour les 8 premiers rangs) 
– score de conservation du sens : indique si la paraphrase reprend exactement le sens de la phrase d’origine (5), comporte différents niveaux d’ajout ou de retrait d’information (4 à 2) ou est d’un sens complètement différent (1).
– score d’intérêt pour un rédacteur : indique si la paraphrase pourrait être réutilisée en l’état pour une reformulation (5), avec une modification mineure (4), présente des éléments intéressants qui peuvent participer à une reformulation (3), présente des éléments qui peuvent suggérer une reformulation (2) ou correspond à du bruit (1).
Les scores sont obtenus en prenant la moyenne des scores de deux juges francophones.5 Le tableau de la figure 2 présente les résultats obtenus par différentes combinaisons de modèles pour notre corpus d’évaluation.6 Nous avons ici décidé d’utiliser des poids λm uniformes pour la combinaison des modèles, leur optimisation automatique en fonction de caractéristiques choisies par un utilisateur faisant partie de nos travaux futurs. Le deuxième groupe de colonnes indique les moyennes des différents scores et leur moyenne pour la reformulation classée au premier rang. Le troisième groupe de colonnes donne un score combinant les scores des 8 meilleurs résultats7 , calculé comme suit : 8rang=1 rang1 score(rang).
En ce qui concerne la grammaticalité des paraphrases, les modèles P IV et 5 GRAM sont les meilleurs contributeurs. La performance de P IV peut s’expliquer par la nature des alignements, dont les plus forts peuvent correspondre à des patrons morpho-syntaxiques cohérents. La contribution d’un modèle de langue était attendue, mais on constate que 5 GRAM seul a une performance légèrement inférieure à D EP. La combinaison P IV +5 GRAM mène cependant à une 
L’écart-type des différences de scores entre les deux juges est de 0.59 pour la grammaticalité, 0.7 pour la conservation du sens, et 0.8 pour l’intérêt pour un rédacteur, ce qui rend assez bien compte des différents niveaux de subjectivité de ces scores.

Contrairement à ce qui se passe en traduction statistique sur des phrases complètes, la taille de notre espace de recherche permet ici une exploration complète, et l’on a donc la garantie de trouver le meilleur score global (parmi les résultats présélectionnés par P IV).

Ce type de mesure est motivé par la finalité de nos travaux, i.e. proposer un nombre raisonnable de suggestions de reformulation à un rédacteur.
Aurélien Max meilleure performance que la combinaison P IV +D EP, ce qui semble indiquer que P IV et D EP opèrent des sélections plus similaires que P IV et L M. À l’examen des données, il apparaît qu’obtenir des reformulations grammaticales requiert parfois des modifications en dehors du segment.
Il serait possible d’essayer d’étendre les segments automatiquement en cherchant à obtenir des reformulations de meilleure qualité, mais en conservant l’approche actuelle, on peut remarquer qu’un critère strict de grammaticalité n’est pas nécessairement le plus important pour le rédacteur.
L’évaluation au niveau de la conservation du sens fait ressortir qu’il est difficile de faire mieux que la baseline P IV. Il s’agit cependant certainement là d’un biais imputable au corpus d’apprentissage des tables de traduction (les débats parlementaires européens), qui contient vraisemblablement peu d’ambiguïtés sémantiques au niveau des segments dont les scores d’alignement sont les plus forts. Si la combinaison avec d’autres modèles a plutôt tendance à dégrader les scores, car ils entraînent vraisemblablement une déformation du sens en préférant des énoncés grammaticaux, le modèle D EP entraîne une amélioration lorsque combiné avec P IV, alors que seul il obtient une performance bien moindre. La conservation des relations de dépendances, et en particulier du type de celles-ci pour les dépendances entrant ou sortant dans le segment paraphrasé, participe certainement à cela.8 La dégradation observée avec P IV +5 GRAM est cohérente avec les résultats obtenus par (Callison-Burch, 2007). Les scores observés en utilisant le modèle L EM semblent indiquer que les reformulations contenant plusieurs mots pleins différents correspondent fréquemment à des sens jugés différents.
Les meilleurs résultats concernant l’intérêt pour le rédacteur sont obtenus en combinant tous les modèles. On constate qu’une mauvaise grammaticalité ou une mauvaise conservation du sens ont tendance à pénaliser ce score, ce qui est cohérent avec les directives d’évaluation. Le modèle 5 GRAM se combine à nouveau favorablement avec P IV, et toutes les combinaisons impliquant P IV améliorent le score obtenu par ce modèle seul. Le modèle L EM permet d’améliorer les résultats, vraisemblablement parce qu’il permet de favoriser les reformulations les plus différentes du segment d’origine, qu’un rédacteur peut juger plus utiles qu’un segment très proche.
Il permet ainsi parfois de sélectionner des reformulations qui obtiennent par ailleurs de mauvais scores en grammaticalité et/ou en conservation du sens, comme dans l’exemple suivant : Phrase d’origine : ceux qui viennent dire ici que l’ europe ne doit pas adopter de directive énonçant les valeurs que nous voulons tous défendre se trompent .
Reformulation : ceux qui viennent dire ici que l’ europe ne doit pas adopter de directive énonçant les valeurs que nous voulons tous défendre devrions à nouveau réfléchir .
L’évaluation prenant en compte les 8 premiers résultats ne fait pas ressortir de différences significatives avec le résultat au premier rang. Les exemples ci-dessous illustrent deux cas où les premières propositions du système en combinant tous les modèles obtiennent de très bons scores : Phrase initiale : et , à cet égard bien précis , je suis d’ accord avec vous , monsieur le commissaire Reformulations : je partage votre point de vue, je pense comme vous, je partage votre avis, je vous rejoins 
Ce type de modèle dépend cependant très fortement de la robustesse de l’analyseur syntaxique utilisé pour analyser des énoncés plus ou moins corrects.
Génération de reformulations locales par pivot pour l’aide à la révision Phrase initiale : notre voisin s’ est efforcé résolument pendant la décennie écoulée de remplir les critères de l’ adhésion .
Reformulations : satisfaire aux exigences, satisfaire aux conditions, répondre aux exigences, respecter les exigences, répondre aux critères, remplir les conditions, satisfaire aux critères 5 Conclusions et perspectives 
Dans cet article, nous avons décrit une approche inspirée de (Bannard & Callison-Burch, 2005) pour produire des reformulations locales en utilisant des tables de traduction de segments et en combinant les scores de différents modèles. Nos évaluations, basées sur trois critères dont un concernant directement l’intérêt des reformulations proposées pour le rédacteur, ont plus particulièrement permis de dégager la contribution de notre modèle basé sur la conservation des relations de dépendance entre un énoncé et ses reformulations. Cependant, l’approche proposée comporte de nombreuses limitations, que nous nous efforcerons de corriger dans nos travaux ultérieurs.
La principale source d’amélioration selon nous consiste à mieux prendre en compte le contexte du segment à paraphraser dans la phrase source. Alors que (Callison-Burch, 2007) a montré l’importance de la prise en compte du contexte pour la génération de paraphrases, ses expériences se sont basées sur un choix de pivot issu directement d’un corpus parallèle bilingue, ce qui revient à faire une désambiguïsation supervisée. Des travaux récents en traduction statistique tels que (Stroppa et al., 2007) ont montré la possibilité d’intégrer dans des systèmes basés sur des segments des modèles permettant d’améliorer la sélection des segments cibles.9 Nous travaillons par ailleurs sur ces aspects dans le cadre d’un système de traduction statistique basé sur des segments, et espérons que les résultats bénéficieront au travail présenté ici.
Nous allons par ailleurs poursuivre l’analyse de nos données pour proposer de nouveaux modèles, permettant par exemple de regrouper des sens dans les segments. Dans le cadre d’une intégration dans un système d’aide à la reformulation, nous serons intéressé par la possibilité de corriger les paraphrases produites, pour respecter par exemple des contraintes d’accords grammaticaux. Il nous semble également intéressant de travailler sur le problème du repérage des segments qui seraient de bons candidats à la reformulation (gallicismes en anglais, phraséologie mal adaptée à un genre documentaire, etc.). En outre, nous aurons à considérer l’intégration de segments alignés provenant de corpus comparables, qui sont des ressources beaucoup plus faciles à construire que les corpus alignés. Enfin, ce type de recherche devrait tendre vers plus de généralisation dans le processus de reformulation, et la possibilité de produire des paraphrases plus profondes au niveau d’énoncés, voire de discours. Un type d’application particulièrement intéressant serait alors l’aide à la condensation d’articles scientifiques pour tenir dans des contraintes de taille imposées.
Remerciements L’auteur remercie Daniel Déchelotte pour la préparation de certaines données utilisées dans ce travail, et Didier Bourigault pour l’utilisation de S YNTEX.

Il est possible cependant que la nature des corpus utilisés ne permette pas d’amélioration très sensible des résultats, car le besoin de désambiguïsation est peut-être assez faible dans l’ensemble.
Aurélien Max 

Les architectures linguistiques et computationnelles en traduction automatique sont indépendantes 
Christian BOITET 
Laboratoire LIG, GETALP – Université Joseph Fourier, 385 rue de la bibliothèque, BP 53, 38041 Grenoble, Cedex 9, France Christian.Boitet@imag.fr Résumé Contrairement à une idée répandue, les architectures linguistiques et computationnelles des systèmes de traduction automatique sont indépendantes. Les premières concernent le choix des représentations intermédiaires, les secondes le type d'algorithme, de programmation et de ressources utilisés. Il est ainsi possible d'utiliser des méthodes de calcul « expertes » ou « empiriques » pour construire diverses phases ou modules de systèmes d'architectures linguistiques variées. Nous terminons en donnant quelques éléments pour le choix de ces architectures en fonction des situations traductionnelles et des ressources disponibles, en termes de dictionnaires, de corpus, et de compétences humaines.
Abstract     Contrary to a wide-spread idea, the linguistic and computational architectures of MT systems are independent. The former concern the choice of the intermediate representations, the latter the type of algorithm, programming, and resources used. It is thus possible to use "expert" or "empirical" computational methods to build various phases or modules of systems having various linguistic architectures. We finish by giving some elements for choosing these architectures depending on the translational situations and the available resources, in terms of dictionaries, corpora, and human competences.
Mots-clés : Traduction Automatique, TA, TAO, architecture linguistique, architecture computationnelle, TA experte, TA par règles, TA empirique, TA statistique, TA par l'exemple Keywords: Machine Translation, MT, linguistic architecture, computational architecture, expert MT, rule-based MT, empirical MT, statistical MT, example-based MT.
Introduction Il y a un certain nombre d'idées fausses qui circulent parmi les chercheurs en TA, et freinent à notre avis les progrès dans ce domaine. La première est que la plupart des systèmes opérationnels utilisent la TA statistique, alors que la plupart (voir le Compendium (Hutchins & al. 2005) publié par l'EAMT) utilisent des méthodes « expertes » (« à règles », mais pas seulement à règles). L'autre est que les systèmes utilisant un « pivot interlingue », évidemment très adapté à la communication multilingue, sont nécessairement « à règles » (TAFR, en anglais RBMT ou « rule-based MT »), et donc très coûteux à construire (ce « donc » est faux aussi…).
Il ne faut pas faire l'amalgame entre l'architecture linguistique d'un système de TA, caractérisée par les représentations intermédiaires qu'il utilise durant le processus de traduction, et son architecture computationnelle, caractérisée par les méthodes de calcul et les ressources utilisées dans ses diverses « phases » transformant une représentation intermédiaire en sa suivante dans le processus.
Christian BOITET 
Après une brève partie consacrée aux définitions des variantes de ces architectures, nous montrerons que, pour à peu près chaque architecture linguistique, on trouve des systèmes utilisant diverses architectures computationnelles. De plus, une bonne partie des systèmes utilisent plusieurs architectures computationnelles dans leurs différentes phases. Nous essaierons enfin de dégager quelques indications sur les choix d'architecture appropriés aux diverses situations traductionnelles et des ressources disponibles, en termes de dictionnaires, de corpus, et de compétences humaines.
1 Architectures des systèmes de TA 
1.1 Architectures linguistiques Ces architectures correspondent aux « chemins » dans le fameux « triangle de Vauquois ».
Figure 1 : triangle de Vauquois (Vauquois & Boitet 1985, Analectes de Vauquois — Boitet 1988) Les systèmes directs n'utilisent que deux représentations, le texte d'entrée et le texte de sortie. Pour les langues ayant des systèmes d'écriture à séparateurs de mots ou de syllabes, le texte d'entrée n'est souvent pas strictement le flot de caractères tel quel, mais une suite de « mots typographiques » séparés grâce à des règles simples. Les systèmes semi-directs ont une phase de segmentation ou d'analyse morphologique, voire morphosyntaxique, et une phase de génération morphologique. C'est le cas des systèmes de « première génération » (russe-anglais aux USA et anglais-russe en URSS dès les années 1950), et un certain nombre de systèmes commerciaux actuels sont toujours de ce type.
Il existe au moins 7 variantes des systèmes à transfert. La structure obtenue en fin d'analyse peut être syntagmatique (basée sur des constituants la plupart du temps connexes), ou bien dépendancielle, et dans ce cas surfacique (fonctions syntaxiques comme sujet, objet direct, épithète, attribut…) ou profonde (relations sémantiques comme agent, patient, cause, concession…). Les systèmes à transfert profond fondés sur les théories de Tesnière, puis de l'Ecole de Prague et de celle de Moscou, utilisent des représentations logico-sémantiques distinguant les arguments des circonstants.1 
Les circonstants portent des relations sémantiques (cas profonds), tandis que les arguments ne portent en général qu'un numéro (Arg0, Arg1… Arg4 ou Arg5 au maximum), car il est très difficile sinon impossible d'affecter fiablement une relation sémantique à un argument, si le répertoire de ces relations est celui utilisé pour les circonstants. Le projet FrameNet montre d'ailleurs bien que, si on veut définir des relations Indépendance des architectures linguistiques et computationnelles en traduction automatique 
On dit qu'il y a « transfert lexical » quand on passe directement de « l'espace lexical » de la langue source à celui de la langue cible. Par « espace lexical », on entend tout le système lexical, qui va des « formes » de surface aux « acceptions », en passant par les lemmes et éventuellement par les « unités lexicales » (familles dérivationnelles) ou « prolexèmes » (les mêmes, un peu élargies).
Le « pivot hybride » (terme dû à Shaumyan) des systèmes du CETA des années 1965-70 était un type de représentation utilisant des attributs et relations interlingues, et des unités lexicales de chacune des langues. Ces systèmes étaient donc à transfert simple, alors qu'on a un double transfert en « pivot ».
Les structures multiniveau de Vauquois sont basées sur un graphe syntagmatique abstrait (suppression des auxiliaires, regroupement de lexèmes discontinus comme give...up, etc.), lexicalisé (chaque nœud interne domine un « gouverneur » lexical), et contenant aussi bien les informations et relations profondes que celles de surface. De telles structures sont « génératrices » des structures mononiveau usuelles, et offrent une sorte de « filet de sécurité ».
Les systèmes à véritable interlingua (comme ATLAS-II de Fujitsu ou PIVOT/Crossroads de NEC, ou KANT/CATALYST de CMU/Caterpillar, ou UNL, ou MASTOR-1 d'IBM, ce dernier en TA de parole) utilisent 3 espaces lexicaux, car un véritable interlingua possède son propre vocabulaire, même si ce vocabulaire est construit comme union des acceptions2 d'un certain nombre de langues, comme UNL (Uchida 1996, 2004). Dans les systèmes de TA, il existe des interlinguas « linguisticosémantiques » (comme KANT, ULTRA, UNL) dont les « lexèmes » sont construits à partir des lemmes et des lexies de dictionnaires d'une ou plusieurs langues naturelles, et des interlinguas « sémantiques » ou « sémantico-pragmatiques », dont les lexèmes sont construits à partir des entités, propriétés, actions et processus d'un domaine précis et d'un ensemble de tâches bien identifiées (par exemple, réservation touristique).
Enfin, si la plupart des systèmes de TA ont comme « unité de traduction » le « segment » (phrase ou titre) des systèmes d'aide au traducteur utilisant des mémoires de traductions, certains ont des unités de traduction de l'ordre de la page (Ariane-G5), ce qui permet de mieux traiter certains phénomènes comme la concordance des temps et de résoudre des anaphores hors du contexte de la phrase.

1.2 Architectures computationnelles Pour ce qui est des processus automatiques, on distingue entre méthodes expertes et méthodes empiriques. Il y a aussi des distinctions à faire si le processus de traduction est interactif.

1.2.1      Méthodes « expertes » Les méthodes « expertes » sont plus ou moins procédurales ou déclaratives, et font appel à de la programmation directe ou fondée sur des « modèles de calcul » abstraits, d'où l'utilisation de LSPL (langages spécialisés pour a programmation linguistique). On a en bref : •      la programmation directe dans un langage algorithmique classique (souvent employée au niveau des traitements typographiques ou morphologiques).
•      la programmation directe dans un langage de haut ou très haut niveau (Lisp, Prolog) offrant des structures de données et de contrôle plus adaptées à la programmation linguistique, mais demandant une grande expertise en programmation.
•      la programmation dans des LSPL d'automates (comme les transducteurs finis, les ATN ou les transformateurs d'arbres, abusivement dits « grammaires » transformationnelles).
•      la programmation dans des formalismes de grammaires déclaratives (ou presque) comme LFG, GPSG, HPSG, ou TAG.

sémantiques pour les arguments, il faut le plus souvent les lexicaliser ("donner" aura alors "donateur/donneur" pour Arg0, "don" pour Arg1, "donataire" pour Arg2).

Une "acception" est un sens d'un mot, au sens de lemme ou terme, dans l'usage de la langue. Une "lexie" est un sens de mot dans un dictionnaire.
Christian BOITET 
Il est abusif de parler de systèmes « à règles » pour les deux premiers. Ainsi, Systran utilise des automates (transducteurs d'états finis) pour l'analyse morphologique, tandis que l'analyse syntaxique n'est pas faite par « règles », mais par un programme instanciant un schéma procédural fixe (écriture de « macros » déterminant des décisions locales par examen d'une « fenêtre courante » sur un graphe sans boucle représentant la phrase).

1.2.2   Méthodes empiriques Ce sont les méthodes fondées sur les corpus : •   TA statistique (SMT) et TA statistique à syntagmes (PSMT, ou « phrase-based » SMT), •   TA fondée sur les exemples (EBMT), avec 3 variantes.
Notons que « TA statistique » est un assez mauvais terme, car on devrait plutôt parler de TA « probabiliste ». En effet, un « modèle de langage » est une collection de probabilités estimées d'après des comptages sur de gros ou très gros corpus.
La différence essentielle entre SMT et EBMT est que, en EBMT, les exemples sont utilisés directement durant le processus de traduction, tandis que la SMT utilise les résultats d'une sorte de gigantesque « compilation » de l'ensemble des exemples (corpus aligné).
Les variantes de l'EBMT sont les suivantes : •   En EBMT classique, on étend les techniques de recherche de segments voisins des systèmes d'aide aux traducteurs avec mémoire de traductions, et on propose, pour les mots différenciant le segment à traduire et le segment trouvé, des remplacements venant d'autres exemples ou de dictionnaires. Le système Similis™(dérivé de (Planas 1998)) d’aide au traducteur en est proche.
•   En EBMT par analogie (Lepage & Denoual 2005), si S1 est le segment à traduire (en langue L1), on cherche les « rectangles analogiques » P1:Q1::R1:S1 tels qu'on dispose des exemples de traduction (P1,P2), (Q1,Q2), (R1,R2), et on résout en X (dans la langue L2) l'équation analogique P2:Q2::R2:X. On obtient en général plusieurs traductions X, qu'on filtre pour la fluidité par un modèle n-gramme. Si on ne trouve pas de tel rectangle, on résout en Y (dans la langue L1) l'équation P1:Q1::Y:S1 et on continue récursivement. Il n'y a donc pas de « décomposition en morceaux qui se correspondent » puis de « recomposition ».
•   Dans le système EBMT par exemples de correspondances structurées de Al-Adhaileh et Tang (USM, Penang), on utilise un corpus parallèle annoté par des S-SSTC (correspondances chaînearbre structurées synchronisées). La traduction se fait par analyse-synthèse. Une correspondance (C1, A1)—c—(C2, A2) est élémentaire ou composée (= {(C1i, A1i)—ci—(C2i, A2i)}i).
Quand on en trouve une car on a identifié un morceau C1 du segment S1 à traduire, ou bien les correspondances la constituant, on a d'un seul coup les 3 autres éléments et leur synchronisation.
2 Variété des architectures computationnelles Voici maintenant une étude synthétique (non exhaustive) des architectures computationnelles utilisées dans des systèmes de TA basés sur 11 architectures linguistiques différentes. Pour la clarté, nous utilisons des tableaux, organisés de la façon la plus homogène possible. Il n’a malheureusement pas été possible de suivre la suggestion d’un relecteur, et de faire un seul grand tableau croisant les deux architectures, car trop de systèmes utilisent différentes architectures computationnelles dans différentes phases du traitement. Pour des raisons de place, il n’a pas non plus été possible de mettre autant de références qu’on l’aurait souhaité. D’un autre côté, les références sur les systèmes opérationnels (commerciaux comme Systran, ATLAS, The Translator, Honyaku-no-oo-sama, ProMT, Softissimo, Tracy, PIVOT/Crossroads, ALTFlash, METAL/Compendium, LanguageWeaver, etc., et non commerciaux ou semi-commerciaux comme PAHO-MTS, ALT/JE ou Google Translator) sont très rares et souvent anciennes. Le « Compendium » (Hutchins & al. 2005) est une source importante, mais ne donne pas de détails précis sur la façon dont les systèmes cités sont construits.
Indépendance des architectures linguistiques et computationnelles en traduction automatique 
2.1 Systèmes de traduction directe Type Étapes           Méthode               Commentaires                            Exemples RBMT Segmentation FST (règles + dict.) Convient pour des langues très voisines ATLAS-I Fujitsu,76-78 1975— Trad. mot à mot règles                japonais ↔ coréen, hindi ↔ urdu …       (coréen↔japonais) SMT Segmentation, Alignement +              SMT = première idée sur la TA par les Beaucoup de systèmes 1980— réarrangement… « décodage »           cryptographes de la 2° guerre mondiale statistiques (SMT) statistique           (W. Weaver 1949)                        IBM 1980EBMT Pas de           Résolution analogique Résultats ≈ ceux de la SMT              ALEPH 2000— prétraitement   + filtrage n-grammes Nagao 1984 (plutôt TA par similarité) ATR 2000EBMT « pure » analogique              Lepage 2000 (vraie analogie à 4 termes) GREYT, Caen 2006— Le plus souvent, ces systèmes sont « empiriques », mais certains utilisent une approche « experte », comme ATLAS-I (différent de ATLAS-II).

2.2 Systèmes de traduction semi-directe Type   Étapes            Méthode                   Commentaires         Exemples 1G-MT Segmentation & Consultation de               Tables + macros sur  GAT (Georgetown) 1950— Lemmatisation par dictionnaire + "macros"    des chaînes          EURATOM, Ispra, 1965—69 programme         de réarrangement          procédural           SPANAM-1, PAHO, ≈1975— procédural                                     GLOBALINK ← Spanam-1 (PAHO) SMT Lemmatisation        Procédural + règles       Modèle de langue     Candide IBM, 1980—, Google 20051990— Décodage           statistique               probabiliste         Beaucoup de systèmes statistiques Trad. Lemmatisation      Traitement de chaînes     procédural (snobol4) Idée de B. Harris pidgin Transfert lexical règles en systèmes-Q      Énoncé =             (TAUM, « traductologiste ») Réarrangement     --                        graphe de chaînes    rus → eng, fre (Boitet 1972) Génération        --                        d'arbres étiquetés GlobaLink a été fait à partir d'une copie de Spanam-1. Spanam-2 est de type expert (ATN).
Les systèmes actuels de Google sont (sans doute) plus PSMT (phrase-based SMT) que SMT.

2.3 Systèmes à transfert descendant de constituants Type Étapes                  Méthode               Commentaires        Exemples RBMT Analyse par ATN         LSPL étendant Lisp ou règles + dict. +    ENGSPAN, SPANAM-2, ou 1970—                        un autre Lprog        transformation      ‘PAHO-MTS’ (PAHO, ≈1978—) Transfert/génération   Descente récursive    procédural + règles AS-Transac (Toshiba, 1982—) Reverso ProMT, 1986— RBMT    Analyse par ECFG LSPL étendant Lisp ou grammaire+dict.         METAL (TUA+Siemens, 1982—) 1980—   (hors-contexte        un autre Lprog       règles              Duet-2 (Sharp, 1984—) étendu)                                                        Shalt-1 (IBM-Japon, 1982—) Transfert /génération Descente récursive   procédural + règles Kate KDD (1983—) RBMT    Lemmatisation         Dictionnaire +tables procédural          LMT (IBM-US, 1983—) 1984—   Slot-grammars         LSPL étendant Prolog règles              PT-1 (Personal Tanslator) de T+G en Prolog         Descente récursive   procédural + règles Linguatec, dérivé de LMT, —2000 Les systèmes récents de type PSMT de LanguageWeaver sont sans doute aussi de ce type.

2.4 Systèmes à transfert descendant de dépendances Type    Étapes                  Méthode                            Commentaires          Exemples 1.5G-MT Lemmatisation           FST (+ dictionnaires)              règles                Systran 1990— 1990— Analyse produisant un     macros C + dictionnaire            procédural graphe de dépendances   Descente récursive                 procédural Transfert /génération RBMT Segm.+ lemmatisation       dictionnaire + tables              procédural            JETS (IBM-Japon, 1985— Analyse de                LSPL pour les grammaires de        grammaire + dict.     1985-90) dépendances             dépendances + contraintes          règles Désamb. interactive     limitées (1 seul quantificateur)   contraintes Transfert /génération   Descente récursive                 procédural + règles Christian BOITET 
RBMT     Segmentation et          Programmation                       procédural + règles        Neon (Xiamen) /SMT     lemmatisation multiple   en Pascal puis C                    Version hybride            En-Ch & Ch-En, 2000—    Analyse de               + dictionnaire                      (TA experte + SMT)         2000— dépendances              Algorithme factorisant (DP)         depuis 2006 Tranfert/génération      Descente récursive                  + statistiques Systran est très ancien (1966), mais depuis 1990 environ il intègre des FST pour les traitements morphologiques, et les macros utilisées pour la suite du traitement sont développées en C et plus en assembleur. Dans JETS (ancêtre de Honyaku no oo-sama, actuellement commercialisé par IBMJapon), les dépendances sont les « cas profonds » correspondant aux particules casuelles du japonais.

2.5 Systèmes à transfert horizontal de constituants Type Analyse/données       Transfert/préparation        Génération/méthode           Exemples RBMT Lemmatisation +       Contient la génération       Descente récursive           PT (= LMT d'IBM) 1995— Slot Grammars        Prolog                       grammaire+dict.              Linguatech, 1995—2000 règles               procédural + dict.           règles EBMT Données initiales:    Préparation: construction    Traduction: 3 étapes         « EBMT » (ou ‘Banturjah’) 2000— corpus // bilingue   autom. de S-SSTCs puis       en parallèle (A//T//G)       UTMK, USM, 2000— dictionnaire         édition (humaine)            combinaison ascendante       basé sur un corpus de S-SSTC PSMT Lemmatisation         Alignement                   Aplatissement de l'arbre     LanguageWeaver 2002— PSCFG Chunking             Décodage                     Post-traitement              Google 2005— 2002— statistique          statistique                  statistique                  +Wu, Melamed 1997, 2004 La différence avec les systèmes précédents est que le transfert produit une structure de même nature que ce que produirait l'analyse de l'unité de traduction cible. Cela permet éventuellement de composer deux systèmes de TA en perdant beaucoup moins d'information et en introduisant beaucoup moins d'erreurs qu'en mettant bout à bout deux systèmes complets, i.e. en passant par un « pivot textuel ».

2.6 Systèmes à transfert horizontal de dépendances Type     Analyse                  Transfert                       Génération               Exemples RBMT     Grammaire + dict.        Dictionnaires                   Aplatissement de l'arbre ETAP-2, ETAP-3 1975—    Anal. de dépendance      Transformations d'arbres        grammaire+dict.          IPPI, Moscou, 1977— règles                   règles                          règles RBMT     Lemmatisation +          Dictionnaire de « treelets »    Aplatissement de l'arbre TDMT, Furuse (prototype 1992—    patrons linéaires        + thesaurus sémantique          grammaire+dict.          pour la TA de parole) règles                   règles                          règles                   ATR, 1992—1998 RBMT+ Analyseurs de MSR           Apprentissage du transfert Générateurs de               MTS-1 SMT   (Microsoft)                 à partir de paires (lf_s, lf_t) Microsoft               (prototype sur de la 1999— règles (en G)               statistique                     règles (en G)           documentation technique) LMT (MacCord, IBM), est rangé ici car les « slots » correspondent à des fonctions syntaxiques.

2.7 Systèmes à transfert multiniveau horizontal Type Étapes                            Méthode                     Commentaires               Exemples RBMT Lemmatisation                     Dictionnaire + tables       procédural + dict.         ITS-2 (Genève, 1990—) 1990— Analyse multiple par ECFG        Programmation en            dict. + grammaire (gouvernement & liage)           langage évolué              procédural + règles Désambiguïsation interactive     (Modula)                    interactif si pas assez de place            --                          procédural + règles Transfert autonome               --                            + dictionnaire Génération                       descente récursive          aplatissement de l'arbre RBMT Lemmatisation +                   LSPL grammatical,           procédural + dict.         PT-2 (Linguatec et 2000— Slot Grammars                    analyse multiple            dict. + gram.              Lingenio) depuis 2000 Transfert autonome               dictionnaire de treelets    procédural + règles Génération                       descente récursive          (en Prolog) Passer d'une architecture à transfert descendant à celle de transfert « horizontal » a été très difficile (communication personnelle de K. Eberle de Linguatec à COLING-2000). Cela a été aussi tenté sur METAL (par Siemens puis Sietech), mais sans succès.
Indépendance des architectures linguistiques et computationnelles en traduction automatique 
2.8 Systèmes à transfert ascendant multiniveau Type Étapes                  Méthode                  Commentaires                  Exemples RBMT Analyse morphologique dictionnaire + automate LSPL (5 au total)                Systèmes en Ariane-G5 1978— Analyse structurale    transformations d'arbres règles                        1974Tansfert lexical       règles de réécriture     pour toutes les               ru-de→ru, en→my-th 80-87 Transfert structural   dictionnaires            phases                        fr→en (BV/aero) 85-92 Génération structurale transformations d'arbres dictionnaires pour            fr→en-de-ru (LIDIA) 90-96 Génération morphol.    dictionnaire + automate certaines phases               HICATS Hitachi (1990-) Jemah USM, NUS (1990-) Ici, le transfert produit une structure multiniveau « génératrice » dans laquelle les informations non interlingues correspondent à celles de la langue source de façon « contrastive », et sont à utiliser par le générateur comme des préférences ou des ordres en fonction des valeurs de certains attributs « tactiques ». La première phase de l'étape de génération consiste alors à « sélectionner une paraphrase » en recalculant les informations de surface.

2.9 Systèmes à transfert sémantique ou « conceptuel » Type Étapes                     Méthode                  Commentaires           Exemples RBMT Segm. +lemmatisation       Programmation en C       procédural             MU (Kyodai, 82-87) 1982— Autres phases             Transformations d'arbres règles (gram.s + dict) MAJESTIC (JICST, 87—) On pourrait ajouter les systèmes du CETA (1962-70), à « pivot hybride », décrit plus haut.

2.10 Systèmes à interlingua sémantique ou « linguistico-sémantique » Il s'agit de systèmes utilisant un interlingua muni d'un vocabulaire « autonome ».
Type Enconversion                      Déconversion          Commentaires              Exemples RBMT Lemmatisation directe             Transformations       procédural                ATLAS-II 1980— Transformations chaîne-graphe    graphe-chaîne         +                         Fujitsu, 1980— règles                           règles                règles                    PIVOT Nec, 1983— RBMT Formalisme proche des DCG         LSPL fondé sur des règles                       ULTRA NMSU, 89-95 1980— règles                           règles Prolog RBMT Selon les partenaires             Selon les partenaires graphe UNL = structure    UNL 1996— 1997— règles (jusqu'à présent)         règles                « anglo-sémantique » Les graphes UNL sont « linguistico-sémantiques ». Le vocabulaire (UW) est l'union des acceptions des différentes langues traitées, comme dans ULTRA, mais les relations sémantiques et le traitement des idiomes sont liés à l'anglais (et tant mieux, car les langues voient assez souvent différemment les relations sémantiques dans des énoncés synonymes).

2.11 Systèmes à ontologie Ces systèmes sont les seuls à faire de la « compréhension explicite », leur interlingua étant « projeté » dans une ontologie Ω, soit de façon séparée, soit de façon interne.
Type Enconversion             Projection dans une Ω     Déconversion          Examples KBMT Lemmatisation &          Oui, de tout sauf les     Planification de la   KBMT-89 CMU, 1989—91 1980— EPSG+f-structures       éléments de discours      structure profonde    KANT/Catalyst +pseudo-unification     dict. + règles            Descente récursive    CMU+Caterpillar, Règles (Univ. Parser)   + désamb. interactive     règles                en→fr-sp-de-? 1992— RBMT Dictionnaire + FST       Pas d'ontologie           dictionnaire + FST    CSTAR-II & Nespole! 1997— règles                  explicite séparée :       règles                GETA 97-03, ETRI (Corée) 97-99 SMT Appris à partir de        c'est l'idée (ancienne)   Appris à partir de    CSTAR-II & Nespole! 2003— couples (chaîne,IF)     des « grammaires          couples (IF,chaîne)   Irst 98-03 statistique             sémantiques »             statistique           Mastor-1 (IBM 2003), sur PDA L'IF (interface format) réfère à une ontologie implicite, pas explicite.
Christian BOITET 
3 Éléments pour le choix d'architectures en TA 
3.1 Taille et coût des ressources / architectures computationnelles Le tableau suivant donne une estimation des ressources nécessaires pour construire un système de TA en fonction de la difficulté de la tâche, grossièrement estimée à partir de la taille moyenne des phrases.
Les coûts sont donnés ici en homme*année (h*a), M veut dire « million », et K « mille ».
•   Pour la TA empirique, il s'agit de la taille du corpus, en mots, pages (de 250 mots), phrases, et du temps humain de préparation de ce corpus. S’il s’agit de traduction, nous utilisons le taux professionnel de 1h/page (avec la révision, ce serait 1h20 par page). S’il s’agit d’annotation, les coûts ne sont la plupart du temps pas publiés, et nous utilisons des informations dont nous disposons par communications personnelles. Le coût par page est bien plus élevé, mais le corpus peut être beaucoup plus petit, et finalement bien moins coûteux, pour de meilleurs résultats.
•   Pour la TA experte, il s'agit de la taille des dictionnaires et des grammaires, et du travail d'experts humains. Contrairement à ce qu’on lit dans de nombreux cours sur la TA qu’on peut glaner sur le Web, ce coût est souvent très surévalué, et pas seulement par les tenants des méthodes empiriques.
Phrases              6.5 mots/phrase                          25 mots/phrase Type                          BTEC, METEO                              Informations (news) SMT                           0.9—3 M mots                             50—200 M mots PSMT                          3.6—12 K pages                           200—800 K pages EBMT par analogie             0.15—0.5 M phrases                       2—8 M phrases Coût : 2.4—8 h*a                                100—400 h*a (rarement disponible !) EBMT avec arbres              N/A pour ce type de phrases courtes      4—12.5 M mots SMT                           Apprentissage supervisé                  15—50 K pages Mastor-1 (IBM)                1h/page (par recoupements)               0.15—0.5 M phrases Coût :                                          10—40 h*a EBMT avec arbres et S-SSTCs N/A pour phrases courtes                   4—12.5 M mots Banturjah (USM)               Apprentissage supervisé                  0.6—1 K pages Coût : 15 h/page (10 h/p espéré)                0.006—0.01 M phrases dictionnaire (50 K) souvent disponible   6—10 h*a (travail assez spécialisé) RBMT                          Dictionnaire 3-10 K 0.6—2 h*a            Dict. 50-500 K, soit     15—150 h*a Grammaires environ       25 h*a Coût : Total 1—3 h*a                           Total ≈ 40—175 h*a 
3.2 Brève analyse 1. Il est clair que, plus les corpus sont « bruts », plus ils doivent être grands. Même à raison de 15h/page de travail humain, il semble intéressant d'utiliser une méthode comme celle de l'USM à Penang, car on n'a besoin que de 1000 pages et d'un gros dictionnaire assez simple.
2. D'autre part, la SMT (et la PSMT) sont en fait adaptées à des « niches de riches », tout comme la TA « experte » pour sous-langages. En effet, il y a très peu de corpus parallèles disponibles de 200 à 800 K pages ! Du point de vue des corpus, les différences entre couples de langues « bien dotés » et « mal dotés » sont encore plus grandes qu'en ce qui concerne les dictionnaires.
3. Créer de très gros corpus parallèles à partir de zéro est 2 à 3 fois plus coûteux que de construire un grand système de TA par approche experte (procédurale et/ou à automates et grammaires).
4. L'architecture linguistique par « pivot interlingue » peut utiliser n'importe quel paradigme computationnel, qu'il soit statistique, analogique, à règles, ou hybride.
5. En dernier ressort, le choix de l'architecture linguistique et de l'architecture computationnelle dépend des ressources disponibles en termes de corpus préalablement traduits, et d'humains plus ou moins experts. Les types d'expertise recherchée sont, par ordre de difficulté croissante (estimée via le temps de formation et la relative rareté des experts) : la traduction, la post-édition, la correction d'annotations, l'annotation à partir de rien, la terminologie, la lexicographie complexe Indépendance des architectures linguistiques et computationnelles en traduction automatique 
(vocabulaire général et tournures), l'écriture de grammaires assez déclaratives, la programmation par automates dans des LSPL adaptés, et enfin la programmation directe.
Conclusion Nous avons donc montré que les architectures linguistiques et computationnelles des systèmes de traduction automatique sont indépendantes, au sens où on peut utiliser n'importe quelle architecture computationnelle pour réaliser n'importe quelle phase de traitement dans une architecture linguistique donnée, non seulement en théorie, mais en pratique, comme l'illustre la variété des systèmes cités en exemple. Nous avons aussi donné une évaluation des tailles et des coûts de construction des ressources utilisées par différents types de systèmes de TA, ce qui donne quelques éléments pour le choix de l'architecture linguistique et computationnelle d'un système à créer, en fonction des situations traductionnelles et des ressources disponibles, en termes de dictionnaires, de corpus, et de compétences humaines.
Cette réflexion ouvre sur une perspective plus générale et « sociétale ». Si l'on veut surmonter la « barrière linguistique » entre toutes les langues, on ne pourra pas se contenter de construire des systèmes de TA entre l'anglais et les autres langues, même pas pour le tchat entre deux langues différentes de l'anglais. En effet, l'anglais intermédiaire serait nécessairement trop « grossier », entaché d'erreurs, et porteur d'ambiguïtés nouvelles en sus des anciennes (celles de la langue source). La plupart des locuteurs (ou simplement lecteurs « passifs ») seront de plus toujours bien moins compétents et à l'aise en anglais que dans leur langue.
Il faudra donc construire des systèmes fondés sur des interlingues, soit « sémantico-pragmatiques » (comme l'IF de CSTAR, Nespole! ou MASTOR-1) s'il s'agit de tâches et de domaines restreints et bien identifiés, soit « linguistico-sémantiques » (comme UNL). Cela sera d'autant plus nécessaire qu'on voudra intégrer ces systèmes au « Web sémantique », car il faudra alors demander aux internautes d'aider les systèmes d'annotation, sans doute par le même type de « désambiguïsation interactive » que celui qui permet de compenser la nécessaire « rusticité » (ou la « mauvaise qualité intrinsèque ») des systèmes de TA « tout terrain » quand on veut les utiliser en « tout automatique ».
Il ressort de ce qui précède qu'il devrait être possible de construire des systèmes de TA entre toutes les langues, passant par un niveau sémantique comme UNL, non seulement par des approches « expertes » comme c'est le cas actuellement, mais par des approches empiriques moins coûteuses et moins longues en développement, si toutefois on disposait de corpus adéquats de taille suffisante.
D'autre part, à la lumière des développements récents en alignement et en TA statistique, de tels corpus devraient pouvoir être construits par « transitivité », en alignant des corpus parallèles et des corpus annotés en IL (en UNL par exemple) s'ils ont au moins une langue en commun.


Généralisation de l’alignement sous-phrastique par échantillonnage 
Adrien Lardilleux1 François Yvon1,2 Yves Lepage3 (1) LIMSI-CNRS, BP 133, 91403 Orsay Cedex (2) Université Paris-Sud (3) IPS, université Waseda, Japon Adrien.Lardilleux@limsi.fr, Francois.Yvon@limsi.fr, Yves.Lepage@aoni.waseda.jp 
Résumé.          L’alignement sous-phrastique consiste à extraire des traductions d’unités textuelles de grain inférieur à la phrase à partir de textes multilingues parallèles alignés au niveau de la phrase. Un tel alignement est nécessaire, par exemple, pour entraîner des systèmes de traduction statistique. L’approche standard pour réaliser cette tâche implique l’estimation successive de plusieurs modèles probabilistes de complexité croissante et l’utilisation d’heuristiques qui permettent d’aligner des mots isolés, puis, par extension, des groupes de mots. Dans cet article, nous considérons une approche alternative, initialement proposée dans (Lardilleux & Lepage, 2008), qui repose sur un principe beaucoup plus simple, à savoir la comparaison des profils d’occurrences dans des souscorpus obtenus par échantillonnage. Après avoir analysé les forces et faiblesses de cette approche, nous montrons comment améliorer la détection d’unités de traduction longues, et évaluons ces améliorations sur des tâches de traduction automatique.
Abstract. Sub-sentential alignment is the process by which multi-word translation units are extracted from sentence-aligned multilingual parallel texts. Such alignment is necessary, for instance, to train statistical machine translation systems. Standard approaches typically rely on the estimation of several probabilistic models of increasing complexity and on the use of various heuristics that make it possible to align, first isolated words, then, by extension, groups of words. In this paper, we explore an alternative approach, originally proposed in (Lardilleux & Lepage, 2008), that relies on a much simpler principle, which is the comparison of occurrence profiles in subcorpora obtained by sampling. After analyzing the strengths and weaknesses of this approach, we show how to improve the detection of long translation units, and evaluate these improvements on machine translation tasks.
Mots-clés :         alignement sous-phrastique, traduction automatique par fragments.

Keywords:           sub-sentential alignment, phrase-based machine translation.
1    Introduction L’alignement sous-phrastique consiste à extraire des traductions d’unités textuelles de grain inférieur à la phrase à partir de corpus multilingues parallèles, c’est-à-dire dont les phrases ont préalablement été mises en correspondance. Cette tâche constitue la première étape de la plupart des systèmes de traduction automatique fondés sur les données (traduction statistique et traduction par l’exemple). Les systèmes qui concentrent aujourd’hui les efforts de recherche sont majoritairement des systèmes statistiques par fragments (phrases en anglais), qui utilisent comme principale ressource une table de traductions, dérivée d’alignements sous-phrastiques. Un telle table consiste en une liste pré-calculée de couples de traductions associant à chaque couple de fragments (source, cible) un certain nombre de scores reflétant la probabilité que source se traduise par cible.
On peut globalement inscrire les méthodes d’alignement sous-phrastique dans l’un des deux courants suivants : l’approche estimative, introduite par Brown et al. (1988), et l’approche associative, introduite par Gale & Church (1991). La première est la plus utilisée à ce jour, principalement parce qu’elle est parfaitement intégrée à la traduction automatique statistique, dont elle constitue un pilier depuis l’apparition des modèles IBM (Brown et al., 1993).
Cette approche consiste à définir un modèle probabiliste du corpus parallèle dont les paramètres sont estimés selon un processus de maximisation globale sur l’ensemble des couples de phrases disponibles. Pratiquement, le but est de déterminer les meilleurs appariements possibles entre les mots sources et cibles dans chacun des couples de phrases parallèles. Dans la seconde approche, on établit une liste de traductions candidates soumises à un test d’indépendance statistique, tels que l’information mutuelle (Fung & Church, 1994) ou le rapport de vraisemblance A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 
(Dunning, 1993) — voir (Melamed, 2000; Moore, 2005) pour des travaux récents dans cette lignée. Il s’agit ici d’un processus de maximisation locale : chaque segment est traité indépendamment des autres. Cette approche est plus souvent utilisée pour extraire directement des couples de traductions, tandis que la première cherche avant tout à établir des liens de traduction entre les mots sources et cibles de chacun des couples de phrases du corpus d’entrée. Ces liens permettent, dans un deuxième temps, d’extraire des couples de traductions.
Nous avons récemment proposé une méthode d’alignement sous-phrastique (Lardilleux & Lepage, 2008, 2009; Lardilleux, 2010), apparentée aux méthodes associatives, s’attaquant à un certain nombre de problèmes souvent négligés dans le domaine : traitement simultané de multiples langues, parallélisme massif, passage à l’échelle au cœur de la méthode, et simplicité de mise en œuvre. En moyenne, cette méthode s’est révélée meilleure que l’état de l’art sur des tâches de constitution de lexiques bilingues, mais en retrait sur des tâches de traduction automatique par fragments (Lardilleux et al., 2009). Nous n’avions émis jusqu’alors que des hypothèses pour expliquer ces résultats a priori contradictoires. Dans cet article, nous proposons une analyse fine du comportement de notre méthode afin de déterminer l’origine de ces différences, ainsi qu’une généralisation destinée à améliorer ses performances en traduction automatique par fragments.
Cet article est organisé de la façon suivante : la section 2 présente une vue d’ensemble de la méthode d’alignement d’origine ; la section 3 présente des expériences mettant en évidence l’origine de ses faiblesses ; nous décrivons dans la section 4 une généralisation, et évaluons ses performances ; et la section 5 conclut ces travaux.
2      Vue d’ensemble de la méthode d’alignement d’origine 
2.1     Principes de base 
Notre méthode d’alignement peut être vue comme une émulation des méthodes associatives, à la différence (majeure) près qu’elle ne se restreint pas à aligner des couples de mots1 (source, cible). Elle permet, en effet, de considérer des séquences de mots de taille variable, éventuellement discontinues, qui partagent strictement la même distribution (répartition) dans les phrases du corpus parallèle d’entrée, indépendamment de leur langue. Ces séquences constituent en fait un sous-ensemble des candidats de traduction qui obtiendraient un score maximal par des tests d’association statistiques. Le nombre de séquences de mots ayant exactement la même distribution étant réduit, nous ne recherchons pas ces séquences dans le corpus d’entrée même, mais dans des sous-corpus de celuici, l’idée étant que plus un sous-corpus est petit, plus les mots qu’il contient ont de chances de partager la même distribution, et que par conséquent plus le nombre de mots alignés dans ce sous-corpus est élevée.
Le cœur de la méthode consiste donc à extraire des alignements à partir de multiples sous-corpus indépendants construits par échantillonnage. En pratique, nous privilégions les sous-corpus de petite taille car ils sont plus rapides à traiter et semblent donner de meilleurs résultats (Lardilleux, 2010). Pour chaque séquence de mots de même distribution dans un sous-corpus, deux alignements sont extraits : la séquence elle-même, d’une part, et son complémentaire, d’autre part. Le nombre de sous-corpus à traiter n’étant pas défini à l’avance, le processus est anytime, c’est-à-dire qu’il peut être interrompu à tout moment par l’utilisateur, ou selon des critères tels que le temps écoulé ou le taux de couverture du corpus de départ. Plus le nombre de sous-corpus traités est élevé, plus la couverture du corpus de départ est grande et plus les mesures d’association sont précises. Les alignements extraits sont collectés à partir de l’ensemble des sous-corpus traités, et sont évalués par divers scores (probabilité de traduction et poids lexicaux (Koehn et al., 2003)) à proportion du nombre de fois qu’ils ont été extraits. Le résultat est une table de traductions directement utilisable, par exemple, pour des tâches de traduction automatique.
2.2     Algorithme complet 
L’algorithme d’extraction complet est schématisé dans le tableau 1.
La figure 1 illustre les principales étapes de l’algorithme sur un exemple d’alignement d’un texte trilingue. Dans la suite de cet article consacré aux applications de l’alignement en traduction automatique, nous nous limiterons à une application bilingue de la méthode, bien que son caractère multilingue en constitue un atout majeur.

1 Nous   employons le terme « mot » pour désigner toute forme graphique identifiée par un programme de tokenisation.
G ÉNÉRALISATION DE L’ ALIGNEMENT SOUS - PHRASTIQUE PAR ÉCHANTILLONNAGE Entrée : un corpus multilingue, ici arabe-français-anglais.
1                                    ↔ Un café , s’il vous plaît . ↔ One coffee , please .
2                                    ↔ Ce café est excellent .                       ↔ This coffee is excellent .
3                                    ↔ Un thé fort .                                 ↔ One strong tea .
4                                    ↔ Un café fort .                                ↔ One strong coffee .
Transformation en corpus alingue (= monolingue) en concaténant les traductions d’une même phrase et distinguant les mots en fonction de leur langue d’origine.
Sélection d’un sous-corpus aléatoire (ici, les trois premières lignes du corpus d’origine).
1    1 1            1       1 1            Un2 café2 ,2 s’il2 vous2 plaît2 .2 One3 coffee3 ,3 please3 .3 2    1 1            1        1           Ce2 café2 est2 excellent2 .2 This3 coffee3 is3 excellent3 .3 3    1 1        1             Un2 thé2 fort2 .2 One3 strong3 tea3 .3 Indexation des mots (calcul des vecteurs de présence). Les mots ayant même distribution sont regroupés.
1   .2 .3   1       café2 coffee3 One3 Un2           1 1           1    ,3 ,2 plaît2 please3 s’il2 vous2        1       1       Ce2 This3 est2 excellent2 . . .
1 1 11               1    1      1           1        1   1     1           1 11       1          1       1      1       0       0    0       0   0       0      ...
2 1 11               1    1      1           0        0   0     0           0 00       0          0       0      0       1       1    1       1   1       1      ...
3 1 11               0    0      0           1        1   0     0           0 00       0          0       0      0       0       0    0       0   0       0      ...
Chaque groupe de mots permet d’extraire deux alignements par phrase où il apparaît.
apparaissent dans Les mots :                                                                                      d’où sont extraits : les phrases : 
1         café2 coffee3 
1 1            1        1     Un2 _ ,2 s’il2 vous2 plaît2 .2 One3 _ ,3 please3 .3 1               café2 coffee3 1          café2 coffee3 
1 1            _1                 Ce2 _ est2 excellent2 .2 This3 _ is3 excellent3 .3 ..
Décompte des alignements et rétablissement des limites entre langues.
Arabe                                   Français                               Anglais               Décompte ↔ café                                         ↔ coffee                                  2 ↔ Un _ , s’il vous plaît . ↔ One _ , please .                                            1 _               ↔ Ce _ est excellent .                         ↔ This _ is excellent .                   1 ..
F IG . 1 – Vue d’ensemble de la méthode d’alignement. C’est la phase d’indexation et de constitution des groupes de mots (troisième étape sur la figure) que nous généraliserons dans la suite de l’article.
A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 
Transformer le corpus parallèle d’entrée, multilingue, en corpus alingue (= monolingue) Initialiser un tableau associatif CompteurAlignements Faire Sélectionner un sous-corpus par échantillonnage Indexer les mots par leur vecteur de présence dans les phrases du sous-corpus Les mots de même distribution sont rassemblés dans un même groupe Pour chaque groupe de mots : Pour chaque phrase où le groupe apparaît : Rétablir l’ordre des mots du groupe CompteurAlignements[groupe] ++ CompteurAlignements[phrase - groupe] ++ Jusqu’à interruption par l’utilisateur ou temps imparti écoulé ou plus aucun alignement obtenu ou tout autre critère Calculer les scores des alignements 
TAB . 1 – Les étapes de la méthode d’alignement.
2.3     Résultats 
Dans cette section, nous résumons les principaux résultats et conclusions de (Lardilleux, 2010). Nous avons évalué cette méthode d’alignement sur deux tâches : en traduction automatique statistique par fragments et en constitution de lexiques bilingues. L’implémentation de notre méthode, Anymalign2 , est comparée à MGIZA++3 (Gao & Vogel, 2008), l’implantation la plus récente des modèles IBM. Anymalign étant anytime, nous commençons en pratique par exécuter MGIZA++ avec ses paramètres par défaut (5 itérations de chacun des modèles IBM1, HMM, IBM3 et IBM4), mesurons son temps d’exécution, et exécutons Anymalign pendant la même durée. Les corpus parallèles utilisés dans les expériences sont principalement Europarl (Koehn, 2005) et des extraits du BTEC (Takezawa et al., 2002), distribués lors des campagnes d’évaluation de traduction automatique IWSLT (Fordyce, 2007).
Les extraits du BTEC sont constitués de 20 000 à 40 000 couples de phrases courtes alignées (10 mots anglais en moyenne) et ceux d’Europarl de 100 000 couples de phrases longues (30 mots anglais).
Dans la tâche de traduction automatique statistique par fragments, nous comparons les scores obtenus par Moses (Koehn et al., 2007) avec sa table de traductions par défaut, construite à partir des alignements de MGIZA++, et celle produite par Anymalign. En moyenne, Anymalign est en retrait de deux points BLEU (Papineni et al., 2002) sur l’ensemble des expériences que nous avons menées. Dans le meilleur des cas, nous avons obtenu un gain d’un point par rapport à MGIZA++ (BTEC, japonais-anglais) ; dans le pire, une perte de huit points (Europarl, finnois-anglais). Dans l’ensemble, les écarts sont plus prononcés sur Europarl que sur le BTEC.
Dans la tâche de constitution de lexiques bilingues, nous comparons les tables de traductions produites par les deux aligneurs avec un lexique bilingue de référence4 . Dans un premier temps, ce lexique est filtré de façon qu’il ne contienne que des couples de traductions qui peuvent effectivement être extraits par les aligneurs à partir du corpus parallèle d’entrée. En pratique, un couple de traductions du lexique de référence est conservé s’il s’agit d’une sousséquence d’un couple de phrases du corpus parallèle. Nous définissons alors le score d’une table de traductions relativement à ce lexique de référence filtré comme la somme des probabilités de traduction source → cible des alignements de la table de traductions présents dans la référence, divisée par le nombre d’entrées distinctes dans la référence. Le résultat s’interprète comme un score de rappel, entre 0 et 1. En moyenne, Anymalign est meilleur de 7 % relativement à MGIZA++ sur l’ensemble des expériences que nous avons menées. Dans le meilleur des cas, nous avons obtenu un gain relatif de 70 % (Europarl, finnois-français) ; dans le pire une perte de 18 % (Europarl, suédois-finnois). Le genre de textes constituant le corpus ne semble pas avoir d’influence majeure sur ces scores.
En résumé, notre méthode est en retrait sur les tâches de traduction automatique par fragments, mais produit de meilleurs alignements de mots, comme l’attestent les résultats de comparaison avec lexiques de référence, dont les entrées sont majoritairement des mots simples (le nombre moyen de mots par entrée est 1,2). Nous avons montré (Lardilleux et al., 2009) que cela est en fait principalement dû à la faible capacité de cette méthode à produire des alignements de n-grammes de mots avec n 2, comme l’illustre la figure 2. Le but de la section suivante est de mettre en évidence l’origine de ces différences.

2 http://users.info.unicaen.fr/~alardill/anymalign 3 http://geek.kyloo.net/software/doku.php/mgiza:overview 4 Nos   lexiques proviennent principalement du site XDXF : http://xdxf.sourceforge.net G ÉNÉRALISATION DE L’ ALIGNEMENT SOUS - PHRASTIQUE PAR ÉCHANTILLONNAGE 100 % Couverture des n−grammes MGIZA++ 80 %                    Anymalign 
60 % 
40 % 
20 % 
0% 1      2    3      4   5    6      7 
F IG . 2 – Couverture de la partie source d’un échantillon d’Europarl français-anglais par les tables de traductions de MGIZA++ et d’Anymalign. Anymalign aligne plus d’unigrammes, mais peu de n-grammes plus longs.
3     Une analyse du comportement de la méthode Dans cette section, nous présentons des expériences montrant que deux causes principales sont à l’origine des résultats apparemment contradictoires présentés ci-dessus : les différences de fréquences des mots qui composent les séquences à aligner (cause propre à la méthode), et les fréquences de mots utiles à ces tâches (cause propre à la tâche). Les expériences présentées ici sont réalisées sur un extrait d’environ 320 000 phrases d’Europarl, avec les couples de langues portugais-espagnol (cas extrêmes de langues proches dans nos expériences) et finnoisanglais (cas extrême de langues éloignées : le finnois est une langue ouralienne agglutinante, l’anglais une langue germanique d’influence romane isolante, ce qui s’exprime par une grande différence de taille des vocabulaires).
Le tableau 2 présente le nombre de mots de chaque partie de nos corpus.

Langue                          Nombre de mots (tokens)     Taille du vocabulaire portugais                                9 249 177                   87 341 espagnol                                 9 330 199                   85 366 finnois                                  6 472 649                274 958 anglais                                  8 955 995                 53 704 
TAB . 2 – Caractéristiques des corpus utilisés pour nos analyses.
3.1    Différences de fréquences 
Nous avons précédemment montré (Lardilleux et al., 2009) qu’en pratique, la contrainte d’identité des distributions qui est au cœur de la méthode empêche d’extraire des séquences composées de mots de fréquences différentes. Par exemple, un bigramme constitué d’un mot hapax suivi du point de fin de phrase (assimilé à un mot typographique) ne peut être produit, car en supposant que le point apparaisse dans toutes les phrases du corpus d’entrée, la seule configuration dans laquelle ces deux mots partageraient la même distribution serait un souscorpus constitué d’une seule phrase. Dans une telle configuration, presque tous les mots seraient hapax, et la séquence extraite consisterait donc en l’unique phrase de ce sous-corpus. Le bigramme attendu serait donc « masqué » et ne pourrait pas être extrait isolément.
Nous faisons un pas supplémentaire en étudiant la taille des sous-corpus d’où les mots sont extraits en fonction de la fréquence de ces mots. Étant donné un mot source ms à aligner isolément, trois cas peuvent se produire : 1. dans un sous-corpus « trop petit », d’autres mots sources ont la même distribution que ms . Il n’est donc pas possible d’aligner ms isolément.
2. dans un sous-corpus de taille « idéale », aucun autre mot source n’a la même distribution que ms , et au moins un mot cible a cette distribution. ms peut donc être aligné isolément.
A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 
3. dans un sous-corpus « trop grand », aucun autre mot source n’a la même distribution que ms , mais aucun mot cible non plus. ms ne peut donc pas être aligné du tout.
Il existe ainsi une plage de tailles de sous-corpus qui permet d’extraire un mot isolément. Cette plage dépend bien entendu du mot à extraire et plus particulièrement de sa fréquence. Ces plages sont déterminées empiriquement en mesurant, pour chaque mot source d’un corpus parallèle, la taille moyenne des sous-corpus à partir de laquelle il peut être aligné isolément, ainsi que celle à partir de laquelle il ne peut plus être aligné du tout. Pour cela, nous commençons par tirer aléatoirement un sous-corpus d’une seule phrase contenant ce mot, testons si le mot peut y être aligné, puis recommençons ce test en augmentant le sous-corpus d’une nouvelle phrase tirée aléatoirement.
Le processus s’arrête lorsque plus aucun mot cible n’a la même distribution que le mot source testé.
Chaque expérience produit deux nombres : la taille à partir de laquelle le mot peut être aligné isolément (passage du cas 1 au cas 2 ci-dessus), et celle à partir de laquelle le mot ne peut plus être aligné du tout (du cas 2 au cas 3).
Ce test est répété 1 000 fois pour chaque mot source, et nous effectuons la moyenne des mesures recueillies sur l’ensemble des 1 000 tirages. Les résultats sont présentés à la figure 3, par classes de mots de fréquences proches.
pt → es                                                                                   fi → en Taille moyenne des sous−corpus Taille moyenne des sous−corpus 
100 000                                         Non alignable 100 000                            Non alignable Ali gn 10 000                ab                                                                         10 000 le iso lém 1 000                                   en                                                       1 000 
100                                                                                              100 10         Alignable, mais pas isolément 10         Alignable, mais pas isolément 1                                                                                                1 1     10 100 1 000       100 000                                                                 1     10 100 1 000       100 000 Nombre d’occurrences du mot                                                                      Nombre d’occurrences du mot 
F IG . 3 – Tailles moyennes des sous-corpus à partir desquelles un mot source peut être extrait en fonction de la fréquence de ce mot. Dans la zone inférieure, le mot ne peut pas être aligné isolément (cas 1). Dans la zone du milieu, le mot peut être aligné isolément (cas 2). Dans la zone supérieure, le mot ne peut pas être aligné du tout (cas 3). Le petit sursaut de la limite supérieure à l’extrémité droite des deux graphiques est dû au point de fin de phrase, qui s’aligne plus facilement que les autres mots fréquents : il peut être aligné isolément dans des sous-corpus de 5 à 80 phrases environ.
Ces graphiques nous permettent de faire deux remarques. D’abord, la plage des tailles « idéales » des sous-corpus, autrement dit la largeur de la zone du milieu, varie grandement d’un couple de langues à l’autre. Notons que l’échelle logarithmique fait paraître cette plage plus étroite qu’elle ne l’est en réalité : le rapport moyen entre sa limite supérieure et sa limite inférieure est de 2,2 pour le couple espagnol-portugais et 1,2 pour le couple finnoisanglais. Cette différence de rapport s’explique aisément par les différences de morphologie des langues dans chacun de ces couples. Nous pouvons donc nous attendre à ce que l’alignement d’un mot donné par Anymalign nécessite le traitement de davantage de sous-corpus avec le couple finnois-anglais qu’avec le couple portugaisespagnol, puisqu’il est alors plus difficile de tirer aléatoirement un sous-corpus de la « bonne » taille.
La seconde remarque nous intéresse tout particulièrement dans le cadre de cet article : plus un mot est fréquent, plus les sous-corpus à partir desquels il est extrait sont petits, et réciproquement. Les mots rares (partie gauche des graphiques) sont donc alignés à partir de grands sous-corpus, tandis que les mots fréquents (partie droite des graphiques) sont alignés à partir de petits sous-corpus, constitués par exemple de 5 à 9 phrases pour la virgule. Ces résultats valident nos premières hypothèses : s’il est difficile de tirer un sous-corpus dans lequel deux mots source de fréquences différentes partagent la même distribution, c’est avant tout parce que ces mots ne peuvent pas être alignés à partir du même sous-corpus. Pour aligner des mots de fréquences différentes, il est nécessaire de les extraire à partir de sous-corpus de tailles différentes. Nous proposerons une alternative dans la section suivante.
G ÉNÉRALISATION DE L’ ALIGNEMENT SOUS - PHRASTIQUE PAR ÉCHANTILLONNAGE 
3.2         Fréquences utiles 
La seconde explication des différences de résultats d’Anymalign sur les deux tâches sur lesquelles il a été évalué provient en fait de la tâche elle-même, ou pour être plus précis du couple (aligneur, tâche).
Notre méthode et les modèles IBM reposent sur des intuitions opposées : la première tire parti de la rareté des mots pour les aligner (on réduit artificiellement et temporairement la fréquence de tous les mots en se plaçant dans un sous-corpus), tandis que les seconds sont estimés à partir des observations mesurées sur l’ensemble du corpus.
En conséquence, Anymalign aligne mieux les mots rares, tandis que MGIZA++ aligne mieux les mots fréquents, comme l’illustre la figure 4.

pt-es                                                  fi-en 100 %                                                  100 % Anymalign (60 %)                                       Anymalign (36 %) 80 %          MGIZA++ (53 %)                          80 %           MGIZA++ (26 %) 
60 %                                                  60 % Score Score 40 %                                                  40 % 20 %                                                  20 % 0%                                                    0% 1     10 100 1 000       100 000                       1     10 100 1 000       100 000 Nombre d’occurrences des mots                          Nombre d’occurrences des mots 
F IG . 4 – Scores obtenus par les tables de traductions produites par Anymalign et MGIZA++ sur la tâche de constitution de lexiques bilingues. Les scores entre parenthèses sont les scores globaux, calculés comme décrits au 3e paragraphe de la section 2.3. Les courbes présentent le détail de ces scores, en fonction du nombre d’occurrences du mot source de chacun des alignements : un score a été calculé localement pour chaque effectif de mot. Les courbes ont été lissées pour améliorer leur lisibilité.

Ce qui nous intéresse ici n’est pas tant l’allure générale des courbes que leur position relative : la courbe correspondant à Anymalign est au-dessus de celle de MGIZA++ pour les mots d’effectif 1 à 5 000 environ, et en-dessous pour les effectifs supérieurs. Cela montre qu’Anymalign aligne mieux non seulement les mots rares, mais également les mots de fréquence intermédiaire. Cette observation a été corroborée sur d’autres couples de langues (de-en, es-en, fr-en).
Or, les mots rares étant beaucoup plus nombreux dans tout texte — cf. loi d’Estoup-Zipf (Zipf, 1965; Mandelbrot, 1954; Montemurro, 2004) —, a fortiori dans notre corpus parallèle ainsi que dans les tables de traductions produites, et notre protocole d’évaluation par comparaison avec lexiques de référence traitant les mots indépendemment de leur fréquence, il est attendu que notre méthode obtienne de meilleurs scores en constitution de lexiques bilingues, puisque les mots qu’elle aligne le mieux sont au total les plus nombreux. À l’opposé, les mots fréquents sont beaucoup moins nombreux, mais autrement plus importants en traduction automatique car ils y sont beaucoup plus sollicités : un mot fréquent a plus de chances d’apparaître dans un jeu de test qu’un mot rare. Cela peut expliquer, au moins pour partie, les scores plus faibles d’Anymalign en traduction automatique. Idéalement, nous aimerions pouvoir utiliser les alignements de tel ou tel aligneur en fonction de la fréquence des mots, par exemple en combinant les tables de traductions produites par les aligneurs. Des expériences préliminaires utilisant les probabilités de traduction d’Anymalign comme fonction de trait supplémentaire dans la table de traduction par défaut de Moses ont donné des résultats prometteurs. Cela sort cependant du cadre de cet article, et nous nous consacrons par la suite à l’alignement de mots de fréquences différentes. Nous garderons néanmoins à l’esprit que, pour bien faire en traduction automatique, notre méthode devra également aligner plus efficacement les mots fréquents, ce que nous gardons pour des recherches futures.
4       Généralisation de la méthode à toutes les chaînes de mots Dans cette section, nous présentons une généralisation de la méthode destinée à améliorer ses performances en traduction automatique statistique par fragments. En conformité avec la méthode d’origine, nous travaillerons A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 
toujours sur les formes surfaciques des mots et sans ressource autre que le corpus d’entrée (traitement endogène).
Notre but est d’extraire davantage d’alignements de n-grammes (chaînes de mots) avec n 2 (cf. figure 2), tout en contournant le problème de l’extraction des mots de fréquences différentes (section 3.1).
4.1   Phase d’indexation 
Nous introduisons le traitement à un grain variable en indexant des n-grammes plutôt que des mots. Nous ne chercherons pas à effectuer une segmentation particulière des phrases, par exemple en chunks, dont Vergne (2009) a montré qu’ils pouvaient être déterminés de façon endogène, mais traiterons plus simplement tous les n-grammes de mots se chevauchant. Considérons le (sous-)corpus d’entrée alingue5 suivant, constitué de trois phrases : 1    abc 2    abde 3    ac 
L’indexation sur l’ensemble des n-grammes de ce corpus, avant recensement des groupes de même distribution servant de base à l’extraction des alignements, produit le résultat suivant : n=1                        n=2                       n=3             n=4 a     b    c    d   e    ab     ac    bc bd       de     abc   abd     bde     abde 1    1     1    1    0   0     1     0     1   0       0       1     0       0       0 2    1     1    0    1   1     1     0     0   1       1       0     1       1       1 3    1     0    1    0   0     0     1     0   0       0       0     0       0       0 
Dans l’étape suivante, le recensement des groupes de même distribution, nous introduisons un changement majeur : si des n-grammes de même distribution se chevauchent, le groupe de mots résultant est constitué de l’union de ces n-grammes. Par exemple, les bigrammes de même distribution bd et de formeront le groupe de mots bde.
Autrement dit, les groupes ne sont plus constitués de mots de même distribution, mais de mots issus de n-grammes de même distribution. Un même mot peut désormais apparaître dans plusieurs groupes, ce qui n’était pas le cas dans la méthode d’origine.
Ce changement soulève un problème qui ne pouvait pas se produire avec la méthode d’origine : des n-grammes peuvent masquer des (n−1)-grammes, et ce récursivement. L’unigramme b est par exemple masqué par le bigramme de même distribution ab, car l’union de b et ab donne ab, et b ne peut plus être aligné isolément. Il est donc nécessaire de traiter l’introduction de chaque longueur de n-gramme de façon spécifique.
4.2   Stratégie de constitution des groupes de mots 
Nous avons testé trois stratégies : 1. traiter séparément les n-grammes en fonction de leur longueur. Ainsi, les groupes de mots ne sont construits qu’à partir de n-grammes de même longueur en source et en cible. Cela est bien entendu d’efficacité limitée sur des couples de langues tels que finnois-anglais : il serait préférable d’autoriser l’extraction d’un seul mot d’une langue agglutinante avec plusieurs mots d’une langue isolante.
2. permettre le mélange de toutes les longueurs de n-grammes, mais en ajoutant progressivement chaque longueur. L’ensemble initial ne contient que des unigrammes (méthode d’origine). Dans un deuxième temps, nous ajoutons les bigrammes et recréons tous les groupes de mots : certains sont identiques (les décomptes des alignements correspondants sont renforcés), d’autres sont nouveaux, d’autres enfin sont masqués mais cela n’a pas d’importance car ils ont déjà été extraits à partir des unigrammes. On ajoute ensuite les trigrammes, etc. Les alignements sont extraits à chaque fois que des n-grammes sont ajoutés.
3. forcer l’alignement de n-grammes de longueurs différentes, à contrepied de la première stratégie, en traitant séquentiellement tous les couples de longueurs (source, cible) possibles (produit cartésien). Cela permet l’alignement de n-grammes de longueurs très différentes en source et en cible, voire trop : puisque nous n’avons recours à aucune connaissance extérieure, Anymalign ne sait pas a priori quelle langue est traitée, et rien ne l’empêche par exemple de vouloir aligner des unigrammes en anglais avec de longs n-grammes en finnois, quand bien même il est peu probable que le moindre alignement puisse être produit à partir d’une telle configuration. En outre, la complexité de cette approche est bien plus importante que celle des deux précédentes, et ne passe pas à l’échelle lorsque nous traitons plus de deux langues simultanément.
5 Comme   décrit à la section 2, notre principal algorithme ne fait pas de différence entre corpus multilingues et corpus monolingues.
G ÉNÉRALISATION DE L’ ALIGNEMENT SOUS - PHRASTIQUE PAR ÉCHANTILLONNAGE 
Pour comparer ces trois stratégies, nous préparons un ensemble de 100 000 sous-corpus aléatoires issus d’Europarl (français-anglais) et en extrayons les alignements selon chacune de ces stratégies. Nous réalisons l’expérience pour des longueurs maximales de n-grammes allant de 1 à 5. Les tables de traductions (3 × 5 = 15 tables au total), obtenues à partir de ce même ensemble de sous-corpus, sont évaluées sur les mêmes tâches que précédemment : en traduction automatique statistique par fragments (les critères d’évaluation sont BLEU et TER (Snover et al., 2006)) et en constitution de lexiques bilingues. Les résultats sont présentés dans le tableau 3.

Stratégie    n max.   Score en lexique (%)   BLEU (%)     TER (%)     Nombre d’entrées    Long. moy. des entrées 1             36,19             21,12        63,57          83 967                  1,92 2             36,71             22,62        61,93         277 858                  2,79 1.         3             36,66             23,08        62,06         366 971                  3,13 4             36,60             23,23        61,43         393 453                  3,24 5             36,58             22,92        62,14         399 810                  3,27 1             36,19             21,12        63,57          83 967                  1,92 2             37,08             23,63        60,68         290 631                  2,78 2.         3             37,35             24,72        59,86         398 880                  3,12 4             37,45             24,47        60,69         436 760                  3,25 5             37,56             24,25        59,94         448 212                  3,31 1             36,19             21,12        63,57          83 967                  1,92 2             31,71             23,85        60,41         312 273                  2,86 3.         3             30,90             24,50        60,68         453 429                  3,24 4             30,48             24,47        59,96         507 359                  3,39 5             30,25             24,26        60,03         524 091                  3,45 
TAB . 3 – Qualité et caractéristiques des tables de traductions produites selon chacune des trois stratégies de constitution de groupes de mots, pour différente longueurs maximales de n-grammes indexés. Les lignes où n max. = 1 sont identiques pour les trois stratégies et correspondent à la méthode d’origine.

Comme il était attendu, plus la longueur maximale des n-grammes indexés est grande, plus le nombre d’entrées dans la table de traductions et la longueur de ces entrées sont également élevés, car les alignements produits avec un n max. donné contiennent ceux produits avec un n max. inférieur (inclusion des tables). Les scores en constitution de lexiques augmentent de façon négligeable lorsque n max. augmente avec les deux premières approches, mais se dégradent de façon significative avec la troisième. Le gain en traduction automatique est significatif avec les trois approches. La seconde semble néanmoins fournir des résultats très légèrement meilleurs selon les trois critères d’évaluation. Son temps d’exécution est légèrement supérieur à celui de la première (au pire deux fois plus lent avec les 5-grammes), mais bien en-deçà de celui de la troisième (de l’ordre de l’heure à celui de la journée avec les 5-grammes).
La stratégie que nous utiliserons par la suite sera donc la deuxième. Elle constitue sur le fond un bon compromis entre les deux autres. La figure 5 présente le détail de la colonne « Nombre d’entrées » du tableau 3 pour cette deuxième stratégie, et est à confronter avec la figure 2.
Dans l’ensemble, l’ajout d’une longueur de n-grammes indexés, autrement dit le passage d’une courbe à celle immédiatement au-dessus, augmente considérablement la quantité de l’ensemble des n-grammes produits (y compris, de façon marginale, les n-grammes de taille inférieure, mais cela n’est dû qu’à l’extraction des complémentaires des groupes de mots). Le cas le plus significatif est celui de l’indexation des bigrammes (n max. = 2), qui fait exploser la quantité de bigrammes en sortie, et dans une moindre mesure de toutes les tailles de n-grammes supérieures. Le phénomène se produit également en indexant des n-grammes encore plus longs, mais cela est de moins en moins significatif à mesure que n max. augmente. Le graphique semble montrer qu’il n’est pas utile d’indexer des n-grammes de plus de 3 ou 4 mots, car cela se révèle peu productif. Les n-grammes qui nous intéressent le plus sont de toute façon ceux de longueur 1 à 3, parce que ce sont généralement les plus utiles en traduction automatique par fragments.
4.3    Expériences et nouveaux résultats 
Nous comparons à présent notre méthode généralisée (indexation des n-grammes + constitution des groupes de mots selon la deuxième stratégie testée) à MGIZA++ sur des tâches de traduction automatique statistique par A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 140 000 n max. = 5 Nombre d’entrées source 120 000                                                            n max. = 4 n max. = 3 100 000                                                            n max. = 2 80 000                                                            n max. = 1 
60 000 40 000 20 000 
1   2     3     4     5     6    7 Longueur des entrées source (en mots) 
F IG . 5 – Distribution des n-grammes dans les cinq tables de traductions obtenues par la deuxième stratégie de constitution de groupes de mots. Chaque courbe correspond à une ligne du tableau 3, et la somme des ordonnées de ses points reportés est égale à la valeur indiquée dans la colonne « Nombre d’entrées » du tableau. La courbe la plus basse (n max. = 1) correspond à la méthode d’origine (cf. figure 2).

Tâche                    Entraînement      Développement        Test      Références par phrase de test BTEC : ar-en                                                 19 972          1 512             489                      7 BTEC : zh-en                                                 19 972          1 512             989                      7 Europarl : fi-en, fr-en, pt-es                              318 804            500           1 000                      1 
TAB . 4 – Caractéristiques des corpus utilisés pour notre évaluation.

Aligneur      n max.   BLEU (%)    TER (%)         Nombre d’entrées MGIZA++                  33,68      46,17              217 512 Anymalign       1        26,33      51,17              170 521 ar-en          -            2        30,88      49,70              269 454 -            3        31,81      51,48              273 197 -            4        33,75      48,80              258 141 MGIZA++                  15,46      70,49              141 773 Anymalign       1        14,77      68,97              158 904 zh-en          -            2        16,35      71,70              263 315 -            3        16,54      70,62              250 292 -            4        16,84      69,45              269 353 
TAB . 5 – Résultats des tâches de traduction sur le BTEC.

Même temps de traitement que MGIZA++           Temps théorique = 20 × MGIZA++ Aligneur                        n max.          BLEU (%)    TER (%)     Nombre d’entrées       BLEU (%)    TER (%)     Nombre d’entrées MGIZA++                                            21,68        65,50        5 241 325 Anymalign                            1             13,73        77,57        1 871 639               13,54        74,34      5 178 683 fi-en       -                                 2             14,39        76,59          890 644               16,21        71,18      5 948 094 -                                 3             14,64        77,15          696 420               17,44        72,63      4 001 816 -                                 4             12,79        78,46          279 437               16,80        71,34      2 266 448 MGIZA++                                            29,39        54,37       10 783 083 Anymalign                            1             22,74        61,85        1 755 334               23,58        61,09      7 882 822 fr-en       -                                 2             24,68        60,22        1 805 297               24,55        58,42      8 317 221 -                                 3             24,40        59,77        1 074 258               25,29        57,66      6 943 421 -                                 4             23,01        61,86          492 530               24,78        58,11      5 121 617 MGIZA++                                            38,22        47,47       17 828 592 Anymalign                            1             34,63        50,25        1 532 520               34,84        50,35      6 730 554 pt-es       -                                 2             36,03        49,63          987 884               36,72        49,10      7 295 581 -                                 3             35,72        49,95          744 947               35,98        49,02      6 126 896 -                                 4             35,18        50,34          342 168               37,01        48,71      3 926 578 
TAB . 6 – Résultats des tâches de traduction sur Europarl.
G ÉNÉRALISATION DE L’ ALIGNEMENT SOUS - PHRASTIQUE PAR ÉCHANTILLONNAGE 
fragments. Le tableau 4 présente les caractéristiques des données utilisées pour chacune de ces expériences, et les tableaux 5 et 6 présentent les résultats.
Les lignes où n max. = 1 correspondent à la version d’origine d’Anymalign. Comme décrit précédemment (section 2.3), Anymalign étant anytime, la condition d’arrêt que nous lui imposons dépend du temps d’exécution de MGIZA++. Ce temps est constant quelle que soit la valeur de n max. Le temps de traitement augmentant avec ce paramètre, plus ce paramètre est élevé et plus le nombre de sous-corpus traités est faible, contrairement aux expériences présentées dans la section 4.2 où l’ensemble des sous-corpus à traiter était fixé à l’avance, impliquant un temps de traitement dépendant de n max. Théoriquement, les tables produites pour un n max. donné sont plus grandes que pour un n max. inférieur, à condition que l’aligneur soit exécuté suffisamment longtemps. Cela explique pourquoi les tables de traductions des tableaux 5 et 6 peuvent contenir moins d’entrées pour de plus grandes valeurs de n max. En pratique, ces tables contiennent tout de même davantage de longs n-grammes, ce qui permet une amélioration très significative des scores, malgré une table de traductions plus petite.
Sur les tâches impliquant le BTEC, les lignes où n max. = 1 montrent que la version d’origine d’Anymalign obtient des scores BLEU comparables à MGIZA++ en chinois-anglais, et est loin derrière en arabe-anglais. La généralisation aux n-grammes lui permet de devancer MGIZA++ de plus d’un point BLEU en chinois-anglais, et de l’égaliser en arabe-anglais, soit un gain spectaculaire de 7 points BLEU.
Sur les tâches impliquant Europarl, les scores de la version d’origine d’Anymalign sont en retrait de façon significative par rapport à MGIZA++, ce qui est conforme aux expériences que nous avions menées précédemment. Cela dit, la différence n’était pas aussi prononcée dans nos anciennes expériences : nous observions une différence de 2 à 3 points BLEU en moyenne, alors qu’elle est ici de 6 points. Nous pensons que ce changement est dû à la taille de notre corpus qui est désormais beaucoup plus élevé : 320 000 couples de phrases contre 100 000 précédemment.
La taille des tables de traductions d’Anymalign, très petites par rapport à celles de MGIZA++, semble indiquer que le temps d’exécution de notre méthode n’est pas suffisant. Pour cette raison, le tableau 6 contient dans sa partie droite une deuxième série de résultats, qui correspondent à l’exécution d’Anymalign pendant une durée totale égale à 20 fois le temps d’exécution de MGIZA++. En pratique, Anymalign étant massivement parallélisable, nous avons découpé les traitements en 140 processus et les avons exécutés sur un cluster, pour finalement profiter d’un temps de traitement 7 fois plus rapide qu’avec les résultats présentés dans la partie gauche du tableau. Les tailles des tables de traductions dans la partie droite du tableau sont plus proches de celles de MGIZA++, ce qui confirme que le temps d’exécution n’était pas suffisant6 , mais le gain en BLEU de la version d’origine d’Anymalign n’est pas significatif pour autant. Il l’est par contre lorsque nous augmentons n max. : nous gagnons jusqu’à 3 points BLEU en finnois-anglais (n max. = 3) simplement en exécutant Anymalign plus longtemps. Dans tous les cas de la partie droite du tableau, l’indexation des n-grammes permet un gain en BLEU allant d’1,7 point en françaisanglais à près de 4 points en finnois-anglais. En moyenne, les meilleurs scores d’Anymalign sont désormais en retrait de 3,5 points BLEU par rapport à MGIZA++, divisant pratiquement par deux son retard initial.
5     Conclusion 
Cet article a présenté une généralisation de notre méthode d’alignement sous-phrastique afin d’améliorer ses résultats en traduction automatique. La méthode d’origine obtient de meilleurs résultats que l’état de l’art sur des tâches de constitution de lexiques bilingues, mais des résultats inférieurs en traduction automatique statistique par fragments. Nous avons montré que ces différences ont principalement deux causes : les différences de fréquences des mots qui composent les séquences à aligner (cause propre à la méthode), et les fréquences de mots utiles à ces tâches (cause propre à la tâche). Pour pallier le premier problème, nous avons proposé une généralisation de la phase d’indexation de notre méthode, en ne considérant non plus le mot comme unité, mais le n-gramme. Le résultat de cette généralisation est un fort accroissement du nombre de n-grammes en sortie, qui mène à des gains très significatifs en traduction automatique par fragments (jusqu’à +7 points BLEU sur le couple arabe-anglais).
Notre méthode fait désormais jeu égal avec l’état de l’art sur des tâches « simples » de traduction automatique (BTEC), et nous avons pratiquement divisé son retard par deux sur des tâches plus difficiles (Europarl). Pour aller plus loin, nous envisageons d’étudier le cas de l’alignement des mots fréquents, dont nous avons montré qu’ils étaient moins bien alignés que les mots rares par notre méthode, ainsi que la question de sa condition d’arrêt.

6 Cela soulève une autre question, qui est celle de la condition d’arrêt d’Anymalign. Les présentes expériences montrent que nos critères 
actuels sont insuffisants, ne serait-ce que pour effectuer une juste comparaison avec d’autres outils.
A DRIEN L ARDILLEUX , F RANÇOIS Y VON , Y VES L EPAGE 
Remerciements Les travaux présentés dans cet article ont été partiellement financés par le projet Cap Digital SAMAR.


Estimation d’un modèle de traduction à partir d’alignements mot-à-mot non-déterministes 
Nadi Tomeh Alexandre Allauzen François Yvon Université Paris Sud et LIMSI/CNRS BP 133 91 403 Orsay {nadi,allauzen,yvon}@limsi.fr 
Résumé.           Dans les systèmes de traduction statistique à base de segments, le modèle de traduction est estimé à partir d’alignements mot-à-mot grâce à des heuristiques d’extraction et de valuation. Bien que ces alignements mot-à-mot soient construits par des modèles probabilistes, les processus d’extraction et de valuation utilisent ces modèles en faisant l’hypothèse que ces alignements sont déterministes. Dans cet article, nous proposons de lever cette hypothèse en considérant l’ensemble de la matrice d’alignement, d’une paire de phrases, chaque association étant valuée par sa probabilité. En comparaison avec les travaux antérieurs, nous montrons qu’en utilisant un modèle exponentiel pour estimer de manière discriminante ces probabilités, il est possible d’obtenir des améliorations significatives des performances de traduction. Ces améliorations sont mesurées à l’aide de la métrique BLEU sur la tâche de traduction de l’arabe vers l’anglais de l’évaluation NIST MT’09, en considérant deux types de conditions selon la taille du corpus de données parallèles utilisées.
Abstract.         In extant phrase-based statistical translation systems, the translation model relies on word-to-word alignments, which serve as constraints for further heuristic extraction and scoring processes. These word alignments are infered in a probabilistic framework ; yet, only one single best word alignment is used as if alignments were deterministically produced. In this paper, we propose to take the full probabilistic alignment matrix into account, where each alignment link is scored by its probability score. By comparison with previous attempts, we show that using an exponential model to compute these probabilities is an effective way to achieve significant improvements in translation accuracy on the NIST MT’09 Arabic to English translation task, where the accuracy is measured in terms of BLEU scores.
Mots-clés :         traduction statistique, modèles de traduction à base de segments, modèles d’alignement mot-à-mot.

Keywords:           statistical machine translation, phrase based translation models, word alignment models.
1    Introduction Dans les systèmes de traduction statistique à base de segments (phrase-based systems), le modèle de traduction sert de pont entre les langues source et cible. Sur la base d’hypothèses de segmentation de la phrase source à traduire, il permet de proposer, pour chacun des segments, des traductions candidates en langue cible. Ces hypothèses de traduction sont sélectionnées dans un inventaire qui enregistre des appariements valués entre segments de longueur variable. Ces associations et les scores qui les accompagnent constituent la table de traductions (phrase-table).
Ce modèle est estimé en deux temps à partir d’un corpus parallèle : (i) extraction d’un ensemble de couples de segments candidats, (ii) valuation des couples retenus dans la phase (i). Faute de disposer de méthodes d’estimation théoriquement bien fondées, chacune de ces deux étapes repose sur un ensemble d’heuristiques. Il s’avère en effet impossible d’estimer directement les valuations calculées en (ii), ni même de recencer tous les appariements possibles en (i). En effet, estimer de façon non-supervisée un modèle probabiliste des alignements de segments demanderait de pouvoir calculer des sommes sur tous les alignements de segments possibles, à défaut, de savoir calculer un alignement optimal utilisant des segments de taille variable. Ces deux procédures posent des problèmes combinatoires NP-difficiles (DeNero & Klein, 2008) et ne peuvent être effectuées de manière exacte. De manière plus subtile, construire des modèles d’alignements de segments demande de mettre en compétition des segmentations conjointes de taille variable des phrases source et cible, au risque de toujours préférer les alignements impliquant des segments longs. Enfin, ne considérer qu’une seule segmentation lors de l’apprentissage semble avoir un effet négatif sur la capacité de généralisation du modèle (DeNero et al., 2006).
La solution pratique qui s’est progressivement imposée contourne le problème en considérant en premier lieu une segmentation NADI T OMEH , A LEXANDRE A LLAUZEN ET F RANÇOIS Y VON 
maximale et en effectuant un alignement préalable au niveau des mots ; des procédures efficaces fondées sur l’algorithme EM (Expectation-Maximisation) pour effectuer cet alignement de manière efficace existent depuis le début des années 90 (Brown et al., 1993; Och & Ney, 2003). Ces alignements de mots sont ensuite ré-analysés pour en déduire des alignements de segments, la méthode la plus répandue consistant à extraire les alignements de segments compatibles avec les contraintes posées par les alignements de mots.
Dans un troisième temps, les statistiques d’occurrence de ces alignements de segments sont collectées et utilisées pour attribuer des scores de confiance à ces groupes bilingues. Ces trois étapes successives de la construction du modèle de traduction sont usuellement abordées et optimisées séparément les unes des autres. Le risque est naturellement que les erreurs s’accumulent le long de cette séquence de traitements. Ainsi, des erreurs précoces dans les calculs des alignements mot-à-mot viennent bruiter le processus d’extraction des couples de segments appariés et biaiser les calculs de scores afférents.
Pour pallier ce problème, les auteurs de (Liu et al., 2009) proposent d’extraire davantage d’informations de la phase d’alignement des mots, sous la forme d’une matrice d’alignements pondérés, qui représente de manière compacte un ensemble d’alignements de mots potentiels. Cette matrice est utilisée dans les étapes ultérieures de l’apprentissage. Dans une matrice pondérée, chaque lien d’alignement potentiel est nanti d’une probabilité qui mesure la confiance dans l’alignement de ces deux mots. Dans (Liu et al., 2009), ces probabilités sont estimées à partir du calcul des n-meilleurs alignements de mots tels que produits par les modèles d’alignement standards. À l’aide de cette technique, ces auteurs parviennent à améliorer de façon modeste leurs systèmes de traduction automatique. Une des limites de cette approche est toutefois l’utilisation d’une liste de n-meilleurs, qui ne représente que très imparfaitement la diversité et la variabilité des alignements de mots potentiels, et conduit à des mauvais estimateurs des probabilités a posteriori des liens d’alignement.
Dans ce travail, nous soutenons qu’une meilleure estimation des probabilités des liens d’alignement est susceptible de donner lieu à de meilleurs modèles. Nous étudions donc une méthode alternative pour réaliser cette estimation, fondée sur des modèles discriminants pour l’alignement de mots (Ayan & Dorr, 2006; Tomeh et al., 2010, 2011) et analysons les performances qu’elles permettent d’obtenir. La principale contribution de ce travail est donc de nature empirique : en comparant différentes manières de calculer et d’exploiter ces matrices d’alignement pondérées, nous montrons qu’il peut être bénéfique, en particulier quand les données d’apprentissage du modèle de traduction sont réduites, de prendre en compte l’information contenue dans ces matrices, au-delà du meilleur alignement mot-à-mot.
Cet article est organisé comme suit. Après avoir brièvement posé le cadre de la construction du modèle de traduction dans l’approche standard, nous présentons à la section 2 les principes de construction et d’exploitation de matrices d’alignements pondérées. Nous introduisons, à la section 3 une approche alternative permettant d’estimer directement la matrice d’alignement pondérée. Les résultats expérimentaux sont ensuite décrits à la section 4. Enfin, nous explicitons le positionnement de notre approche par rapport aux travaux existants, avant de conclure et d’évoquer diverses pistes vers lesquelles nous comptons nous orienter dans le futur.
2     Matrices pondérées pour la construction de modèles de traduction 
Pour un système de traduction à base de segments (Zens et al., 2002), le modèle de traduction est la source de connaissance principale qui établit une correspondance entre les deux langues (source et cible). Son rôle est de guider la construction, pour chaque phrase source, d’un ensemble d’hypothèses de traduction en langue cible. L’unité de traduction est le segment, qui correspond à un groupe de mots contigus. L’association entre un segment source et une traduction possible en cible forme un bi-segment. Notons qu’il est possible qu’un segment admette plusieurs traductions alternatives, donnant lieu à plusieurs bi-segments partageant le même segment source. Afin de faire un bon usage de ces bi-segments, il est nécessaire de leur associer des mesures, par exemple statistiques, qui quantifient la confiance en l’association ainsi réalisée.
Dans la suite de cet article, nous utilisons les notations suivantes : un couple de phrases est désigné par (e, f ), où la phrase source f = f1 , ..., fi , ..., fI est une séquence de I mots et la phrase cible e = e1 , ..., ej , ..., eJ est une séquence de J mots. De plus, une sous-séquence de mots extraite d’une phrase sera notée fii12 = fi1 . . . fi2 et donc f = f1I .
2.1    Cadre général 
Les méthodes décrites dans la littérature pour construire le modèle de traduction peuvent se résumer par l’algorithme présenté dans la partie gauche de la figure 1. Le point de départ est un couple de phrases accompagné d’un alignement mot-à-mot représenté par une matrice d’alignement. Chaque cellule de cette matrice booléenne A = {ai,j : 1 ≤ i ≤ I, 1 ≤ j ≤ J} représente un lien 4   2e soumission à TAL E STIMATION D ’ UN MODÈLE DE TRADUCTION que les méthodes d’évaluation (sous-section 2.4) et la manière dont nous évaluerons les différents modèles.

1: POUR toutes les paires de phrases        (f1J , eI1 ) FAIRE j2 2:   POUR tous les segments fj1 FAIRE                                                      2.1. Définition Corpus parallèle : j2 i2                                  Un alignement mot-à-mot             entre pas  phrase une la glaceetau sa chocolat traduction. associe à chaque mot 3:       Construire l’ensemble des bi-segments EA = {fj1  , ei1 }                          de cette phrase un mot e : je n' aime de f : I do not likeUn la traduction.     alignement chocolate     iceregroupe cream . donc un ensemble de satisfaisant le jeu de contraintes CA                                             liens décrivant une relation de traduction entre mots. Il est possible qu’un mot n’ait pas de traduction directe, il est alors aligné sur un symbole spécial noté null.
4:       Trier EA selon la fonction fR                                                                                                                  Modèle d'alignements mot-à-mot Dans la suite de cet article, nous utilisons les notations suivantes : un couple de 5:       Appliquer le critère de sélection CS définissant l’en-                            phrases est désigné par e, f , où la phrase e = e1 , ..., ei , ..., eI est une séquence de I mots f : je et    = f1pas n' faime   , ...,la  , ..., fJau fj glace                   . e :de une séquence estchocolat             J mots.
I do  not like   alignementice Unchocolate       mot-à-mot cream .
semble EAS des bi-segments à extraire                                             d’un couple de phrases est représenté par une matrice d’alignement. L’élément (i, j) de la matrice est 1 si le ième mot de e est aligné avec le j ème mot de f et 0 sinon. La 6:       Assigner une fonction de compte fC à chaque bi-                                   e : I do1 not Figure         likeunchocolate donne       exemple de    icematrice   .
creamd’alignement       et des pas lienslaqui f : je n' aime            glace       associés. .
au chocolat lui sont j2 i2 segments (fj1   , ei1 ) de EAS Heuristique de symétrisation 7:     end POUR 8:   end POUR chocolat glace aime 9:   POUR chaque bi-segments extraite {(e, f )} FAIRE pas au Je n’ la 10:     Calcul des scores :                                                                                         cream ice fC (e, f )                                                                 chocolate φ(e|f ) =                      ,                                                           like not fi fC (e, fi )                                                             do length(e) 1                                           Figure 1. Exemple de matrice d’alignementExtraction lex(e|f, A) =                                                  w(ei |fj ),                                                                     entre une phrase          anglaise et et évaluation 
i=1 |{j : (i, j) ∈ A}|                                    une phrase française. Les termes non nuls des                de lasegments matrices sont tés par des carrés pleins. L’ensemble des liens associés à cette matrice est représenbilingues ∀(i,j)∈a {(1, 1), (2, 2), (2, 3), (3, 4), (4, 2), (4, 3), (6, 6), (6, 7), (7, 5), (8, 5), (9, 8)} où A désigne la matrice d’alignement, et w une probabi-                        glace au chocolat ||| chocolate ice cream |||0.82 0.21 0.81 0.49 2.72 Nous pouvons d’ores et déjà remarquer qu’une matrice d’alignement comporte lité de traduction lexicale (IBM1 ou fréquence relative).                           majoritairement des termes nuls : en première approximation, chaque mot de la phrase e est aligné avec un mot de la phrase f ; la matrice d’alignement comporte donc envi11: end POUR                                                                              ron min(I, J) éléments non nuls où I et J sont les tailles des deux phrases à aligner.
F IGURE 1 – Algorithme générique pour la construction du modèle de traduction et un exemple de son application fréquement utilisé d’alignement potentiel ; la variable binaire ai,j vaut 1 si le lien entre le ième mot de f et le j ème mot de e est actif, et 0 sinon.
Un jeu de contraintes CA permet de définir, parmi tous les bi-segments potentiellement contenus dans une paire de phrases, ceux qui sont « acceptables » ou cohérents avec la matrice d’alignement. Les contraintes apportées par les alignements de mots permettent l’énumération conjointe de toutes les segmentations de la paire de phrases avec tous les alignements de segments autorisés. Une fois cet ensemble de bi-segments identifié, il est possible de le trier (fR ) et de lui appliquer un critère de séléction CS afin d’éliminer les bi-segments qui semblent a priori les moins plausibles. La dernière étape concerne la valuation des bi-segments ainsi extraits. Les fonctions de valuation les plus communément utilisées sont : – la fréquence d’observation du segment e connaissant le segment f notée φ(e|f ) ainsi que le terme symétrique φ(f |e) ; – les poids lexicaux ou lexical weights dans les deux directions (lex(e|f, A) et lex(f |e, A)), qui utilisent, le plus souvent, les probabilités de traduction lexicale du modèle IBM1.
Ces fonctions sont définies dans l’algorithme détaillé sur la figure 1 (ligne 10).
L’instanciation standard de cet algorithme correspond aux travaux de (Zens et al., 2002; Koehn et al., 2003) (voir partie droite de la figure 1), qui se déduit du cadre général en utilisant les définitions suivantes : – CA représente des contraintes de cohérence qui s’appliquent à un alignement mots-à-mots symétrisé d’une paire de phrases. Ces alignements se déduisent des deux meilleures hypothèses données par le modèle IBM4 (une pour chaque direction de traduction), symétrisées par l’heuristique grow-diag-final-and (Koehn et al., 2003).
– La fonction de compte et celle de tri sont les mêmes : fR = fC = 1 – la contrainte CS est définie par un seuil portant sur la longueur relative des segments source et cible et permet de filtrer les bi-segments trop longs.
Les hypothèses simplificatrices utilisées dans l’approche standard permettent d’obtenir une procédure efficace et robuste ; elles soulèvent néanmoins quelques critiques. Tout d’abord, le choix du modèle IBM4 pose problème puisque sa complexité interdit d’utiliser des procédures exactes lors de l’inférence et du calcul des probabilités a posteriori de chacun des liens d’alignement.
Ainsi, les contraintes de cohérence des bi-segments portent sur des alignements qui ne sont pas forcément les meilleurs et pour lesquels les approximations des probabilités a posteriori ne reflètent qu’imparfaitement la confiance du modèle. Ce dernier point implique naturellement le choix des fonctions de compte et de tri fC = fR = 1, puisqu’en l’absence de mesure de confiance, une décision binaire s’impose. Enfin, ces simplifications entraînent que l’exploration de la matrice d’alignement est restreinte à la sous-partie sélectionnée par les alignements IBM4 et ne prend pas en considération la plus grande partie de la matrice d’alignement.
NADI T OMEH , A LEXANDRE A LLAUZEN ET F RANÇOIS Y VON 
j1            j2 0,9 0,5 0,8 0,8 0,6 0,7 0,2 0,4 0,8 0,7 0,1                       0,3 0,1 0,4 0,8 0,2 0,3 0,1 0,1 0,6 0,3 0,8 0,2                                i1 0,1            0,4 0,8 0,7 0,2 0,1 0,9 0,1 0,3                 i2 
0,4 0,5 0,6 0,5 ,                                                             0,9 0,4 0,8 0,8 
,                                                                     0,8 1,0 
F IGURE 2 – Illustration du calcul des comptes fractionnaire pour un bi-segment donné. Dans cet exemple, le calcul des comptes fractionnaires se fait de la manière suivante : fC (fjj12 , eii21 ) = α(j1 , j2 , i1 , i2 ) × β(j1 , j2 , i1 , i2 ).
2.2    La matrice d’alignement pondérée 
Dans (Liu et al., 2009), les auteurs proposent d’augmenter le nombre des alignements mot-à-mot qui sont impliqués dans l’estimation des modèles de traduction et introduisent, à cet effet, la notion de matrice d’alignement pondérée : Ap = {p(ai,j |e, f ) : 1 ≤ i ≤ I, 1 ≤ j ≤ J}. Dans cette matrice, chaque lien d’alignement est pondéré par sa probabilité a posteriori p(ai,j |e, f ). Ces probabilités sont calculées à partir des n-meilleurs alignements symétrisés proposés par le modèle IBM4. Partant de cette matrice, l’algorithme représente à la figure 1 est modifié de la manière suivante : – Les contraintes de cohérence CA stipulent qu’un bi-segment est acceptable si au moins un lien d’alignement ai,j à l’intérieur du bi-segment est tel que p(ai,j |e, f ) est supérieur à un certain seuil.
– Les fonctions de compte fC = fR prennent en compte le caractère non-déterministe des liens d’alignement de la manière suivante.
Pour un bi-segment fC (fjj12 , eii21 ) : 
fC (fjj12 , eii21 ) = α(j1 , j2 , i1 , i2 ) × β(j1 , j2 , i1 , i2 ) avec                                     (1) α(j1 , j2 , i1 , i2 ) = 1 −                                 p¯(ai,j |e, f ),                                    (2) (j,i)∈in(j1 ,j2 ,i1 ,i2 ) 
β(j1 , j2 , i1 , i2 ) =                                p¯(ai,j |e, f )                                          (3) (j,i)∈out(j1 ,j2 ,i1 ,i2 ) où p¯(ai,j |e, f ) = (1 − p(ai,j |e, f )), le coefficient α correspond à la confiance accordée au lien à l’intérieur (in) du bi-segment et β quantifie la masse totale de probabilité des liens situés à l’extérieur (out) de ce bi-segment. L’estimation de cette fonction est illustrée à la figure 2.
Avec ces nouvelles définitions, l’évaluation des bi-segments doit être modifiée pour également prendre en compte les probabilités des alignements. La fonction φ ne nécessite pas de modification, puisqu’elle utilise la fonction fC , qui a été redéfinie. En revanche, les poids lexicaux sont maintenant définis comme suit : |e|                                                                                              |f | 
lex(e|f, Ap ) =                                                            w(ei |fj )p(ai,j |e, f ) + w(ei |f0 )           p¯(ai,j |e, f ) .   (4) i=1 {j|p(ai,j |e, f ) > 0}                                                                    j=1 ∀j:p(ai,j |e,f )>0 L’une des hypothèses explorée dans notre travail est que les gains modestes obtenus par (Liu et al., 2009) sont dus à la méthode utilisée pour estimer cette matrice pondérée, qui s’appuie sur un petit ensemble d’alignements calculés par le modèle IBM4. En E STIMATION D ’ UN MODÈLE DE TRADUCTION 
effet l’échantillonnage des alignements en ne considérant que les n-meilleures hypothèses des modèles IBM4 (n = 10 en pratique) revient à considérer qu’un sous-ensemble qui ne contient que peu de variation et beaucoup de redondance. Ainsi, l’exploration de la matrice d’alignement est par construction très limitée et l’estimation approximative. Par ailleurs, le calcul de la matrice d’alignement s’appuie sur une procédure ad hoc de recombinaisons des probabilités a posteriori des alignements initialement calculés séparément pour chaque direction de traduction.
L’alternative que nous proposons d’explorer consiste à estimer cette matrice en utilisant une modélisation directe de la probabilité d’un lien d’alignement en utilisant des modèles conditionnels exponentiels qui seront décrits à la section 3.
3    Modélisation de la matrice d’alignement Un alignement mot à mot entre une phrase source, et sa traduction (la phrase cible) regroupe un ensemble de liens décrivant une relation de traduction entre mots. Ainsi, prédire la matrice d’alignement peut être envisagé comme un problème de classification superviséé pour des données structurées. Lorsque des données étiquettées sont disponibles, la solution proposée dans (Ayan & Dorr, 2006; Tomeh et al., 2010, 2011) consiste à estimer de manière indépendante la probabilité de chaque lien dans la matrice à l’aide d’un modèle de régression logistique défini par : 
p (y|x) =        exp          λk fk (y, x) ,                                          (5) Z(x) k=1 où y désigne la variable aléatoire binaire qui indique si un lien est actif, x l’observation, Z(x) le facteur de normalisation, (fk )K k=1 définit un ensemble de fonctions caractéristiques, et (λk )K k=1 les poids associés. Dans l’équation (5), l’observation x désigne la paire de phrases augmentée de son étiquetage morphosyntaxique et des liens d’alignement produits par les modèles génératifs.
Cette formulation du problème permet de modéliser directement chaque cellule de la matrice d’alignement. Mais elle peut être également perçue comme une manière de fusionner différents alignements d’une paire de phrases. Cette approche permet donc également de remplacer l’étape heuristique de symétrisation, nommée grow-diag-final-and (Koehn et al., 2003) dans l’approche standard, par un modèle d’apprentissage statistique pouvant prendre en compte un nombre arbitraire d’alignements en entrée.
Estimer ce modèle à partir d’exemples demande néanmoins de prendre en considération le caractère très creux de la matrice d’alignement, conséquence du fait qu’une forte majorité de liens sont inactifs. La tâche de classification considérée est donc très déséquilibrée. Afin d’éviter d’apprendre un classifieur trop biaisé en faveur de la prédiction de liens inactifs, l’ensemble des liens à étiqueter peut être au préalable réduit à un sous-ensemble de la matrice. Pour définir ce sous-ensemble, les modèles génératifs classiques sont utilisés (modèles de Markov cachés et/ou IBM4 dans les deux directions) : tout lien qui n’apparait pas dans un des alignements génératifs est considéré comme inactif ; les autres liens sont évalués par le modèle de classification. Dans ce cadre, les alignements génératifs sont utilisés pour réduire l’espace de recherche et permettent de limiter l’effet potentiellement néfaste de données déséquilibrées (Ayan & Dorr, 2006; Elming & Habash, 2007).
Ce modèle est utilisé pour estimer la matrice pondérée d’alignement Ap décrite à la section 2.2. Le classifieur supervisé estime donc la probabilité p(ai,j |e, f ) pour chaque cellule de la matrice.
Apprentissage L’estimation des paramètres du modèle (les λk dans l’équation (5)) est faite de manière à maximiser la vraisemblance conditionnelle régularisée à partir d’un corpus d’entraînement. La régularisation utilisée est connue sous le nom d’ elasticnet (Zou & Hastie, 2005) et combine un terme de régularisation 1 , qui aide à sélectionner les fonctions caractéristiques les plus utiles et ainsi réduire la taille du modèle, et un terme de régularisation 2 , qui garantit que le Hessien de la fonction objectif n’est jamais trop proche de zéro, et permet ainsi d’éviter les problèmes d’instabilité numérique. Ce choix de régularisation nous permet d’envisager de nombreuses fonctions caractéristiques, sachant que certaines d’entre elles seront éliminées lors de l’entraînement car jugées inutiles.
Les caractéristiques Les fonctions caractéristiques utilisées pour le classifieur sont décrites en détail dans (Tomeh et al., 2010) et reprennent en partie celles proposées par (Ayan & Dorr, 2006). Elles prennent en compte les multiples sources d’informations : la paire de phrases augmentée de son étiquetage morphosyntaxique et les liens d’alignement produits par les différents modèles génératifs considérés. Ainsi, pour un lien d’alignement donné, ces fonctions binaires indiquent par exemple : l’association entre les mots source/cible et de même pour les étiquettes morphosyntaxiques associées ; quel modèle génératif propose ce lien comme actif NADI T OMEH , A LEXANDRE A LLAUZEN ET F RANÇOIS Y VON 
ainsi que le nombre total de modèles génératifs proposant ce lien comme actif ; combien de liens sont proposés par les modèles génératifs dans le voisinage ; la fertilité du mot source (et resp. du mot cible) considérant l’ensemble des alignements d’entrée ; l’écart du lien à la diagonale afin de favoriser ou non les alignements monotones ; la distance du lien avec le mot aligné le plus proche (en source et en cible) afin de caractériser si ce lien est isolé des autres.
À ces caractéristiques s’ajoutent celles que nous allons décrire. Une première famille de fonctions caractéristiques décrit les mots source et cible relatifs à un lien d’alignement (i.e une case de la matrice) : – Probabilité de traduction lexicale pour le couple de mots utilisé : p(fi |ej ) et p(ei |fj ) estimées par le modèle IBM1.
– La fréquence des mots source et cible ainsi que leur ratio.
– Un test sur tous les préfixes et suffixes de longueur 3.
– La similarité entre les mots source et cible calculée par la distance d’édition. Cette caractéristique tente de capturer la propension qu’ont les noms propres à être traduits de manière similaire, comme par exemple : SdAm Hsyn et Saddam Hussein.
– Un test portant sur l’égalité entre les mots source et cible.
– Un test indiquant si l’un des mots est une ponctuation associé avec un mot qui n’est pas une ponctuation.
Nous avons également définit un ensemble de fonctions caractéristiques permettant de décrire la structure de la matrice et les liens qui la composent. En plus des fonctions décrites dans (Tomeh et al., 2010), nous ajoutons la fonction qui indique si un lien d’alignement implique un mot dupliqué dans l’une des phrases. Cette caractéristique permet de pallier une faible modélisation de la distorsion.
Par exemple le mot arabe fy peut apparaître plusieurs fois dans une même phrase et être ainsi toujours aligné avec le même mot in en cible. Cette fonction retourne la distance du lien considéré à la diagonale.
4        Expériences 
Pour évaluer les différentes approches, nous utilisons la tâche de traduction de l’arabe vers l’anglais de l’évaluation NIST MT’09.
Nous comparons quatre méthodes d’estimation de la matrice pondérée : l’approche standard qui utilise les modèles d’alignement IBM4 et les heuristiques d’extraction et de valuation usuelles ; la méthode décrite dans le premier article sur les matrices pondérées (Liu et al., 2009) ; le système PostCAT (Graça et al., 2010) (décrit brièvement à la section 4.1) ; et l’estimation directe de la matrice via un modèle de régression logistique. Le système de traduction utilisé est M OSES(Koehn et al., 2007), un outil sous licence libre.
4.1       Corpus et outils 
Pour entraîner le modèle logistique, nous avons utilisé Wapiti (Lavergne et al., 2010) 1 , avec comme corpus d’apprentissage et de développement les données alignées manuellement du corpus IBMAC (Ittycheriah et al., 2006), contenant respectivement 10 000 et 663 paires de phrases. Nous avons construit 2 sous-ensembles, de taille différente, de données parallèles pour entraîner le système de traduction, afin d’évaluer l’impact du volume de données disponibles sur les résultats obtenus. Ces deux corpus ont été constitués à partir des données autorisées dans la tâche contrainte de l’évaluation NIST MT’09. Elles sont toutes disponibles via le Linguistic Data Consortium 2 .
Nous avons ainsi défini 2 tâches, l’une avec un corpus parallèle de 30 000 phrases (30k) et l’autre avec 130 000 phrases (130k). Les systèmes de traduction sont construits avec M OSES 3 en utilisant la configuration par défaut. Les paramètres de ces systèmes sont optimisés de manière usuelle avec l’outil MERT (Minimum Error Rate Training) avec comme données de développement le corpus NIST MT’06 contenant 1 800 phrases arabes et 4 traductions anglaises. Les traductions produites sont évaluées avec la métrique BLEU (Papineni et al., 2002) sur les données d’évaluation NIST MT’08, qui contiennent 1 400 phrases et 53k mots.
Pour le système PostCAT 4 et l’extraction des unités de traduction 5 , nous avons utilisé les outils libres disponibles sur la toile. Enfin les modèles de langue cible ont été appris avec la boîte à outils SRILM 6 en utilisant toutes les données monolingues autorisées dans le cadre de l’évaluation NIST MT’09 (pour plus de détails, on se reportera à (Allauzen et al., 2009)).
La partie anglaise des données est pré-traitée de manière classique (les méthodes utilisées sont décrites dans (Allauzen et al., 2009)).

1.   http ://wapiti.limsi.fr/ 2.   La description complète est disponible à l’adresse http ://www.itl.nist.gov/iad/mig/tests/mt/2009/ 3.   http ://www.statmt.org/moses/ 4.   http://www.seas.upenn.edu/~strctlrn/CAT/CAT.html 5.   http://www.nlp.org.cn/~liuyang/wam/wam.html.
6.   http://www-speech.sri.com/projects/srilm/.
E STIMATION D ’ UN MODÈLE DE TRADUCTION 
Pour la partie arabe, toutes les phrases sont analysées et segmentées avec l’outil MADA+TOKAN 7 . Nous avons utilisé le schéma de segmentation D2 afin de tenir compte de la morphologie riche de l’arabe et ainsi segmenter les mots arabes en des unités qui correspondent approximativement aux mots anglais.
4.2   Construction des modèles de traduction 
Dans la section 2, nous avons décrit un algorithme générique pour la construction d’un modèle de traduction. Cet algorithme fonctionne en trois étapes séparées : construction des matrices d’alignement pondérées, extraction puis évaluation des bi-segments. Nous allons maintenant évaluer l’impact de ces trois étapes sur les résultats en traduction automatique.
Pour la première étape, nous expérimentons deux manières de construire les matrices pondérées : (i) la méthode standard qui ne considère que les meilleurs alignements (ii) la matrice pondérée par les probabilités qui est utilisée dans le processus d’extraction et de valuation.
Notons qu’il est possible de passer de la configuration (ii) à (i) par un simple seuillage sur les probabilités. Dans toutes nos expériences, nous utilisons un seuil de 0, 5. Ainsi, pour chaque modèle d’alignement, deux types de systèmes sont construits : standard (configuration (i)) et WAM pour la matrice pondérée (configuration (ii) ). Le corpus de référence IBMAC contient également un jeu de test qui est utilisé pour calculer le taux d’erreur d’alignement (ou AER, pour Alignment Error Rate).
Les deux autres étapes (extraction et valuation des bi-segments) dépendent du mode de construction de la matrice d’alignement.
Dans le cas standard, les bi-segments sont extraits et évalués selon les heuristiques décrites à la section 2.1. Lorsque l’on utilise des matrices pondérées, nous utilisons les méthodes d’extraction et de valuation décrites à la section 2.2, qui prennent en compte la probabilité des liens d’alignement. Pour cette dernière approche, seuls les bi-segments dont la probabilité est supérieure à un seuil sont conservés. Ceci permet, comme le préconisent les auteurs de (Liu et al., 2009), de restreindre le nombre de bi-segments qui sont extraits. De plus, comme cela est fait dans l’approche standard, les bi-segments comprenant un segment de longueur supérieur à 7 sont également rejetés. Comme il est d’usage, les performances en traduction automatique sont évaluées par la métrique BLEU (Papineni et al., 2002).
4.3   Modèles d’alignement mot-à-mot 
En plus des deux méthodes de construction du modèle de traduction, nous avons également considéré plusieurs modèles d’alignement mot-à-mot, que nous allons décrire brièvement.
MGIZA++ 8 propose une implémentation efficace et parallèle (Gao & Vogel, 2008) des modèles génératifs les plus utilisés : les modèles IBM1 à IBM4 (Brown et al., 1993) et HMM (Vogel et al., 1996). Ces modèles sont utilisés par la suite pour construire des modèles de traduction selon la configuration standard et pour entraîner notre système d’alignement discriminant (voir section 3).
N-best WAM construit la matrice pondérée en effectuant une moyenne des occurences des liens d’alignement à partir des nmeilleures séquences d’alignement produites par le modèle IBM4. Cette méthode correspond à l’article original sur les matrices pondérées (Liu et al., 2009). Comme ces auteurs, nous avons utilisé la valeur n = 10.
PostCAT (Posterior Constrained Alignment Toolkit) propose une implémentation des modèles HMM permettant d’injecter des contraintes lors de l’apprentissage via l’algorithme EM. Ces contraintes portent sur les probabilités a posteriori des variables latentes (Graça et al., 2010) et permettent de corréler les deux directions d’alignement. Deux types de contraintes simples (symmétrie et bijectivité) permettent au modèle HMM d’atteindre des performances comparables au modèle IBM4. Le fait d’utiliser des modèles HMM permet de pouvoir calculer de manière exacte et efficace les probabilités a posteriori et ainsi construire la matrice pondérée en considérant l’ensemble des liens d’alignement. Dans cet article, nous avons utilisé la boite à outils Geppetto 9 (Ling et al., 2010), une implémentation de PostCAT et des matrices d’alignement pondérées.

7. http ://www1.ccls.columbia.edu/ cadim/MADA.html 8. http ://geek.kyloo.net/ 9. http ://code.google.com/p/geppetto/ NADI T OMEH , A LEXANDRE A LLAUZEN ET F RANÇOIS Y VON 
MaxEntWA est le système décrit à la section 3. Il s’agit d’un classifieur MaxEnt qui prédit pour chaque lien de la matrice sa probabilité a posteriori.
Exception faite du modèle noté MGIZA++, il est possible pour tous les modèles d’extraire et de valuer les bi-segments selon les deux méthodes. Pour appliquer la méthode (i), nous avons appliqué pour toutes les expériences un seuil de 0, 1 comme les auteurs de (Liu et al., 2009).
4.4    Résultats 
Les résultats expérimentaux pour les différentes configurations et les différents modèles d’alignement sont rassemblés dans le tableau 1. Examinons pour commencer, la partie 30k du tableau qui correspond aux expériences où M OSES a été entraîné sur un corpus de 30 000 phrases parallèles. La partie MGIZA++ présente les résultats obtenus en utilisant l’approche standard : utilisation des meilleures hypothèses d’alignement IBM4 symmetrisés pour extraire et valuer les bi-segments via les heuristiques usuelles (Koehn et al., 2003). Ainsi sur la tâche 30k, le système standard obtient un score BLEU de 35,9. La partie 10-best WAM correspond au matrice pondérée où les probabibilités a posteriori sont estimées à partir des 10 meilleurs alignements de IBM4. Cette approche permet d’obtenir un faible gain de 0,3 points BLEU par rapport à l’approche standard, soit (36,2). Ce résultat est cohérent avec ceux publiés dans (Liu et al., 2009).
La partie PostCAT introduit par rapport aux travaux de (Liu et al., 2009) l’utilisation des modèles HMM pour les alignements de mot et donc la possibilité d’estimer les probabilités a posteriori de manière exacte pour l’ensemble de la matrice. Cet apport permet d’augmenter le BLEU de manière significative : de 35,9 à 36,9 ou 37,0 selon la variante du modèle HMM utilisée. Enfin la partie MaxEntWA présente les résultats obtenus en utilisant un modèle exponentiel pour prédire la matrice d’alignement. Les résultats montrent un gain en BLEU supplémentaire et conséquent : 1,5 points par rapport à l’approche standard et 0,5 points par rapport à l’approche PostCAT. Notons également, que même si les méthodes standard d’extraction et de valuation sont utilisées, les matrices d’alignements engendrées par PostCAT et MaxEntWA permettent d’obtenir de meilleurs résultats et que MaxEntWA est à nouveau la méthode donnant le meilleur résultat.
Sur la tâche 130k (M OSES est entrainé sur 130 000 phrases parallèles), nous observons les mêmes tendances, avec cependant des gains en BLEU moindres. Notons que le gain modeste obtenu avec la méthode 10-best pour estimer la matrice pondérée est similaire à celui obtenu sur la tâche 30k. Pour les autres méthodes de calcul de la matrice pondérée, les gains restent significatifs, bien que moins importants. De nouveau, nous pouvons observer que le calcul de la matrice d’alignement avec le modèle de régression logisitique (MaxEntWA) permet d’obtenir de meilleurs résultats en termes de score BLEU.
La colonne PT du tableau 1 indique la taille du modèle de traduction en nombre de bi-segments extraits. Nous observons, tout naturellement, que quand on considère l’intégralité de la matrice pondérée (PostCAT et MaxEntWA), la taille du modèle de traduction augmente considérablement, puisqu’elle se trouve multipliée par plus de 4, alors même que le seuil de filtrage est resté constant à 0,1.
Le risque était, en multipliant les entrées du modèle de traduction, d’ajouter un bruit pouvant affecter le comportement global du système. Toutefois, il apparaît que la valuation des bi-segments par les probabilités (voir la section 2.2) est un moyen effectif pour filtrer les bi-segments les moins utiles lors de l’étape de traduction.
Ainsi, l’amélioration de la valuation des bi-segments a un impact significatif sur les résultats en BLEU. Si cette amélioration peut être imputée en partie à l’utilisation des matrice pondérée, la colonne AER (Alignment Error Rate) montre que cette amélioration peut provenir également d’alignements mot-à-mot de meilleure qualité. Partant d’un l’AER obtenu avec les modèles IBM4 symétrisés d’une valeur de 25,0%, on note tout d’abord que l’usage des 10-meilleurs alignements ne permet pas d’améliorer la qualité intrinsèque des alignements. En revanche, l’utilisation d’un modèle plus approprié tel que PostCAT entraîne une amélioration sensible des alignements, avec un AER de 22,5%. Cette tendance est encore plus affirmée avec la méthode MaxEntWA, qui introduit dans le processus des alignements de qualité nettement accrue, puisque la réduction absolue de l’AER est de plus de 10 points.
Globalement, les résultats expérimentaux montrent que l’utilisation de la matrice pondérée pour extraire et valuer les bi-segments permet d’améliorer les performances des systèmes de traduction, quand cette méthode est associée à un mode de calcul pertinent pour les valuations de la matrice pondérée. Ce dernier point recouvre d’une part la manière dont sont calculées les probabilités d’alignement, et d’autre part la fraction de cette matrice qui est effectivement explorée. La différence de résultats entre les deux tâches (30k et 130k) suggère que l’utilisation d’un modèle de régression logistique pour estimer la matrice pondérée conduit à des gains bien plus importants sur la petite tâche (30k). Une explication de cette différence est que cette approche permet, lorsque l’on dispose de peu de données parallèles, d’extraire plus de bi-segments : lorsque les données manquent pour estimer le modèle de traduction, il est en effet important de pouvoir malgré tout engendrer un grand nombre de bi-segments potentiels. De surcroît, on note que la valuation par des probabilités permet effectivement de limiter, au moment du décodage, les effets de l’introduction d’entrées bruitées dans la table de traduction.
E STIMATION D ’ UN MODÈLE DE TRADUCTION Tâche de traduction :                         30K                                             130K Construction du MT :                 Standard(i)         WAM(ii)                      Standard(i)         WAM(ii) Alignement                   AER      BLEU       PT    BLEU       PT         AER      BLEU       PT     BLEU       PT HMM                 28,4     35,0      3,6      -         -        26,8      39,2      9,7       -        MGIZA++ IBM4                25,0     35,9      2,4      -         -        23,3      40,2      6,5       -        10-best             IBM4                24,9     35,8      2,4     36,2     3,0        23,3      40,0      6,6     40,4      8,5 Bijective             22,5     36,6      3,3     36,9     10,2       20,5      40,1      9,1     40,6      29,5 PostCAT Symmetric              22,5     36,7      2,9     37,0     10,7       20,8      40,2      8,5     40,4      30,2 HMM                    17,6     36,9      6,7     37,5     11,7       16,4      40,5     17,7     40,8      30,0 MaxEntWA          IBM4                   15,6     37,2      5,5     37,5      9,6       14,3      41,0     14,5     41,1      25,0 HMM+IBM 1,3,4             14,7     37,1      5,2     37,9      8,6       13,9      40,8     13,4     41,1      22,2 
TABLE 1 – Comparaison de 4 modèles d’alignement (MGIZA++, 10-best, PostCAT and MaxEntWA) et de leurs interactions avec la méthode d’extraction et de valuation de la table de traduction en termes de taux d’erreur d’alignement (AER), de score BLEU et de la taille de la table de traduction exprimée en millions de bi-segments (PT). Les deux méthodes de construction du modèle de traduction (MT) sont l’approche standard (standard) et celle utilisant les matrices pondérées (WAM). Deux tailles de données parallèles d’apprentissage sont considérées (30K et 130K).
5    Discussion 
De nombreux travaux récents se sont intéressés aux méthodes d’extraction d’unités de traduction à partir de corpus parallèles. Que ce soit dans le cadre des systèmes hiérarchiques ou à base de segments, le processus d’extraction (Koehn et al., 2003; Chiang, 2007) repose sur les matrices d’alignement mot-à-mot construites à partir des modèles d’alignement IBM4 (Brown et al., 1993) symétrisés.
Comme nous l’avons évoqué à la section 2.1, ce choix de la première étape se justifie par un souci d’efficacité puisqu’il restreint considérablement l’espace des unités qui sont explorées, puis sélectionnées. Néanmoins, ce choix favorise la propagation d’erreurs dues à des décisions (d’accepter ou de rejeter des liens d’alignement) qui sont prises trop tôt dans le processus, sans qu’il soit de surcroit possible d’affecter de réels scores de confiance à ces décisions.
Lorsqu’il s’agit d’étendre l’espace des unités qui sont explorées, la première difficulté est la complexité qui résulte de l’énumération puis de la valuation de toutes les unités de traduction possible. Ainsi, une partie des travaux récents s’intéresse à l’élaboration d’une représentation efficace. Dans (Mi & Huang, 2008), le processus d’extraction des règles pour un système hiérarchique est étendu en considérant l’ensemble composé des n-meilleurs arbres d’analyse syntaxique au lieu de tenir compte uniquement du meilleur. Afin de représenter puis de manipuler efficacement ces n-meilleurs arbres, les auteurs utilisent une représentation efficace (packed forest) (Billot & Lang, 1989) ayant également démontré son utilité (Galley et al., 2006; Wang et al., 2007) en traduction automatique.
De manière similaire, les n-meilleurs alignements peuvent être utilisés afin d’enrichir la matrice d’alignement, que ce soit pour extraire les bi-segments (Xue et al., 2006), ou les règles d’un système hiérarchique (Venugopal et al., 2008). Dans ce dernier article comme dans (Mi & Huang, 2008), les auteurs définissent une distribution de probabilité sur les alignements à partir des n-meilleurs alignements et des n-meilleurs arbres d’analyse syntaxique. Cette approche par échantillonage permet aux auteurs d’introduire des comptes fractionnaires pour les règles extraites et ainsi de pouvoir estimer le modèle de traduction.
Ce recours à l’échantillonnage pour l’inférence des probabilités a posteriori des d’alignement se justifie par la complexité d’inférence du modèle IBM4. Il existe en revanche, pour les modèles plus simples, tels que ceux qui s’inspirent des modèles de Markov cachés (souvent désignés de manière générique sous le nom de « modèle HMM ») (Vogel et al., 1996) ou pour le modèle IBM1 (Brown et al., 1993), des algorithmes d’inférence exacts et efficaces (Venugopal et al., 2003; Deng & Byrne, 2005). Une des limitations du modèle HMM est son absence de modélisation de la fertilité. Pour pallier cette limitation, les auteurs de (Deng & Byrne, 2005) définissent un HMM permettant d’aligner des mots avec des segments qui rivalise en termes de performances avec le modèleIBM4, tout en préservant la possibilité d’un calcul exact des probabilités a posteriori des alignements de mots et qui s’étend au calcul de distributions a posteriori des segments ou des règles. Les expériences montrent que cette approche améliore significativement le processus d’extraction d’unités de traductions pour les systèmes à base de segments (Deng & Byrne, 2005) et hiérarchiques (de Gispert et al., 2010).
L’introduction des matrices pondérées (Liu et al., 2009) que nous décrivons à la section 2 peut être considérée comme l’adaptation NADI T OMEH , A LEXANDRE A LLAUZEN ET F RANÇOIS Y VON 
des packed forests des systèmes hiérarchiques au systèmes à base de segments : une exploration plus exhaustive de la matrice d’alignement, l’usage des probabilités des alignements de mots pour dériver des scores de confiance sur les bi-segments extraits.
Pour ce dernier point, les auteurs s’inspirent d’ailleurs des travaux de (Mi & Huang, 2008).
Comme mentionné à la section 2, un des problème des matrices pondérées est l’estimation des probabilités a posteriori des alignements. Dans (Liu et al., 2009), cette estimation est faite en échantillonnant les n-meilleurs alignements des modèles IBM4, alors que dans (Deng & Byrne, 2005; de Gispert et al., 2010; Ling et al., 2010) le modèle HMM ou une de ses variante est utilisé pour les estimer de manière exacte. Cependant, dans ce dernier type d’approche, il est encore nécessaire de fusionner les alignements correspondant aux deux directions (un modèle d’alignement de source vers cible et réciproquement). Les solutions envisagées semblent peu satisfaisantes : soit la fusion est heuristique et consiste simplement à prendre la moyenne arithmétique des distributions a posteriori (Graça et al., 2010; Ling et al., 2010) ; soit de manière beaucoup plus coûteuse, deux systèmes de traduction indépendants sont utilisés utilisant chaque modèle HMM, la fusion se fait alors sur les treillis engendrés par chaque système (de Gispert et al., 2010).
Dans cet article, nous introduisons donc une extension du travail de (Liu et al., 2009) en proposant une nouvelle méthode de construction de la matrice d’alignement. Pour cela, nous proposons d’utiliser un classifieur au maximum d’entropie décrit dans (Ayan & Dorr, 2006; Tomeh et al., 2010, 2011). Cette approche permet en effet de calculer directement la matrice pondérée sans avoir recours ni à une fusion heuristique des distributions a posteriori, ni à une coûteuse étape de fusion de système. Faute de données étiquettées permettant de mettre en œuvre cette démarche, l’approche de (Graça et al., 2010) semble fournir des performances proches de nos meilleurs résultats.
6    Conclusion 
Dans cet article, nous avons abordé le problème de l’estimation des modèles de traduction à partir d’alignements mot-à-mot nondéterministes. En effet, dans l’approche considérée comme standard, les modèles de traduction sont estimés à partir d’alignements mot-à-mot grâce à des heuristiques d’extraction et de valuation. Bien que ces alignements mot-à-mot soient construits par des modèles probabilistes, les processus d’extraction et de valuation utilisent ces modèles comme produisant des alignements déterministes.
À la suite (Liu et al., 2009), la solution que nous avons envisagée lève cette limitation en considérant une matrice d’alignement pondérée, dans laquelle chaque lien d’alignement est valué par sa probabilité. Les premiers travaux dans cette direction étaient, selon nos hypothèses, limités par la méthode d’estimation de la matrice pondérée, et nous avons proposé une méthode permettant d’estimer directement cette matrice à l’aide d’une méthode de classification supervisée.
Afin de valider cette approche, nous avons effectué des expériences sur la tâche de traduction automatique de l’Arabe vers l’Anglais de l’évaluation NIST MT’09. Dans ce cadre expérimental, nous avons comparé 4 méthodes de construction du modèle de traduction, contrastant ainsi l’approche standard avec l’usage des matrices pondérées, et évaluant différents estimateurs de cette matrice.
Les résultats ont montré que l’usage des matrices pondérées impliquait une extraction plus importante de bi-segments et que leur valuation adaptée permettait au système de traduction d’obtenir de meilleurs résultats mesurés en terme de BLEU. En particulier, des gains significatifs (entre 2 et 0,9 point BLEU, selon la tâche considérée) ont été obtenus par notre méthode, qui semble la mieux à même de produire des alignements de bonne qualité (au sens de l’AER). Ces résultats nous ont permis de conclure que le choix de l’estimateur des matrices pondérés a un impact net sur les performances en traduction et que notre méthode est nettement plus pertinente que celles proposées dans les travaux antérieurs.
Contrairement aux heuristiques standard, notre méthode permet de contrôler et d’adapter le nombre de bi-segments extraits à la taille des données parallèles d’entraînement. Nous souhaitons donc à l’avenir explorer cet aspect. L’approche envisagée consiste à extraire le plus de bi-segments possibles et à travailler sur leur filtrage. L’intérêt de cette approche est que nous pensons ainsi limiter l’impact des erreurs commises par les modèles d’alignement. De plus, l’étape de filtrage peut se faire en prenant en compte l’utilité des bisegments lors de l’étape de traduction et ainsi ne pas se limiter à des tests statistiques qui ne prennent pas en compte la finalité des modèles de traduction. Des articles récents comme (Wuebker et al., 2010) montrent l’importance d’une valuation des bi-segments qui améliorerait les simples calculs de fréquences, et qui serait plus directement en rapport avec la finalité des modèles de traduction.
Remerciements 
Ces travaux ont été en partie financé par l’agence OSEO dans le cadre du programme Quaero. Les auteurs tiennent à remercier Thomas Lavergne pour son aide précieuse concernant la mise en œuvre de Wapiti.
E STIMATION D ’ UN MODÈLE DE TRADUCTION 


Combinaison d’informations pour l’alignement monolingue 
Houda Bouamor Aurélien Max Anne Vilnat LIMSI-CNRS, Univ. Paris-Sud Orsay, F-91403, France {prénom.nom}@limsi.fr 
Résumé. Dans cet article, nous décrivons une nouvelle méthode d’alignement automatique de paraphrases d’énoncés. Nous utilisons des méthodes développées précédemment afin de produire différentes approches hybrides (hybridations). Ces différentes méthodes permettent d’acquérir des équivalences textuelles à partir d’un corpus monolingue parallèle. L’hybridation combine des informations obtenues par diverses techniques : alignements statistiques, approche symbolique, fusion d’arbres syntaxiques et alignement basé sur des distances d’édition. Nous avons évalué l’ensemble de ces résultats et nous constatons une amélioration sur l’acquisition de paraphrases sous-phrastiques.
Abstract.         In this paper, we detail a new method to automatic alignment of paraphrase of statements. We also use previously developed methods to produce different hybrid approaches. These methods allow the acquisition of textual equivalence from a parallel monolingual corpus. Hybridization combines information obtained by using advanced statistical alignments, symbolic approach, syntax tree based alignment and edit distances technique. We evaluated all these results and we see an improvement on the acquisition of sub-sentential paraphrases.
Mots-clés :         Paraphrase sous-phrastique, corpus parallèle monolingue, hybridation.

Keywords:           Phrasal paraphrase, monolingual parallel corpora, hybridization.
1    Introduction 
Le traitement de corpus monolingues et multilingues constitue un champ d’investigation très animé dans le domaine du traitement automatique des langues. Ils sont souvent constitués d’unités de texte ayant des liens sémantiques forts, une information qui peut être exploitée pour acquérir des équivalences entre des mots ou des groupes de mots et construire des ressources linguistiques importantes pour diverses applications. Ces resssources peuvent être utilisées par la suite pour extraire des réponses à des questions (Duclaye et al., 2003), par exemple, ou autoriser des formulations différentes en évaluation de la traduction automatique (Russo-Lassner .G & .P, 2005; Kauchak & Barzilay, 2006), ainsi qu’en génération, pour aider des auteurs à trouver des formulations plus adaptées (Max, 2008).
De nombreuses techniques ont été proposées pour l’acquisition de segments en relation de paraphrase. Ces techniques ont en commun d’être directement liées aux types de ressources sur lesquelles elles s’appliquent. Les plus nombreuses exploitent des corpus monolingues comparables disponibles en grandes quantités, et se fondent sur l’hypothèse que des unités linguistiques apparaissant de nombreuses fois dans des contextes similaires peuvent avoir la même signification. Restreindre les corpus utilisés à des textes comparables, sélectionnés sur la base d’un genre ou de thèmes communs, permet d’augmenter la probabilité que les correspondances obtenues seront effectivement valides grâce aux contextes plus restreints.
Peu de travaux ont, en comparaison, porté sur l’exploitation de corpus monolingues parallèles, constitués de phrases alignées en relation de paraphrase. Cela peut certainement s’expliquer par la faible disponibilité de telles ressources engendrée par le coût de leur construction. Mais elles présentent des caractéristiques qui en font les candidates les plus naturelles pour l’étude de la paraphrase sous-phrastique : les phrases parallèles étant issues de la volonté d’exprimer la même idée, les équivalences apprises apparaissent comme beaucoup plus fiables que celles extraites indirectement via des textes comparables ou des équivalences de traduction. En outre, le contexte de ces équivalences peut être extrait de façon directe, ce qui est particulièrement important pour caractériser les H OUDA B OUAMOR , AURÉLIEN M AX ET A NNE V ILNAT 
conditions de leur validité.
Ce travail porte sur l’acquisition de paraphrases sous-phrastiques depuis des corpus monolingues parallèles, et vise en particulier à extraire des paraphrases de qualité. Dans cet article, nous présentons D IST une nouvelle méthode symbolique optimisée pour l’alignement de bi-segments exploitant un corpus monolingue parallèle. Puis nous décrivons une approche hybride d’extraction de paraphrases sous-phrastiques par la combinaison d’informations issues de différentes techniques. Cet article est organisé comme suit : dans la section 2, nous passons en revue les travaux portant sur l’acquisition automatique de paraphrases puis nous détaillons, dans la section 3, le cadre expérimental de notre travail, l’approche suivie pour combiner des informations issues de différentes techniques et extraire des bi-segments à partir de corpus monolingues parallèles ainsi que les résultats obtenus. Nous terminerons par une description de nos prochains travaux (section 4).
2    Travaux précédents en acquisition de paraphrases 
L’acquisition de paraphrases peut être réalisées à l’aide de diverses méthodologies. Langkilde & Knight (1998) se sont basés sur les connaissances sémantiques de WordNet (Miller, 1995) pour exploiter les relations de synonymie entre termes et les utiliser ensuite lors de la génération de paraphrases. Cependant, ces ressources ne sont pas nécessairement disponibles dans toutes les langues et ne comportent que des équivalences textuelles au niveau des mots. C’est la raison pour laquelle de nombreux autres travaux se sont basés sur des corpus monolingues et multilingues parallèles ou comparables.
La majorité des travaux menés sur des corpus monolingues parallèles se basent essentiellement sur l’hypothèse de distributionnalité (Harris, 1954), selon laquelle les mots apparaissant dans le même contexte tendent à avoir des sens similaires. Cette hypothèse a été appliquée, par exemple, à des chemins dans des arbres de dépendance pour la découverte de règles d’inférence à partir de textes (Lin & Pantel, 2001). Barzilay & McKeown (2001) utilisent des informations contextuelles basées sur des similarités lexicales pour extraire des paraphrases à partir d’un ensemble de corpus alignés. De manière similaire, Pang et al. (2003) exploitent la structure syntaxique d’un ensemble de phrases issues de corpus parallèles monolingues pour construire de nouvelles paraphrases d’énoncés par fusion syntaxique et regénération. Ibrahim et al. (2003) présentent eux une méthode non supervisée d’acquisition de paraphrases qui consiste à extraire des paraphrases structurelles, ou des fragments d’arbres syntaxiques sémantiquement équivalents, à partir de corpus monolingues parallèles.
Puisque les corpus monolingues parallèles sont des ressources rares et difficiles à obtenir, d’autres techniques ont été implémentées en se basant sur des corpus monolingues comparables, corpus composés de textes dans la même langue partageant une partie du vocabulaire employé, ce qui implique généralement que les textes parlent d’un même sujet, durant la même période, afin d’obtenir des paraphrases. Notamment, certains travaux exploitent des corpus monolingues comparables, comme ceux de Deléger & Zweigenbaum (2009) dans le domaine médical visant la construction d’un corpus de paraphrases de segments opposant les langues de spécialité et de vulgarisation. Barzilay & Lee (2003) introduisent une technique d’alignement multi-séquence factorisant des phrases ayant la même structure syntaxique, extraites à partir d’un corpus comparable, sous forme de treillis contenant des équivalences locales. Quirk et al. (2004) proposent une approche consistant à apprendre un système de traduction statistique sur un corpus monolingue de phrases alignées automatiquement à partir d’un corpus comparable qui opère par reformulations locales.
Outre les corpus monolingues, des corpus multilingues parallèles ont été exploités pour l’extraction des paraphrases en se basant sur l’hypothèse que des segments partageant des traductions dans une autre langue peuvent être des paraphrases dans certains contextes. Bannard & Callison-Burch (2005) ont décrit une approche par pivot exploitant plusieurs corpus parallèles. De la même manière, Max (2009) utilise des traductions de segments en pivot pour produire des reformulations et sélectionner parmi celles-ci celles qui sont préférées par différents types de modèles. La majorité de ces approches s’attaque au problème d’acquisition de paraphrases d’énoncés complets.
Or, il est également intéressant de pouvoir extraire des reformulations pour des unités de texte plus petites à partir de plusieurs corpus quel que soit leur degré de parallélisme.
C OMBINAISON D ’ INFORMATIONS POUR L’ ALIGNEMENT MONOLINGUE 
3     Combiner des informations pour l’alignement 
Différentes approches peuvent être utilisées pour faire l’acquisition de paraphrases sous-phrastiques depuis des corpus monolingues parallèles (Bouamor et al., 2010). Outre l’amélioration individuelle de ces techniques, il est possible de parvenir à une amélioration des performances obtenues en exploitant utilement les résultats de chacune. Dans cette section, nous commençons par décrire le cadre expérimental dans lequel s’ancre notre étude sur l’alignement monolingue dans des paires de paraphrases, puis nous présentons brièvement quatre techniques que nous utilisons pour cette tâche. Nous décrivons ensuite un cadre de combinaison des résultats qu’elles produisent et détaillons les résultats de nos expériences.
3.1     Cadre expérimental 
Les paraphrases d’énoncés sont relativement rares à l’état naturel, car peu d’activités humaines en gardent la trace lorsqu’elles existent. En outre, certains types de réécritures, comme le résumé, altèrent de façon significative le contenu des textes. Des solutions pour l’acquisition de paraphrases ont cependant été proposées, par exemple à partir de corpus comparables (Dolan & Brockett, 2005) ou de traces d’éditions (Dutrey et al., 2010), mais l’identification de ce qui constitue des paraphrases acceptables reste une difficulté majeure. Une solution plus directe consiste à faire produire de telles paraphrases par des humains dans le cadre naturel d’une traduction où une même phrase est traduite plusieurs fois indépendamment. Le corpus MultiTrad (Bouamor, 2010) a été construit selon ce principe en obtenant des traductions vers le français d’extraits du corpus des débats parlementaire européen.
Pour l’étude présentée ici, nous avons sélectionné un corpus de développement issu de MultiTrad constitué de 50 énoncés traduits 4 fois de l’anglais vers le français. Pour chaque groupe de quatre paraphrases, la paraphrase la plus similaire en moyenne aux autres paraphrases a été identifiée et associée aux trois autres. Cette similarité est calculée par une valeur moyenne d’édition mesurée par TER (Translation Error Rate) (Snover et al., 2009). Les 150 paires de paraphrases obtenues ont alors été annotée au niveau des mots par 3 annotateurs à l’aide de YAWAT (Germann, 2008), un outil qui permet d’utiliser, au choix, une vue parallèle entre énoncés présentés sous forme de paragraphes ou de matrices d’alignement. Chaque paire a été annotée par un seul annotateur : Callison-Burch (2008) mentionne un accord inter-annotateur acceptable sur une telle tâche 1 , mais l’ensemble des annotations a par la suite été vérifié par le même annotateur. À partir des matrices d’alignement produites, l’ensemble des bi-segments de référence est extrait en respectant la contrainte suivante : tous les mots du segment contenu dans la première paraphrase sont alignés avec au moins un mot du segment de la seconde paraphrase et ne sont alignés qu’avec des mots de ce segment, et réciproquement.
Pour évaluer la performance de nos techniques d’alignement monolingue, nous utilisons l’approche PARAMETRIC (Callison-Burch et al., 2008), dans laquelle un ensemble de bi-segments (correspondant à des paires de paraphrases sous-phrastiques) de référence est comparé aux bi-segments produits par la méthode évaluée. La mesure PARAMETRIC se décompose en des valeurs usuelles de précision et de rappel, définies respectivement comme la proportion des candidats proposés appartenant à la référence et la proportion des éléments de la référence proposés, ainsi qu’en une F-Mesure combinant les deux à égalité. Notre évaluation portera sur un extrait du corpus de traductions multiples issus de la campagne CESTA 2 contenant 375 paires de paraphrases (comportant entre 15 et 25 mots) et obtenues par traduction de l’anglais vers le français. L’alignement de référence a été réalisé en suivant la même procédure que pour le corpus de développement avec 2 annotateurs. Notre étude a révélé un taux d’accord inter-annotateur global de 88,96% qu n’est plus, cependant, que de 67,35% lorsque les paraphrases "identité" ne sont pas prises en compte.
3.2     Techniques individuelles 
Nous avons implémenté dans ce travail quatre techniques, développées pour des besoins différents. Nous les avons choisies parce qu’elles opèrent à différents niveaux ce qui devrait permettre de tirer parti de leur complémentarité potentielle. La première est fondée sur l’apprentissage statistique d’alignements entre mots (M OT), et requiert 
1. Il faut cependant noter que les travaux de Callison-Burch (2008) portait sur des textes journalistiques en anglais et qu’un guide d’annotation avait été fourni aux annotateurs.
2. Corpus de la Campagne d’Evaluation de Systèmes de Traduction Automatique : http://www.elda.org/article125.html H OUDA B OUAMOR , AURÉLIEN M AX ET A NNE V ILNAT 
donc des quantités de données d’apprentissage en nombre relativement important. La seconde exploite des règles de description de variantes de termes et des connaissances a priori sur la variation lexicale (T ERME). La troisième utilise la structure syntaxique des énoncés pour mettre en correspondance des segments (S YNT), et requiert par conséquent un analyseur syntaxique. La quatrième, calcule une transformation au niveau des mots pour transformer une séquence de mots en une autre en mettant en jeu des opérations de transformation dont le coût est appris automatiquement (D IST). Une étude comparative des trois premières techniques a été faite dans (Bouamor et al., 2010). Elle a, en particulier, mis en évidence des différences de performance notables sur deux types de corpus parallèles monolingues obtenus par traductions multiples à partir d’une même langue d’une part, et de plusieurs langues d’autre part. Dans cet article, une nouvelle technique est introduite et utilisée de façon originale, et une combinaison efficace sous forme d’adaptation de cette dernière technique est proposée.
3.2.1   Approche fondée sur l’apprentissage d’alignements entre mots (M OT) 
La technique M OT consiste à apprendre des alignements entre mots en utilisant des modèles d’alignement statistique appliqués sur deux phrases parallèles, initialement conçus pour la tâche d’alignement bilingue entre mots en traduction automatique statistique. Une telle technique requiert typiquement des quantités de données importantes pour apprendre des alignements fiables 3 . Dans nos expériences, nous mettrons à disposition de M OT toutes les paires de paraphrases possibles (pour des groupes constitués de 4 paraphrases) afin d’améliorer ses capacités d’alignement, ce qui constitue pour elle un avantage car les autres techniques ne considèrent les paires de paraphrases qu’isolément (en d’autres termes, pour les autres techniques l’information acquise sur une paire de paraphrases n’est pas directement exploitée pour les alignements ultérieurs). Par ailleurs, ce type de technique fonctionne d’autant mieux que les phrases des corpus d’apprentissage utilisées sont parallèles, signifiant ici qu’un alignement mot à mot est facile à réaliser. Dans le cas bilingue, ce n’est évidemment pas le cas de langues très différentes, et dans le cas monolingue, nos expériences précédentes ont montré que M OT obtenait des résultats sensiblement meilleurs lorsque les paraphrases utilisées sont obtenues par traduction depuis une même langue.
Nous avons utilisé le programme G IZA ++ (Och & Ney, 2003) pour réaliser l’alignement entre mots et les heuristiques du système de traduction statistique M OSES (Koehn et al., 2007) pour extraire des bi-segments à partir des matrices d’alignement obtenues. Un exemple d’une matrice d’alignement produite par M OT est donné dans la figure 1. À partir de cette matrice, 12 bi-segments différents sont extraits en appliquant les critères décrits ci-dessus.
3.2.2   Approche fondée sur l’expression symbolique de la variation (T ERME) 
Pour chaque paire d’énoncés en relation de paraphrase, il est possible d’exprimer des règles régissant les variations syntagmatiques et paradigmatiques acceptables au niveau des segments. Les nombreux travaux qui ont porté sur les notions de termes et de variantes de termes offrent ainsi une solution assez directe à ce problème de mise en correspondance. L’approche symbolique T ERME que nous utilisons exploite l’opération d’indexation contrôlée du système FASTR (Jacquemin, 1999) pour trouver les alignements sous-phrastiques possibles entre deux paraphrases d’une paire donnée. Cette opération définit les variations acceptables pour un terme par un système de métarègles décrivant ses réécritures morphosyntaxiques possibles. Les métarègles peuvent également mettre en jeu des relations lexicales définissant des variations morphologiques (mots d’une même famille morphologique) et sémantiques (synonymie). Ces ressources constituent donc des connaissances a priori utilisées par T ERME qui ne sont pas accessibles aux autres techniques.
L’outil FASTR utilisé a été conçu pour rechercher efficacement des termes et leurs variantes dans de grands corpus de textes. Pour nos besoins, considérant une paire de paraphrases d’énoncés, nous recherchons dans la première phrase (notre « corpus ») des variantes pour chacun des segments possibles de l’autre phrase (à concurrence d’une certaine taille), puis nous inversons la recherche et retenons l’intersection des résultats. L’usage que nous faisons du moteur de détection de variantes de termes semble favorable à l’obtention d’une bonne précision. À l’inverse, les métarègles définies pour le repérage de variantes de termes ne sont pas nécessairement les mieux adaptées pour assurer une bonne couverture des phénomènes paraphrastiques entre segments de nature quelconque (Dutrey et al., 2010).
3. La technique développée par Lardilleux (2010) constitue une exception notable adaptée aux événements de basse fréquence, et sera naturellement considérée dans la suite de nos travaux.
C OMBINAISON D ’ INFORMATIONS POUR L’ ALIGNEMENT MONOLINGUE Commission Commission application application témoigner réglement témoigner règlement membres membres intention intention a-t-elle a-t-elle précité précité intérêt intérêt pour états pour états son son par par les La les du La de du de l’ l’ l’ l’ ,                                                                     La Commission envisage-t-elle de contrôler la mise en oeuvre de cette réglementation par les Etats membres F IGURE 1 – Matrice d’alignement d’une paire de phrases dans M OT (à gauche), et sa matrice correspondante dans la base de référence.

3.2.3          Approche fondée sur l’alignement de structures syntaxiques (S YNT) 
Lorsque deux énoncés en relation de paraphrase partagent une même structure syntaxique, il est possible de réaliser un alignement fin guidé par la syntaxe permettant de faire apparaître des correspondances sous-phrastiques fines. L’algorithme de Pang et al. (2003) décrit une fusion syntaxique consistant essentiellement à fusionner des arbres de constituants de deux énoncés là où les listes de catégories filles sont compatibles et qu’aucune évidence de non parallélisme syntaxique (via un mécanisme de blocage lexical) n’est détectée. La forêt d’arbres syntaxiques ainsi obtenue permet de construire un treillis de mots représentant des formulations alternatives qu’il est possible d’extraire par simple parcours du treillis.
Pour la méthode S YNT nous avons réimplémenté l’algorithme originel et avons amélioré sa robustesse et sa correction en ajoutant un mode de fusion flexible dans lequel les parties de la phrase non concernées par un blocage lexical sont tout de même fusionnées. Par ailleurs, étant donné que l’algorithme est très dépendant de la qualité des analyses syntaxiques produites, nous avons également ajouté un mode exploitant les k meilleures analyses produites par un analyseur probabiliste. La combinaison retenue entre une analyse du premier énoncé et une analyse du second parmi les k 2 combinaisons possibles est celle minimisant le nombre de nœuds dans le treillis obtenu avant réduction. Un exemple de treillis obtenu par application de S YNT est donné dans la figure 2.

cette                    proximité dans     14                      15 
...       sous       la       barre       des        2                                  ou                         alentours                                   valeur   19 0         4          5        6           7         8                           cent   12         13   aux                              de          cette deux                                                                       16        17               18 pour                                      autour 10          11 F IGURE 2 – Exemple d’un treillis obtenu par application de S YNT 
Tout comme T ERME, cette technique semble a priori plus adaptée à l’extraction précise de bi-segments monolingues, mais contrairement à T ERME il est attendu qu’elle ne parvienne pas à extraire de correspondance lorsque les structures syntaxiques de haut niveau des paraphrases d’énoncés ne sont pas compatibles.
3.2.4          Approche fondée sur la distance d’éditions sur des séquences de mots (D IST) 
Une relation entre deux paraphrases peut également s’exprimer sous forme de la séquence d’éditions la plus directe permettant de transformer l’une en l’autre. Une telle séquence d’éditions sur les mots est, par exemple, H OUDA B OUAMOR , AURÉLIEN M AX ET A NNE V ILNAT 
implémentée dans la technique TERp (Translation Edit Rate plus) (Snover et al., 2009), originellement développée pour le calcul d’une distance d’édition servant de mesure en traduction automatique pour évaluer une hypothèse de traduction relativement à une traduction de référence. Ce calcul met en jeu des opérations de transformation de chaîne incluant l’insertion, la suppression et la substitution de mots, ainsi que le déplacement et la substitution de segments. Chaque type d’opération est associé à une pondération optimisée sur un corpus de développement pour une mesure particulière, et l’algorithme effectue une recherche de la séquence d’opération la moins coûteuse. Les substitutions de mots ou segments sont optionnelles, mais peuvent exploiter des listes fournies à l’algorithme 4 , et les substitutions de segments ont une probabilité associée.
Pour son calcul, TERp produit donc un alignement au niveau des mots entre deux énoncés. Pour nos besoins, nous avons implémenté une méthode D IST qui extrait l’ensemble des bi-segments (à concurrence d’une taille maximale) dérivables des alignements produits par TERp. Nous avons exploité la possibilité d’optimiser TERp pour nos besoins, en optimisant ses paramètres par la méthode du hill climbing 5 . Par la suite, nous dénoterons D ISTA l’optimisation originelle réalisée par Snover et al. (2009) pour l’évaluation de la traduction automatique (le « A » est pour « adequacy »). Les variantes D ISTP , D ISTR et D ISTF1 correspondent à des optimisations réalisées sur un corpus de développement maximisant respectivement la précision, le rappel et la F-mesure de PARAMETRIC exploitant des annotations de référence. L’ensemble de ces configurations n’utilisent pas de substitutions de segments, mais nous ferons appel à cette possibilité dans un cadre d’hybridation décrit plus loin. Un exemple de résultat d’alignement fourni par TERp est donné dans la figure 3.
F IGURE 3 – Exemple d’un alignement résultat de D IST 3.2.5    Résultats expérimentaux et analyse 
Nous avons évalué chacune des méthodes présentées ci-dessus sur le corpus de test décrit dans la section 3.1.
Les techniques M OT, T ERME et S YNT ont été utilisées telles que décrites. Pour D IST, nous avons exploité la possibilité d’optimiser la mesure selon nos propres objectifs. La variante D ISTA , évaluée pour référence, correspond à la version de TERp optimisée pour les besoins de l’évaluation de la traduction automatique. Les autres variantes D ISTP , D ISTR et D ISTF1 correspondent à TERp optimisée pour maximiser respectivement la précision, le rappel et la f-mesure de PARAMETRIC. La première partie de la table 1 donne les résultats obtenus sur les trois sous-mesures de PARAMETRIC. On constate tout d’abord que les résultats pour les 3 premières techniques sont cohérents avec ceux obtenus dans (Bouamor et al., 2010). La seule différence notable est l’amélioration de la précision des deux techniques symboliques T ERME et S YNT. La technique statistique d’alignement entre mots M OT obtient un rappel beaucoup plus important que les deux autres techniques qui se distinguent par une précision relativement forte (60,87 pour T ERME et 66,96 pour S YNT). La précision de M OT reste toutefois dans une zone raisonnable à 47,02. Comme expliqué précedemment, M OT tire avantage des 3 paires de paraphrases sur lesquelles il peut réaliser son apprentissage, alors que les deux autres techniques, telles qu’implémentées, ne peuvent améliorer l’alignement à l’intérieur d’une phrase en exploitant des informations dérivées d’autres phrases.
L’ajout original pour notre tâche de D IST, technique fondée sur une distance d’édition sur des séquences de mots, révèle de nouveaux résultats intéressants. Tout d’abord, on constate qu’au niveau de la f-mesure, il n’existe qu’une faible différence entre D ISTA et la variante optimisée sur la f-mesure, D ISTF1 . Ceci signifie que nos objectifs sont très similaires à ceux de l’évaluation en traduction automatique tels que décrits par (Snover et al., 2009). On constate cependant que des optimisations spécifiques en faveur de la précision ou du rappel mènent ici à des gains très importants de +8,69 en précision et de +7,42 en rappel. Ces résultats montrent que la technique D IST peine à améliorer simultanément la précision et le rappel, même si celle-ci obtient globalement des performances très proches de la meilleure technique envisagée jusque-là, M OT, avec une précision légèrement meilleure et un rappel 4. La version standard de TERp fournit des techniques de racinisation ainsi que des ressources de synonymie ainsi que de paraphrases locales pour l’anglais. TERp utilise jusqu’à 11 paramètres.
5. La première itération d’optimisation se fait avec des poids uniformes, puis nous réalisons 10 itérations avec des valeurs initiales tirées aléatoirement afin de diminuer le risque d’utiliser un minimum local.
C OMBINAISON D ’ INFORMATIONS POUR L’ ALIGNEMENT MONOLINGUE 
légèrement inférieur. Il est possible que les modèles mis en jeu pour le calcul de la distance d’édition ne soient pas suffisamment expressifs pour nos besoins, et qu’en particulier, la non prise en compte de critères linguistiques pour opérer des transformations de séquences de mots soit à mettre en cause.

Précision   Rappel/13532     F1 Mot                  47,02        61,42       53,26 Terme                 60,87         4,19        7,85 Synt                 66,96        13,11       21,92 DistA                 49,85        54,14       51,91 DistP                 58,54         2,68        5,13 DistR                 39,48        61,56       48,11 DistF1                49,03        56,21       52,37 union(Mot,Terme,Synt,DistF1 )      38,99        73,55       50,97 intersection(Mot,DistF1 )       70,38        32,31       44,29 TABLE 1 – Résultats obtenus pour chaque technique 
La dernière partie de la table 1 donne les résultats obtenus en opérant une combinaison élémentaire des résultats visant à maximiser d’une part la précision, et d’autre part le rappel. L’union sur le résultat de l’ensemble des techniques obtient un maximum de valeur de rappel de 73,55 (+12,13 relativement à M OT), avec une précision légèrement affectée (-2,29 relativement à M OT). Par ailleurs, réaliser l’intersection entre les différentes techniques peut raisonnablement mener à une précision améliorée. Cependant, le peu de résultats produits par T ERME et S YNT nous ont fait préférer une mesure sur l’intersection de M OT et D ISTF1 : nous obtenons alors une valeur maximale de précision de 70,38 (+23,36 relativement à M OT et +21,35 relativement à D ISTF1 ). Ces résultats montrent bien la complémentarité qui existe entre ces différentes techniques, et servent donc ici de motivation pour la recherche d’un mode de combinaison plus efficace des informations issues de chaque technique.
3.3     Approche hybride d’extraction de paraphrases locales 
3.3.1   Observations et motivations 
Les expériences présentées dans la section 3.2.5 ont révélé que les différentes techniques ont des performances variées, ce qui permet aussi de faire l’hypothèse qu’il est possible d’opérer une combinaison efficace de leurs résultats. Nous faisons ici une synthèse des points forts et des limitations de chacune de ces techniques orientée par la recherche d’un mode de combinaison plus efficace : – M OT : très sensible à la fréquence de ses observations de mots et de cooccurrences entre mots, cette technique peut être informée par des connaissances d’association a priori, qui peuvent par exemple être transmises sous forme de données d’apprentissage additionnelles. En outre, il est possible, avec des données d’entraînement annotées, d’améliorer les performances des alignements statistiques par apprentissage discriminant (Tomeh et al., 2010).
– T ERME : cette technique est spécialisée dans l’extraction d’un type de bi-segments contraints par des règles de réécriture et de variation lexicale. Les métarègles, qui ont été développées manuellement, sont assez précises et ne peuvent couvrir tous les phénomènes de paraphrase. Leur apprentissage automatique peut améliorer la couverture, mais au détriment de la précision. L’enrichissement automatique des familles morphologiques et sémantiques devrait également permettre d’augmenter le rappel.
– S YNT : cette technique est très sensible au degré de parallélisme des énoncés qui décide de la fusion de constituants syntaxiques. Nous avons déjà pris en compte la qualité des analyses syntaxiques en autorisant la fusion à opérer sur les k-meilleures analyses syntaxiques. Le blocage lexical empêche une fusion lorsqu’un mot présent dans le constituant d’une phrase est attesté dans un constituant non aligné de l’autre phrase. Il pourrait être amélioré par la connaissance a priori de paraphrases locales, ce qui, néanmoins, ne pourrait bénéficier qu’à la précision.
– D IST : cette technique transforme une séquence de mots en une autre en un coût minimal, en utilisant des pondérations optimisées pour les différentes opérations utilisées. L’algorithme manipule des segments qui n’ont pas nécessairement de motivation linguistique, ce qui peut mener à des transformations aberrantes. En outre, des H OUDA B OUAMOR , AURÉLIEN M AX ET A NNE V ILNAT 
opérations d’insertion et de suppression peuvent être utilisées à tort lorsque des correspondance au niveau des mots ou des segments ne sont pas connues. Ainsi, si de telles correspondances peuvent être fournies à TERp, il est possible d’espérer diminuer le nombre d’opérations de transformation aberrantes et ainsi d’augmenter la performance.
3.3.2   Présentation de l’hybridation des méthodes 
Dans la section précédente nous avons montré qu’il existait plusieurs voies pour améliorer la performance de l’alignement monolingue auquel nous nous intéressons à partir des techniques décrites. Sans considérer davantage, à ce stade, l’amélioration individuelle de chacune des techniques, nous pouvons décrire les deux grandes familles d’approches possibles pour l’hybridation de la manière suivante : 1) les résultats produits indépendamment par chaque technique sont combinés a posteriori, et 2) une technique est adaptée par la connaissance des résultats produits par les autres techniques.
Nous avons déjà montré le résultat de l’évaluation d’une approche élémentaire par combinaison a posteriori dans la section 3.2.5, illustrée sur la partie gauche de la figure 4, qui révèle que la précision et le rappel peuvent ainsi être facilement améliorés. Nous considérons désormais la seconde approche. D’après nos observations, D IST est un candidat assez naturel pour l’adaptation. En effet, la connaissance d’alignements au niveau des mots ou des segments peut diminuer le nombre d’opérations effectuées à tort. Il s’agit précisément de la motivation majeure pour l’évolution de TER à TERp (Snover et al., 2009), liée à la possibilité d’utiliser une base de paraphrases locales connues a priori et ainsi d’être plus robustes quant aux hypothèses de traduction acceptées par le système lorsqu’elle ne correspondent pas exactement à une traduction de référence.
Au contraire de ce qui est fait dans TERp, nous n’utiliserons pas une base de connaissances externe, même si nous ne rejetons pas cette hypothèse pour de futures expériences, mais nous adaptons dynamiquement la base de paraphrases utilisées en fonction des hypothèses extraites par les autres techniques, à savoir des hypothèses nombreuses et relativement précises pour M OT, et peu nombreuses mais précises pour T ERME et S YNT. De plus, comme nous l’avons déjà montré, ces techniques peuvent être complémentaires quant aux types de paraphrases locales qu’elles permettent d’identifier, ce qui rejoint nos intuitions initiales liées à la nature de chacune d’elles.
Cette approche est illustrée sur la partie droite de la figure 4. Les bi-segments obtenus par M OT, T ERME et S YNT sont combinés pour construire une table de paraphrases utilisée ensuite par D IST, que nous pouvons optimiser en fonction d’un besoin particulier (précision, rappel ou f-mesure). On remarque ici une analogie assez directe avec d’autres scénarios de combinaisons d’informations en TAL : en traduction automatique, l’approche de la partie gauche de la figure 4 correspond à la définition classique de la combinaison de systèmes (Matusov et al., 2009), alors que l’approche de la partie droite correspond à l’adaptation d’un système par des sources externes telles que d’autres systèmes de traduction (Crego et al., 2010).
Mot                                                   Mot Terme                                                Terme 
Dist combinaison                                          combinaison (union) Synt                                     Bitexte     Synt Bitexte monolingue                                           monolingue Dist F IGURE 4 – Principales approches de combinaisons d’informations pour l’alignement multilingue. À gauche, plusieurs techniques produisent des résultats combinés pour produire une nouvelle sortie. À droite, un sousensemble des techniques fournissent leurs résultats à une dernière technique adaptée à l’exploitation de ces connaissances.

Un problème important à considérer concerne la manière dont la table de paraphrases utilisée par TERp est construite à partir des hypothèses produites par les différentes techniques. À ce stade de nos travaux, nous ne disposons pas de mesures de confiance données par chaque technique pour chacune de ses hypothèses, et nous sommes donc contraints de les considérer initialement comme équiprobables. De plus, pour assurer une comparaison plus directe avec la combinaison correspondant à la partie gauche de la figure 4, nous réalisons une combinaison simple C OMBINAISON D ’ INFORMATIONS POUR L’ ALIGNEMENT MONOLINGUE 
à base d’union : chaque hypothèse apparaissant au moins une fois parmi les hypothèses des différents systèmes est retenue et est associée à un poids constant uniforme. 6 Un autre aspect important concerne là encore la pondération associée à chacune des paires de paraphrases a priori fournies à TERp. Considérons le cas où deux paraphrases sont fournies à TERp et où l’une est un sous-segment de l’autre : par exemple, (ce degrévement ↔ cet allègement) inclut (dégrèvement ↔ allègement). Si ces deux paraphrases sont fournies avec le même score à TERp, celui-ci préfèrera, dans de nombreux cas, utiliser la plus couvrante des deux, car cela minimisera souvent la quantité d’opérations de transformation restant à faire, et donc le coût global de transformation (voir partie gauche de la figure 5). Cela peut ne pas être un défaut en soi, car l’identification des plus longues sous-unités paraphrastiques peut être utile. Cependant, PARAMETRIC base ces mesures sur l’ensemble des bi-segments pouvant être extraits à partir d’alignement sur les mots. Ainsi, si dans l’exemple précédent l’alignement de référence inclut deux points d’alignement pour (ce ↔ cet) et (dégrèvement ↔ allègement), l’ensemble des bi-segments de référence sera constitué des deux bi-segments précédents et de leur combinaison ou « extension » (ce degrévement ↔ cet allègement). Si ce dernier est utilisé par TERp, il n’existe pas de moyen immédiat pour retrouver l’alignement sous-phrastique, et donc le rappel de la technique adaptée sera pénalisé.
Plusieurs solutions sont envisageables pour pallier ce problème. La pondération des paraphrases pourraient prendre en compte le nombre de mots/tokens couverts en favorisant les courts segments. Ne disposant néanmoins pas de solutions génériques applicables à toutes les techniques ni de moyen d’intégrer des scores de confiance motivés, nous préférons nous en remettre à une solution initiale plus simple, qui consiste à ne conserver que les sous-segments minimaux parmi l’union de ceux proposés par chacune des techniques. Ainsi, ne seront gardés pour construire la table de paraphrases utilisée par TERp que les bi-segments n’étant inclus dans aucun autre bi-segment, que nous appellons bi-segments minimaux.
F IGURE 5 – Exemple de deux alignements résultats de D ISTF1 , avec à gauche l’ensemble des bi-segments non filtrés, et à droite un ensemble de bi-segments minimaux 3.3.3    Résultats expérimentaux et analyse 
Les résultats que nous obtenons en optimisant TERp sur les trois mesures de PARAMETRIC et en utilisant différentes sources de bi-segments sont présentés dans la table 2. Le résultat principal de ces expériences est la nouvelle f-mesure de 55,27 obtenue en optimisant sur cette mesure et en exploitant les bi-segments provenant des trois autres techniques. C’est la valeur la plus élevée sur l’ensemble de nos expériences, et elle correspond notamment à un gain de +4,3 par rapport à la combinaison par union des résultats de toutes les techniques, ou encore à un gain de +2,01 par rapport à M OT, la meilleure technique individuelle pour la f-mesure, et à un gain de +2,9 par rapport à D ISTF1 , la technique utilisée sans adaptation et optimisée selon le même critère. Ces résultats viennent confirmer notre hypothèse que TERp a pu ici tirer utilement profit des connaissances a priori qui lui ont été fournies.
Nous constatons de plus que des valeurs de précision et de rappel encourageantes peuvent être atteintes : une précision de 69,66 est obtenue en exploitant les prédictions de T ERME et en optimisant sur la précision (+2,7 par rapport à la meilleure technique individuelle S YNT), et un rappel de 62,38 est obtenu en exploitant les prédictions de M OT en optimisant sur le rappel (+0.82 par rapport à la meilleure technique individuelle D ISTR ).
Les cas de combinaisons où une seule technique est utilisée pour alimenter la base de paraphrases de TERp peuvent également être étudiés en comparant les valeurs des tables 1 et 2. Hormis les valeurs de rappel obtenues pour 6. Il serait bien sûr possible de pondérer a priori chaque hypothèse par le nombre de techniques l’ayant proposée, et/ou par la performance mesurée des techniques en question, dérivée par exemple de leur performance individuelle dans les différentes valeurs de PARAMETRIC. En outre, la contribution de chacune des techniques pourrait faire l’objet d’un paramètre optimisé simultanément aux paramètres de TERp. Toutes ces possibilités seront considérées dans notre travail futur.
H OUDA B OUAMOR , AURÉLIEN M AX ET A NNE V ILNAT 
Critère d’optimisation Source de bi-segments               D ISTP                      D ISTR                      D ISTF1 P     R/13532     F1       P     R/13532      F1       P      R/13532     F1 M OT                  67,83    13,21     22,11   41,49     62,38    49,83    55,11     54,51     54,81 T ERME                 69,66     6,82     12,42   40,51     55,6     46,87    53,16     49,84     51,45 S YNT                 68,08     8,11     14,48   29,99     56,84    39,26    51,25     50,14     50,69 comb(M OT, S YNT, T ERME)      66,02    13,15     21,93   38,46     61,09     47,2    55,01     55,54     55,27 TABLE 2 – Résultats obtenus pour différentes optimisations et différentes sources de bi-segments. La fonction comb correspond à l’union avec pondération uniforme des bi-segments ne retenant que les bi-segments minimaux.
D ISTR avec les paraphrases de T ERME et S YNT, toutes les autres combinaisons de D IST avec les données d’une autre technique et optimisées selon un critère particulier améliorent la meilleure des deux valeurs précédentes.
Par exemple, D ISTP adapté avec les paraphrases de T ERME obtient une précision de 69,66, qui est meilleure que celle de D ISTP (58,54) et celle de T ERME (60,87). Il est à noter qu’en combinaison de systèmes, comme c’est par exemple le cas en traduction automatique, des gains sont plus généralement obtenus lorsque un certain nombre de systèmes sont combinés. La complémentarité de nos sources d’information et l’impact assez immédiat d’une amélioration des informations a priori utilisées par TERp semblent donc ici avoir un rôle très bénéfique pour notre tâche.
Il est finalement instructif de considérer la performance des différentes configurations testées en fonction d’une certaine difficulté a priori. Celle-ci pourrait se mesurer par le degré d’accord inter-annotateurs pour chaque phrase, mais nous avons choisi d’utiliser un résultat en lien avec TERp : (1 − T ER(paraphrase1 , paraphrase2 )), qui est donc d’autant plus grand que les phrases sont proches. Le résultat pour nos quatre techniques individuelles est présenté dans la figure 6. Pour la précision, on constate tout d’abord que M OT est très sensible à la difficulté telle que nous la définissons, et que les alignements que cette technique produit sont d’autant moins bons que les phrases sont différentes. De façon un peu plus surprenante, S YNT et D ISTP ne semblent pas trop affectés par cette difficulté. Cependant, ceci est peut-être dû au fait que les valeurs des barres, pour chaque intervalle discrétisé, sont une moyenne qui ne rend pas compte du nombre d’éléments. Il est possible que S YNT extraie peu de bi-segments sur des paires de phrases difficiles, mais que lorsqu’elle parvient à trouver des structures syntaxiques compatibles, celles-ci permettent un alignement précis. Enfin, T ERME est lui insensible à cette difficulté, ce qui était attendu puisqu’elle fonctionne sur de courts patrons morphosyntaxiques pouvant impliquer des mots différents. Nous déduisons donc de ces remarques que ces différentes techniques peuvent être utilisées à bon escient pour différents niveaux de parallélisme des corpus d’acquisition. Le rappel fait apparaître une tendance beaucoup plus marquée : M OT, D ISTR et S YNT extraient d’autant moins de bi-segments de la référence que les phrases sont difficiles. À nouveau, T ERME y semble insensible. On retiendra de cette analyse qu’il est préférable d’avoir des paraphrases d’énoncés les plus « parallèles » possibles pour obtenir une bonne performance en acquisition, mais que les techniques symboliques sont utiles pour extraire des paraphrases sous-phrastiques précises dans des paraphrases d’énoncés de formes très différentes.
4    Conclusion et travaux futurs 
Dans cet article nous avons poursuivi deux objectifs. D’une part, nous avons présenté quatre méthodes d’acquisition de paraphrases sous-phrastiques à partir de corpus monolingues parallèles. Trois d’entre elles avaient déjà été évaluées, la dernière est nouvelle. Ces méthodes reposent sur des caractéristiques linguistiques différentes : M OT sur l’apprentissage statistique, T ERME sur un approche symbolique de la variation de termes, S YNT sur des proximités syntaxiques et enfin DIST sur des distances d’édition. En évaluant ces méthodes, nous avons constaté qu’effectivement leurs résultats semblent complémentaires, ce qui nous a mené à notre second objectif, à savoir l’hybridation de ces méthodes. Plutôt que de combiner les résultats a posteriori, nous avons choisi d’utiliser les résultats de certaines méthodes comme données d’entrée d’une autre. Les résultats de cette approche ont confirmé notre hypothèse en montrant que la complémentarité de ces techniques donne un gain significatif.
De nombreuses pistes s’ouvrent à nous à la suite de ce travail. Nous souhaitons explorer toutes celles évoquées au cours de cet article. À court terme, nous comptons attribuer des scores de confiance à chacune des techniques afin C OMBINAISON D ’ INFORMATIONS POUR L’ ALIGNEMENT MONOLINGUE F IGURE 6 – Performance selon les différents critères de PARAMETRIC de différentes techniques. La valeur de chaque barre dans les intervalles discrétisés est une moyenne des éléments de cet intervalle, et ne rend pas compte du nombre de ces éléments. Pour la précision, une valeur de 0 peut indiquer soit l’absence de proposition pour les phrases de cet intervalle, soit de propositions toutes incorrectes.
de mieux tirer parti de leur complémentarité. Nous allons également utiliser des connaissances complémentaires.
Il est important de noter que cette méthode peut s’adapter à la tâche requérant des paraphrases. Ainsi, on peut souhaiter en obtenir de nombreuses, au détriment de leur qualité pour de la recherche d’information, alors que la correction sera privilégiée pour le résumé automatique.

